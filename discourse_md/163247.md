## ga3 large language models discussion thread tds jan 2025
https://discourse.onlinedegree.iitm.ac.in/t/ga3-large-language-models-discussion-thread-tds-jan-2025/163247


**Post ID:** 579668

Please post any questions related to Graded Assignment 3 - Large Language Models.

Important Instruction
Please use markdown code formatting (fenced code blocks) when sharing code in Discourse posts. This makes the code much easier to read and differentiate from non-code text. It also makes it easier for people to copy code snippets and run it themselves. See below code for example
ping exam.sanand.workers.dev

Pinging exam.sanand.workers.dev [104.21.31.149] with 32 bytes of data:
Reply from 104.21.31.149: bytes=32 time=9ms TTL=58
Reply from 104.21.31.149: bytes=32 time=8ms TTL=58
Reply from 104.21.31.149: bytes=32 time=8ms TTL=58
Reply from 104.21.31.149: bytes=32 time=9ms TTL=58

Ping statistics for 104.21.31.149:
    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
    Minimum = 8ms, Maximum = 9ms, Average = 8ms

Visit this link for more details: Extended Syntax | Markdown Guide.
A friendly suggestion: kindly go through Discourse Docs! 

Deadline: Sunday, February 2, 2025 6:29 PM
@carlton @Jivraj @Saransh_Saini

**Post ID:** 579673



**Post ID:** 580013

how to get the dummy API key?

**Post ID:** 580073

Hi Nilay,
In order to make a api call to openai chat completions you are required to send authentication information(openai key) in headers. For first question of GA3 you don’t have to send actual(working) api key, any dummy api key would work(you can put your name, or tds anything works)
kind regards

**Post ID:** 581443

which API should i use in 7th question

**Post ID:** 581855

need help in question 4th. how can i correct this json body? sir  @Jivraj
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": "Extract text from this image."
    },
    {
      "role": "user",
      "content": {
        "image_url": "data:image/png;base64,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"
      }
    }
  ]
}


error:The JSON body must have 1 message
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": {
        "text": "Extract text from this image.",
        "image_url": "data:image/png;base64,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"
      }
    }
  ]
}


Error: The message must have a 2 content parts

**Post ID:** 582119

@Jivraj @carlton  sir plz see it once.

**Post ID:** 582598

Hi @22f3001315 ,
You are almost correct, there are very minor changes that needs to be made.
Take help from Chat GPT or use this documentation which have correct json body Vision - OpenAI API.
Kind regards
Jivraj

**Post ID:** 582639

it worked thanks sir

**Post ID:** 582722

Are we supposed to buy open ai api key ?

**Post ID:** 582744

No, if you scroll down to the last question, we can get our Ai Proxy key

**Post ID:** 582749

@nilaychugh @22f3002034
The API key is available at https://aiproxy.sanand.workers.dev/
The instructions on how to use the token is given at GitHub - sanand0/aiproxy: Authorizing proxy for LLMs
You cannot use this token directly with Open AI or any other gpt. These are only valid via the API exposed by the above instructions.
You get a limit of $1. Use with care.
Kind regards

**Post ID:** 582810

but the embedding model that is said to be used is text embedding 3 small, which is the model of OpenAI

**Post ID:** 583185

Hi Nilay,
Yes you would need to use text-embedding-3-small model of openai for embedding questions.
Kind regards
Jivraj

**Post ID:** 583854

i have a doubt, while submitting the GA3, both 7th and 8th questions require the API url to be active and connected right, but its not possible as both the URLs use same port, so if we check my 7th question URL is running right now, it’ll show as correct, but then if i  run 8th question URL, the 7th question will automatically show the error, is there any solution to this problem?

**Post ID:** 583913

Q5.  How to handle the error ? sir @Jivraj
Error: The first input does not match the first text exactly

**Post ID:** 583919

Q4. How to handle this error? @Jivraj
{
  "id": "chatcmpl-AshDCPwSiXNao1QXmCxCmi63GifFx",
  "object": "chat.completion",
  "created": 1737599182,
  "model": "gpt-4o-mini-2024-07-18",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The image contains an email address and a number. The email address appears to be associated with an educational institution, and the number seems to be a numerical sequence.",
        "refusal": null
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 592,
    "completion_tokens": 33,
    "total_tokens": 625,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_bd83329f63",
  "monthlyCost": 0.05490624000000001,
  "cost": 0.001974,
  "monthlyRequests": 14,
  "costError": "crypto.createHash is not a function"
}

Error: Model must be gpt-4o-mini

**Post ID:** 584032

Hi Nilay,



 nilaychugh:

both the URLs use same port,


You can run two servers on different port numbers.

**Post ID:** 584038

Hi Vikash,
I looked at your answers in backend. In answer you submitted response from openai, but you need to submit json object which is required for sending a request to LLM.
Kind regards

**Post ID:** 584042

You made same mistake here, instead of response use json body that’s required for sending request to LLM.
Kind regards

**Post ID:** 584257

Q4. how to handle this error ? @Jivraj
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Extract text from this image"},
        {
          "type": "image_url",
          "image_url": { "url": "data:image/png;base64,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" }
        }
      ]
    }
  ]
}

Error: The image_url.url must be the base64 data URL of the image

**Post ID:** 584261

Q8. how to handle the error ? @Jivraj
http://127.0.0.1:8000/execute?q=Expense+balance+for+emp+52094
{“name”: “expense_balance”, “arguments”: “{“employee_id”: 52094}”}
TypeError: Failed to fetch

**Post ID:** 584413

```Image was here: The image displays a user interface for a software assessment or quiz platform, featuring a list of questions related to large language models (LLMs) and their applications. The visible elements include a due date indication ("Due Sun, 2 Feb, 2025, 11:59 pm IST"), a scoring summary showing a score of 2.75 out of 8.5, along with a "Check" and "Save" button. Under "Recent saves," it lists several timestamps for saves made on "24/1/2025," each with a score of 2.75. The questions include topics such as "LLM Sentiment Analysis," "LLM Token Cost," and "Embedding Similarity," along with corresponding marks assigned to each. The overall layout suggests a structured environment designed for evaluating knowledge in specific technical areas related to AI and machine learning frameworks.```image1366×622 27.1 KB
Why is my score is out of 8.5? It should be 9.5 right?
It was 9.5 before a reload.

**Post ID:** 584421

You should answer the third question every time the site reloads

**Post ID:** 584453

```Image was here: The image displays a programming task in a coding environment involving Python. It contains a variable named `embeddings`, which is a dictionary pairing phrases with their corresponding embedding vectors, specifically the phrase "Packaging was excellent." followed by a list of float values. Below this, there is a prompt instructing the user to write a Python function named `most_similar(embeddings)` that calculates cosine similarity between the embedding pairs and returns the two most similar phrases as a tuple. However, an error message appears, indicating a `NameError`: "name 'most_similar' is not defined," along with a traceback detailing the file path and line numbers in the context of a Python environment, suggesting that this is from a Jupyter notebook or similar IDE setup. The interface also provides an empty code input area for user coding. The visible coding context suggests that this is related to natural language processing, leveraging cosine similarity for embedding analysis.```image1122×471 13.9 KB
For question no.6, there was some pre-written code there, right?
I am not able to see it now.

**Post ID:** 584459

```Image was here: The image displays a terminal interface, specifically a PowerShell prompt in Windows, executing a Python script named `request.py` located in the directory `C:\Users\Varad\OneDrive\Documents\Desktop\Temp\TDS`. The command issued is `python -u`, indicating the script is run with unbuffered output. Following the command, an error message is returned in JSON format, indicating a quota issue with OpenAI's API: `{"error": {"message": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.","type": "insufficient_quota", "param": None, "code": "insufficient_quota"}}`. This context suggests the user is attempting to make an API request to OpenAI's service while encountering a limitation due to exceeding their current usage plan. The output reflects common debugging or error handling activities in software development related to API usage limits.```image1017×146 6.62 KB
I am getting insufficient_quota message for the 2nd question

**Post ID:** 586911

21f3002277:

The image_url.url must be the base64 data URL of the image


I tried downloading image for your dataset it is 2.36 KB in size.
Using base64 encoded string from image_url.url in your code when decoded comes out to be 8.18 KB, when I encoded image from your dataset and decoded it was 2.36 KB.
```Image was here: The image presents a technical interface showing a section for Base64 encoded data, specifically an image. The upper part displays a long Base64 string starting with "data:image/png;base64," followed by encoded data which suggests it contains an image in PNG format. Below this, there is a "Preview Image" section annotated with the option to "Toggle Background Color," indicating a user interface element that likely allows for image viewing adjustments. The highlighted text includes what appears to be an email address, "21f3002277@ds.study.iitm.ac.in," possibly referencing a user or an account related to a digital learning platform or educational institution. The file information section details the image's resolution of 757x66 pixels, its MIME type as image/png, and specifies the file size as 8.18 KB, along with a link to download the image as "image.png." The context suggests this could be part of an image handling tool or an online resource for decoding Base64 images in a programming or web development setting.```image1518×765 95.5 KB
Hints : check if encoding is correct.

**Post ID:** 586942

Is it required to give SCT for the ROE of this course?
Thank you.

**Post ID:** 587025

SCT is not required for ROE. ROE is not proctored.
Kind regards

**Post ID:** 587062

This is regarding Question 2 I tried to find number of tokens for the message. Using chatgpt identified the followings are valid English words for the given text in the question D m Ay E r u y Vy V Ky P c. then, checked with https://platform.openai.com/tokenizer. whatever number given by it seems to wrong.
@Jivraj could you inform me where I did mistake

**Post ID:** 587070

@23f2003853 You have to find the input tokens from the json response you receive from the proxy.

**Post ID:** 587175

Hi VIKASH,
This problem must be because CORS not enabled or you are running your application inside wsl, if you using WSL then you would need to identify ipaddress of WSL and use it in place of 127.0.0.1
kind regards

**Post ID:** 587180

Sir, from where can I  learn to locate the json response

**Post ID:** 587188

Hi @23f2003853 ,
You can learn from Python’s Requests Library (Guide) – Real Python tutorial about how to use requests module and see responses.
kind regards

**Post ID:** 587193

22f3000445:

I am getting insufficient_quota message for the 2nd question


Which url are you using to send request to openai.

**Post ID:** 587196

22f3000445:

For question no.6, there was some pre-written code there, right?


pre-written code is not required for question 6.

**Post ID:** 587325

In the 6th question ,as I open the graded assignment all the time the new question is generated (NUMERICAL DATA) and the previous answer shows as incorrect answer
My doubt is that should I again and again answer the same quetion(6) all the time until the due passes?
Is there any alternative ways to look after this problem?

**Post ID:** 587371

```Image was here: The image shows a snippet of Python code that utilizes the `requests` library to make a POST request to a specified URL, sending JSON data in the request. The `headers` variable contains the necessary HTTP headers, and the `jsondata` is formatted in JSON. There is a check for a successful response, verifying if the HTTP status code is 200; if so, it prints the parsed JSON response in an indented format. If the status code is not 200, an error handling section outputs a message indicating a failed request, displaying the actual status code received (429). Below the code, an error message in JSON format is presented, stating that the quota has been exceeded, alongside a suggestion to check the user's plan and billing details. The error message contains keys like "error", "type", "message", "param", and "code", with the specific code being "insufficient_quota". The context suggests that the script is intended for debugging and managing API requests, likely in a platform related to OpenAI services. The interface appears to be a code editor environment, possibly Visual Studio Code, indicated by UI elements such as a console output area.```Screenshot 2025-01-29 0948321770×659 35.1 KB
how to solve???

**Post ID:** 587379

getting quota full message for 7th question. How to get the answers then?

**Post ID:** 587575

Hi @Divya1 ,
Question 6 requires to write a generic code for finding most similar pair. If your code is doing so, pls mention exact steps that you have used to arrive at answer.

**Post ID:** 587577

sanand0/aiproxy: Authorizing proxy for LLMs
Are you using this document?

**Post ID:** 587882

each time when I run the following code it gives me different number. None of the answer is correct. can help to fix the issue
```Image was here: The image displays a Python script executed within a coding environment, likely a version of Jupyter Notebook or similar IDE. The code snippet indicates it interacts with OpenAI's API, specifically referencing the chat completions endpoint for GPT-4. Key elements include a list of available models such as 'gpt-3.5-turbo', 'gpt-4', and others. The script prepares a request payload for the Chat API, formatted with a user message. It generates a POST request using the `requests` library, including headers like 'Authorization' and 'Content-Type'. After sending the request, the code checks the response status indicating success, extracting the total token count from the JSON response or reporting an error if the request fails, outputting the status code and response JSON. Contextually, this setup illustrates API interaction for text generation tasks, showcasing key programming constructs such as JSON handling, HTTP requests, and conditional statements in Python. The interface also notes input tokens used as 144, emphasizing token management in API calls.```image584×246 46 KB

**Post ID:** 588058

Hi @23f2003853 ,
Please join tomorrow’s session, we can take it there, I am not sure why you facing this problem.

**Post ID:** 588067

Sure Sir. I am providing you the code below
import json
import os

api_key = key

# Set up the endpoint and headers
url = "https://api.openai.com/v1/chat/completions"  # Use chat completions endpoint for GPT-4
headers = {
    "Authorization": f"Bearer {key}",
    "Content-Type": "application/json"
}

# List of input strings
user_message = """
List only the valid English words from these: Q5YpaFZ0S, qZXgs13f, zyCiAjPh, JfcKU, G51N4, D, 9GbmmI27, jbdnhCd, 2dTr75, m, kS, lhO3Uc8e, SjpEmLl, u1cnuqk50, W54, 9, 7YWtUR, reoWxE2, Ay, ANRl2pFjL, E, 4hcE4cB, TZ2t, vck6a, Sb6vQ5K, CzQ, T5lYjxy1m, 2D, yG7PLW, mvgHmixMqn, YOPzsuhQ3, nSF7e6zFF, J60xA5WVp3, oz, vJM, vp2Zrsr, 59wiruyNzq, r, 8N, wv, z, MAKFrf5, 2L, 1IwLjzNpma, 5N20N7Zuq, 9dVp, tmUao0x, u, QRxy67, y, jrIvOZ, t3i, rptivNJF, Vy, 5WWaC1u, WC, xfoGYp, 350c94lf, Pc9oNu, 1bOnLseHUm, aguOp0jxE, Tbz, qX, 9amaVxKFh, bnBkkNN5jc, o7N4y6, V, Ky, ewWw0qcLnw, bbD7MBGM7x, c0l, P, TMFOMvW, c, THRovqGNKb, BV, XIZcX, J0rDx3c, DxEvjEh, j9, Db5Hij, vpSJyCeyh, Z, D, yWpxiOwRXx, 7NeZN1GVE, Y, Lq6Pk, BCJT
"""

# Prepare the payload for Chat API (gpt-4o-mini model)
data = {
    "model": "gpt-4o-mini",  
    "messages": [{"role": "user", "content": user_message}],  

}

# Send the POST request to OpenAI API
response = requests.post(url, headers=headers, json=data)

# Parse the JSON response
response_json = response.json()

# Check if the request was successful
if response.status_code == 200:
    input_tokens = response_json.get("usage", {}).get("total_tokens", "N/A")
    print(f"Input tokens used: {input_tokens}")
else:
    print(f"Request failed with status code {response.status_code}: {response_json}")```

**Post ID:** 588214

Hello Sir,
I am unable to recieve a proper output for q1 of ga3.
This is my test message. Its been given in two lines.
```Image was here: The image depicts a code snippet or console output consisting of a series of alphanumeric strings arranged in a two-column format, with each line displaying a mix of letters and numbers, indicating potential identifiers or keys. The first column features a numeric prefix "2" followed by "b7" and "rkS94mn4". The second column begins with "AM" and includes additional values "dNG64j", "EVevK24Ev", "VEpI", and "G" along with "LeeHS". The layout suggests a data structure or log output, possibly from a programming or configuration context, though no specific technologies, file types, or UI elements are identifiable. The presentation resembles a command-line or console output, which could relate to various software engineering tasks, such as key management or debugging output from a script.```
The below is my code for the question.
import httpx

url = "https://api.openai.com/v1/chat/completions"

headers = {
    "Authorization": "Bearer api_key",
    "Content-Type": "application/json"
}

system_message = "Analyze the input message if it's  GOOD , BAD or NEUTRAL."
user_message = "2 b7 rkS94mn4  AM dNG4j EVevK24Ev VEpI G LeeHS"

payload = {
    "model": "gpt-4o-mini",
    "messages": [
        {"role": "system", "content": system_message},  # System message
        {"role": "user", "content": user_message}       # One user message
    ],
    "temperature": 0.7
}

response = httpx.post(url, headers=headers, json=payload)

response.raise_for_status()

result = response.json()

for choice in result["choices"]:
    print("AI Response:", choice["message"]["content"])

I tried to put the two test lines as two user messages but received an error stating that the json body must contain only 2 messages with one mandatorily being a system message. With that in mind, i also tried the alternative
user_message = "2 b7 rkS94mn4 \n AM dNG4j EVevK24Ev VEpI G LeeHS"
The error message i keep receiving is as below.
```Image was here: The image shows an error message output within a code editor or terminal interface, likely indicating an issue with a payload for a software application. The relevant code snippet begins with `payload = {` suggesting the start of a dictionary or object definition in a programming language such as Python or JavaScript. The error message reads: "Error: The user message must be 2 b7 rkS94mn4 AM dNG4j EVepl G LeeHS, not 2 b7 rkS94mn4 AM dNG4j EVepl G LeeHS," implying that there is a specific requirement for the format or length of a user message, indicating potential validation or data formatting issues. The context suggests that this is part of a debugging process, likely in a development environment for an application that involves message handling or API requests. Specific technologies or conventions are not explicitly mentioned, but the structure hints at a JSON-like format, relevant for web APIs or similar infrastructures.```
Kindly advice on how to proceed.
Thanks and Regards
Shalini

**Post ID:** 588213

Hi Shalini,
Your user_message is incorrect. I looked at your exact GA and it works if you make sure your user_message is precisely what is given to you.
Hint: How do you store a multi-line variable in python?
Kind regards

**Post ID:** 588228

Hello, could anyone please confirm that GA 3 is worth 9.5 points? Since our GAs are typically 10 marks apiece, I wanted to inquire about and obtain clarification on this.
Thank you in advance.

**Post ID:** 588278

I was unable to make the answer box in Question 3 visible. I was only able to make white space appear there, but couldn’t make it so that answer can be input to the box.

**Post ID:** 588283

In addition to CSS classes there is also a tag attribute acting on it. Check carefully.
Kind regards

**Post ID:** 588333

I am getting below error for Q6 if i am importing sklearn libarary
```Image was here: The image displays a Python error traceback indicating a `ModuleNotFoundError` for the module 'scipy'. It reports the error occurring in the Pyodide environment, specifically within the file located at `/lib/python312.zip/_pyodide/_base.py`, at line 523 during an evaluation of code in a coroutine. The error suggests that 'scipy', which is part of the Pyodide distribution, is not installed, and provides instructions to install it using `await micropip.install("scipy")` in Python or via JavaScript. The traceback highlights multiple lines with carets indicating the sequence of calls leading to the error, and it serves a debugging purpose, targeting issues in a code execution environment that supports running Python in the browser through WebAssembly technology like Pyodide.```image1731×180 13.1 KB

**Post ID:** 588423

Hi team, I am using OpenAI API key for solving Q7 and getting the error like below
{'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

Is it necessary to pay for the OpenAI API key? Is there any other way?

**Post ID:** 588469

@21f2000588
Sure does add up to 9.5 , unless you want another question 
Kind regards

**Post ID:** 588481

Yeah, after all these years of learning and teaching computing, I realize I can’t even count to 10 correctly anymore.
```Image was here: The image depicts a comic strip featuring a character discussing the evolution of technology in relation to math and calculations. The first panel shows the character referencing their father, who learned math using a slide rule in school. The second panel illustrates the father explaining that he hasn't used a slide rule since acquiring a calculator that performs multiple functions. The third panel presents the character proposing that, due to technological advancements, it's better to leave math to machines and play outside instead. The final panel features a humorous statement about bills dying in subcommittee, indicating a commentary on procrastination or inefficiency in governance. The visual style suggests a cartoonish representation, emphasizing the lighthearted narrative. There are no visible code, configurations, or technical elements related specifically to software engineering in this context.```600×187 16.6 KB

**Post ID:** 588484

@Jivraj Please let me know if the code is needed for this. I can share the code generated by chatgpt

**Post ID:** 588749

@Jivraj , @carlton  Dear Sirs, I need help in solving this question. I have the same issue. I have tried tokenizer tool, tried writing request code but still couldn’t get the correct answer. I have tried numerous time and ended up consuming lot of tokens . What should be the optimal approach in this question?
  "id": "chatcmpl-Aw7eXQ8hciiQ0ZedatQEifFGxnLhQ",
  "object": "chat.completion",
  "created": 1738415805,
  "model": "gpt-4o-mini-2024-07-18",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The valid English words from the given list are:\n\n- a\n- I\n- o\n- t\n- U\n- w\n- y\n- z",
        "refusal": null
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 532,
    "completion_tokens": 34,
    "total_tokens": 566,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_bd83329f63",
  "monthlyCost": 0.01662212,
  "cost": 0.001863,
  "monthlyRequests": 41,
  "costError": "crypto.createHash is not a function"
}

**Post ID:** 589234

Tried hundreds of different prompts, different situations but in Q9 AI is not responding “Yes”. Is there anything i am missing?

**Post ID:** 589391

Dear Sir, I got the answer in json but none out put is correct. Please help me to correct the code
curl https://api.openai.com/v1/chat/completions \                                             >   -H “Content-Type: application/json” \                                                                               >   -H “Authorization: Bearer $TOKEN” \                                                                                 '{                                                                                                                          >   -d ‘{                                                                                                           >     “model”: “gpt-4o-mini”,                                                                                            "messa>     “messages”: [{                                                                                             >       “role”: “user”,                                                                                                      "c>       “content”: “List only the valid English words from these: zqndWw3FB, kM, K, njuHs9A, r, lkXJ1lG, Z, yLHDClp, G1Db, 7, m, MYieYF3B, pFTQ1JU8Fj, RL9n6kE, EVpChB, V6iCpP, 9YwiwAnBc5, R, UM, mrnyc, 4ej9x, 8X, CQA9, jHC, uL4G6, f, zzaozWC9, 0qsOenEndF, qaZ2WoX, nXGZ”                                                                                   >     }]                                                                                                                >   }’                                                                                                                  {                                                                                                                         “id”: “chatcmpl-AwTPGH241yjyg9EkO1t1tbeGU7KCu”,                                                                         “object”: “chat.completion”,                                                                                            “created”: 1738499426,                                                                                                  “model”: “gpt-4o-mini-2024-07-18”,                                                                                      “choices”: [                                                                                                              {                                                                                                                         “index”: 0,                                                                                                             “message”: {                                                                                                              “role”: “assistant”,                                                                                                    “content”: “The valid English words from your list are:\n\n- my\n- is\n- an\n- or\n- in\n\n(Note: This assumes a focus on short English words. Longer words or specific proper nouns may also exist but were not included in this selection.)”,                                                                                                                         “refusal”: null                                                                                                       },                                                                                                                      “logprobs”: null,                                                                                                       “finish_reason”: “stop”                                                                                               }                                                                                                                     ],                                                                                                                      “usage”: {                                                                                                                “prompt_tokens”: 160,                                                                                                   “completion_tokens”: 53,                                                                                                “total_tokens”: 213,                                                                                                    “prompt_tokens_details”: {                                                                                                “cached_tokens”: 0,                                                                                                     “audio_tokens”: 0                                                                                                     },                                                                                                                      “completion_tokens_details”: {                                                                                            “reasoning_tokens”: 0,                                                                                                  “audio_tokens”: 0,                                                                                                      “accepted_prediction_tokens”: 0,                                                                                        “rejected_prediction_tokens”: 0                                                                                       }                                                                                                                     },                                                                                                                      “service_tier”: “default”,                                                                                              “system_fingerprint”: “fp_72ed7ab54c”                                                                                 }

**Post ID:** 589614

Pls give some kind of clue. It seems like a waste of so much time!

**Post ID:** 589632

i agree, i have wasted around 300 requests (prompts) and got nothing.

**Post ID:** 590138

Sir I am stuck in Q4. how to handle the error please help me @Jivraj @carlton
Error: The image_url.url must be the base64 data URL of the image

**Post ID:** 590143

Okay thank you sir, for the clarification.

**Post ID:** 590322

You have to download that image, and find the base_url of that image.

**Post ID:** 590325

from where to download

**Post ID:** 590342

The image is part of the question.

**Post ID:** 590350

For those who want to experiment with GPT-4o Mini (or other models), Github Models is free. You can explore and compare models, including GPT-4o Mini, DeepSeek R1, and others.
It has rate limits, so you can’t use it in production, but is a good place to prototype applications and experiment with prompts.
Please let me know if you face any problems accessing it.

**Post ID:** 590386

how to answer the question in first place ?

**Post ID:** 590397

Check if you are requesting through anand sir’s proxy AI Proxy.

**Post ID:** 590398

sklearn might be using scipy for some purpose, just install it, it should work.
Btw what are you trying to do with Sklearn?

**Post ID:** 590422

thanks for the reply i was using cosine function but got another solution.

**Post ID:** 590530

Q2 LLM Token Cost ,
We have https://platform.openai.com/tokenizer , which helps us count tokens in a string, shouldn’t this be a better way than calling the API? However the returned value does not show as correct answer!

**Post ID:** 590614

Hi guys, just wanted to share that I found it hysterical when I saw this question:
```Image was here: The image contains a technical forum post related to RapidRoute Solutions, a logistics company. It discusses the integration of automated address validation using OpenAI. The post outlines a specific task to formulate a JSON request body for an OpenAI chat completion call. Key details include a section labeled "require" that specifies the required fields, which are "type," "string," "input," and "additionalProperties," indicating that additional fields must be provided in the request object. It emphasizes that "additionalProperties": false is necessary for the OpenAI API. There is an instruction to include specific entries in the JSON, highlighting fields like "zip" as a number and "latitude" as a number with a suggestion to also provide a sample message stating "Respond in JSON." At the bottom, it urges the reader to understand the structure required for the API key request and links to the OpenAI API documentation. The interface appears to be that of a coding or educational platform, featuring check buttons and save options, with a visible URL directing to OpenAI's documentation resources. Additionally, a timestamp in the top left indicates the deadline for submission, suggesting a time-sensitive task.```image1920×1080 305 KB
Like I literally showed this question to my mother and younger bro, stating the fact we ourselves had enable the answer box, they laughed there pants off…
More courses could be like this.

**Post ID:** 590620

Q4
s3 string was given by
image_b64 = ""
import base64
with open('/content/TDS_wk3_q4.png', 'rb') as f:
    binary_data = f.read()
    image_b64 = base64.b64encode(binary_data).decode()
data_uri = f"data:image/png;base64,{image_b64}"


s4 string given by : 
used this link   to generate image url
 Then checked them both, they were the same
for x,y in zip(s3,s4):
  if (x != y):
    print(x,y)

i verified that both were equal but still one gave the wrong answer(python code), while the online converter gave the right one?
I know i’m missing something, but why?

**Post ID:** 590626

```Image was here: The image depicts a programming challenge on a technical forum focused on writing a Python function named `most_similar`, designed to compute the cosine similarity between pairs of embeddings and return the most similar phrases as a tuple. The visible code snippet starts by importing the `numpy` library, followed by a partially implemented function definition for `most_similar`, which contains a comment placeholder for user code. Below the code, an error message is displayed indicating a traceback from a Python environment. The specific error mentioned is a `NameError`, stating that 'phrase1' is not defined, with the location traced back to line 8 of the evaluated code. The interface appears to be an integrated coding platform, possibly with features for error highlighting, as indicated by the "Incorrect answer" label next to the input area. This context suggests an activity centered on debugging and developing a function within a Python coding environment.```Screenshot 2025-02-04 1933421670×487 54.1 KB

**Post ID:** 590627

```Image was here: The image displays a web interface form asking for an API URL endpoint for implementation, suggesting a structure such as `http://127.0.0.1:8000/execute`. Below the input field, there is a prominent error message in red stating "SyntaxError: 'undefined' is not valid JSON". This indicates a potential issue related to JSON formatting or API response validity. The context suggests an activity related to API testing or debugging, likely involving a GET request to the specified URL, with parameters required to match a function definition. No specific programming technologies or code files are present, but the interaction implies a focus on web service testing or RESTful API development, commonly used in environments like Postman or similar API testing tools.```Screenshot 2025-02-04 at 19.32.212700×488 55.4 KB
This is in context to Q8. This is a screenshot of the response I am getting when i run the same API on my FastAPI/docs response page, it gives the correct response. But when I check it on the assignment page i get the following error. If you would like to know the code, pls let me know. @carlton @Jivraj

**Post ID:** 590666

Good Evening, I have a doubt regarding 7th and 8th question. I am getting this error of expecting three matches while saving. But, Externally when I check this API, I tried considerable test cases, and I am getting the output correctly. Can you please check this and give a solution. Thank You
```Image was here: The image displays a JSON-like structure indicating a response object, specifically showing a key `"matches"` that contains an array of string elements. The array includes three items: `'banana'`, `'watermelon'`, and `'jamaica'`. The formatting suggests this is part of a data retrieval process, potentially from an API response or a database query assessing string matches. The console output appears to be minimal and clean, indicating a focus on data structure rather than verbose messaging. The context could involve applications in JavaScript, Python, or other programming languages that handle JSON data, and it implies functionality related to search or filtering algorithms where these strings are likely candidates resulting from a query.```
```Image was here: The image features a technical error message related to a web API configuration. It suggests enabling CORS (Cross-Origin Resource Sharing) for HTTP OPTIONS and POST methods, indicating a potential issue with accessing resources from different origins. A sample API URL endpoint is provided, formatted as `http://127.0.0.1:8000/similarity`, which implies that the API is hosted locally on port 8000. The console output includes an error message stating "Error: Expected 3 matches," hinting at a validation issue in the expected number of results from an API request. The overall context suggests a development environment focused on debugging API interaction, possibly within a JavaScript or Python framework that requires CORS configuration for client-server communication.```Screenshot 2025-02-04 2143191694×202 16.4 KB

**Post ID:** 590677

This is regarding the 8th question. Same here, I am getting the answer for all the test cases, but then also, I am getting error in the portal while saving. Please help me out here. Thank You.
```Image was here: The image displays a console output from a local server accessible through the URL `127.0.0.1:8001`. It features a JSON structure that appears to be a request for an API endpoint related to calculating a performance bonus. The content consists of two main components: a "name" key with the value `"calculate_performance_bonus"` and an "arguments" key that contains a nested string representing a JSON object. This inner object includes keys for `"employee_id"` set to `10056` and `"current_year"` set to `2025`. The context suggests this could be a testing or debugging phase involving an API that computes performance bonuses based on specified employee details. No specific programming language or framework is explicitly mentioned, but the structure and content indicate potential usage in a RESTful API environment.```Screenshot 2025-02-04 2320481322×152 8.42 KB
```Image was here: The image presents a user interface prompt asking for an API URL endpoint for an implementation, with an example formatted as `http://127.0.0.1:8000/execute`. Below this input field, there is a console error message stating "TypeError: Failed to fetch", suggesting an issue with accessing the specified endpoint. The UI appears to be related to a web-based or possibly local development environment, likely involving a framework or service that operates over HTTP. The visible HTTP address suggests the context of local server testing and API usage, commonly found in development tools or platforms for backend development, possibly within the context of a REST API client or a web application interface.```Screenshot 2025-02-04 2318471608×129 9.97 KB

**Post ID:** 590682

For question 1 getting the below response … not sure what it means
ythonError: Traceback (most recent call last): File “/lib/python312.zip/_pyodide/_base.py”, line 523, in eval_code .run(globals, locals) ^^^^^^^^^^^^^^^^^^^^ File “/lib/python312.zip/_pyodide/_base.py”, line 357, in run coroutine = eval(self.code, globals, locals) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File “”, line 53, in  TypeError: unhashable type: ‘dict’

**Post ID:** 590701

@carlton
for question 2 what does  the below instruction mean … also how to indicate this in a prompt ’ Remember: indicating that this is a user message takes up a few extra tokens. You actually need to make the request to get the answer."

**Post ID:** 590709

For token count query , trying to do something like below any issues with this
import requests
import json
from google.colab import userdata
def generate_readme_content(proxy_url,auth_token):
    # Prepare the payload
    prompt = f"""       
    SNyFiNTb, BUkDfo0tR, x3x, 6NE8Rq833, Re7, Vth9bYJ0pK, pnI, JAXpFb, BRPE, o, 5xVQe, iY8yVT, 69w, LjLCzs, MJ1g, wBR, 0H, 6bK, AMw, Vrxiux, dqZysH, yD82hcr, FZrwV8Zjq, Xb2, quLpdQqxd1, lqSLbI, HerfhK2, rNPU, 9K1C, 0ywhX2s4O9, mjZ, sR9gCC, 2WVSfwWEae, c, DtWnfOncFj, qjK8P7xh, 0xraHn7RMa, OCmQIi3tbU, S2K, F, q5mO, yZt, X, zd, se0ss3k, uU, yCRCi, S3bMfb, qZ4dh, M7, uhxgDvG3, 696g, 9k, l5U, bH, LVXw1fdWFi, 0kU68gGP, WuyD, V, kVKQ1Y8, kLjMDoEmIN, EYHs7qsabQ, sWrC8vN7n, oAJZP, YLd, mi6Jmxgf, cb9UDdap, kzuot, R0eA2V, mr7SctL49, Td5, in, hxvi, MDg, AAK, uLBF889bO5, Z7z, AO0c, nbc, bE6Rsdw5b, 0, pBjOAuPN8A, 9C3, K, 8, yZyCBPz   
    """
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant to count the number of english words in a message. Find the number of input tokens used for  a message lile below. Try excluding tokens used for understanding this prompt"},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 500,
        "temperature": 0.7
    }
    
        # Send a POST request to the proxy server
    response = requests.post(
            proxy_url,
            headers={"Content-Type": "application/json",
                     
            "Authorization": f"Bearer {auth_token}"},
            data=json.dumps(payload)
        )
    response_data = response.json()
    return response_data
proxy_url = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
auth_token=userdata.get('aiproxy_secret_key')
tokenjson=generate_readme_content(proxy_url,auth_token)
print(tokenjson)

**Post ID:** 590740

I GOT THE CORRECT ANSWER F0R QUES 7 & 8 STILL MY SCORE IS SHOWING 8 DOES ANYONE KNOW HOW TO DO THIS ?
```Image was here: The image displays a screenshot of instructions for an online examination titled "TDS 2025 Jan GA3 - Large Language Models." The interface features a dark-themed background with high-contrast text, outlining key steps for participants. The instructions emphasize essential actions such as learning requirements, checking answers, saving progress, and troubleshooting browser issues. Notably, the document allows the use of external resources, including the internet and various libraries or frameworks. Specific prompts guide users to regularly check answers and indicate that multiple server instances may be employed during the quiz. The UI includes a "Have questions?" link directing users to a discussion board on Discourse, hinting at a collaborative aspect of the exam. The overall context implies an online assessment focused on understanding large language models, with a flexible approach encouraging the use of external tools and resources.```image1903×819 96.2 KB

**Post ID:** 590786

Use addition : to add up your score for each question.
eq:
1+ 1 = 2
Fractions are harder
1.5 + 1 = 2.5
```Image was here: The image displays a list of questions likely related to a technical assessment or examination focused on large language models (LLMs). Each question is numbered and followed by a descriptive title along with a score value in parentheses, indicating their respective marks. The topics include "LLM Sentiment Analysis," "LLM Token Cost," "Generate addresses with LLMs," "LLM Vision," "LLM Embeddings," "Embedding Similarity," "Vector Databases," "Function Calling," and "Get an LLM to say Yes." The content appears to be in a simple text format and may be utilized in a web interface or a digital quiz platform. Specific domain knowledge in machine learning and natural language processing is reinforced through these questions, reflecting current trends and concepts in the field.```image657×512 35.6 KB

**Post ID:** 590788

To this question I have checked values ranging from 6 to 13 none of them are correct, using openAI Tokenizer online tool.
```Image was here: The image displays a web interface for an assessment or coding challenge related to a conversational AI platform named LexiSolve. The UI includes a timer indicating 08:04:14 left, and sections for a scoring mechanism and a submission button. There is descriptive text explaining that LexiSolve uses OpenAI's language models for enterprise applications and emphasizes the importance of token management for system stability. The main task prompts users to generate data for a test case involving an API request to OpenAI's GPT-4-o-Mini with the instruction to "list only the valid English words from these," followed by a prompt for the number of input tokens. Below this, a reminder note points out that the user message consumes extra tokens. The interface hints at interactive functionality with a "Check" button and a score display of 0/95 marks, indicating a testing or quiz environment related to software engineering and APIs.```image1920×1080 248 KB
```Image was here: The image displays a web interface for the OpenAI platform, specifically within the "tokenizer" section of a project dashboard. The highlighted text states: "LIST only the valid English words from these." Below this, a helpful explanation outlines that one token typically corresponds to about four characters of text for common English words, translating to approximately 75 words per 100 tokens. This guidance emphasizes the utility of token management in natural language processing. The interface visually segments elements related to token count and character count, displaying "Tokens: 10" and "Characters: 47." The top menu includes navigation options such as "Clear," "Show example," "Playground," "Dashboard," "Docs," and "API reference." The context appears to be focused on understanding token limits for handling text in programming tasks involving language models. The visible technologies suggest a focus on APIs and possibly Python, with the mention of the "token" package for Python and JavaScript integration.```image1920×1080 225 KB
Please help me were I am going wrong.

**Post ID:** 590789

22f3002723:

user message


that means it should be a user message
messages = [
{
"role":"user",
"content":"message"
}
]

**Post ID:** 590795

Keep getting this error.
```Image was here: The image displays a technical discussion on function calling with OpenAI, likely in a web-based exam or tutorial environment. It features a snippet of code or documentation highlighting the structure of an API response, illustrating document similarity with placeholders for "contents of document j" and "contents of document i." A suggested API URL for implementation is provided as "http://127.0.0.1:8000/similarity." Below, there is an error message indicating a mismatch due to a missing key in the user’s request, advising that improvements are needed for infrastructure and data retrieval. The context suggests debugging and improving API functionality, with attention to CORS (Cross-Origin Resource Sharing) configuration and JSON POST request structures. The interface appears to be a coding assessment tool, with a timer displayed indicating session length. A portion at the bottom labeled "Function Calling (1.5 marks)" suggests a focus on scoring related to a specific programming task or question. The layout includes features for code checks and saving work.```image1920×1080 252 KB

**Post ID:** 590796

Try sending an api call to openai.

**Post ID:** 590800

Check with network tab, you would see the response of api call being made, Compare that with expected output.
Regrading question 8, you would need to check if cors are enabled, check in browser console tab for more.
```Image was here: The image displays a web browser interface with a focus on developer tools, specifically the Network tab showing a request and response interaction. The left side features browser controls with a search bar and various browser icons, including shortcuts to Google and Gmail. On the right, the Network panel lists a request with the name detailing a JSON response related to a web application, indicating a content type of "application/json". The response section shows a JSON object with a key-value pair: `{"aci": {}, "webIsBot": ()}`, suggesting a check for bot status likely from an API call. The context implies the user is debugging network traffic, potentially during a web development session using tools like Chrome DevTools. The main technologies involved seem to relate to web development and API interactions.```image1909×939 126 KB

**Post ID:** 590801

i am unable to find the answer box plss guide me through that

**Post ID:** 590803

You could use AI assistance it helped me.
```Image was here: The image displays a technical forum interface, specifically from a discussion thread related to programming, with code and various elements around it. The left side reveals a conversation thread where a user named "22[2001630]" expresses a recurring error message, posting the text "Keep getting this error." Below this, another user, "23[2000088]," responds, mentioning the need for AI assistance, indicating a collaborative debugging scenario. The right side features a developer tools panel, showing HTML elements including a `<div>` structure with classes related to a discussion interface, and contains a snippet of JavaScript code meant for manipulating the DOM. This context indicates the forum's front-end technology, possibly using React or similar JavaScript frameworks. The console tab is open, and it contains JavaScript snippets that may be related to tracking or handling elements dynamically. The open window labeled "How can I help you?" suggests integration with a chat or support system for additional assistance. The visible elements imply a user-focused scenario of seeking help for coding errors on a shared platform.```image1920×1080 319 KB

**Post ID:** 590804

Oh OK sure. I will try out and let you know. Thank You!

**Post ID:** 590811

Got the answer but it was wired that I had run the curl command three time and the 3 times I got different result.

**Post ID:** 590813

its not working for me any other options plss??

**Post ID:** 590838

23f2003853:

rm me where I did mistake


Sorry but im facing an issue with question 6 and 7 where its saying load failed when I submit it. when I run the queries locally using curl im getting the expected results.  Any help would be appreciated.
```Image was here: The image depicts a user interface for testing an API endpoint, specifically related to handling CORS (Cross-Origin Resource Sharing) settings. It contains a labeled input field where the user is prompted to enter the API URL endpoint, with a suggestion showing a typical format: `http://127.0.0.1:1800/execute`. Beneath this field, there is a red error message stating "TypeError: Load failed," indicating an issue with fetching the provided URL. The text also mentions that a GET request will be sent to this URL, which will verify that it matches the expected response format, emphasizing that arguments must be in the same order as defined in the function setup. The interface features a "Check" button, suggesting an interactive capability to validate the specified URL. The context implies usage of web development technologies likely involving JavaScript or a similar framework for API interaction.```Screenshot 2025-02-05 at 6.19.41 PM1304×299 30.1 KB
curl "http://127.0.0.1:8001/execute?q=What%20is%20the%20status%20of%20ticket%2083742?"

{"name":"get_ticket_status","arguments":"{\"ticket_id\": 83742}"}

**Post ID:** 590867

For question 2, do we have to make the API call to the proxy or openai? If to the proxy, are there any instructions on the page before question 2 that would have pointed me in that direction?

**Post ID:** 590869

```Image was here: The image features a technical discussion focused on making API requests, likely within a web development context. On the left, there is a JSON-like structure displaying a method named "get_ticket_status" with an argument key specifying a ticket ID formatted as `{"ticket_id": 83742}`. Below, there is a CORS-related instruction emphasizing enabling CORS for all origins. An input field suggests constructing an API URL, with an example URL being `http://127.0.0.1:18000/execute`. An error message appears in red, stating "SyntaxError: 'undefined' is not valid JSON," indicating a problem with JSON formatting. To the right, a UI section outlines a query parameter, labeled "q," for fetching the status of ticket 83742, along with a button to "Execute" the request. Below, a sample cURL command is provided for making a GET request to the specified URL, indicating that the request expects a JSON response. The configuration suggests the use of a local development environment, as indicated by the localhost URL. The overall purpose revolves around testing API functionality and debugging potential issues with the request format.```image1287×568 32 KB
I am trying this for so long how to fix this plss guide me. thanking you

**Post ID:** 590875

there is a problem in question 7 and 8, fast api question, when i click on save, both api calls happens at once at http://127.0.0.1:8000, and i can run fast api app for question 7 or 8 for one only, suppose i check for question 7 it shows correct, also for question 8 i check it shows correct , but when i try to save one of the answer gets incorrected because of simultaneous calls by question 7 and 8 at this address http://127.0.0.1:8000

**Post ID:** 590877

```Image was here: The image displays a technical discussion or tutorial on implementing a service flow for a document retrieval system using JSON and API calls. It outlines the steps involved in sending a POST request, including a request payload that contains two main components: `docs`, an array of documents, and `query`, a string for the user's search query. The embedding generation process is described, utilizing a text embedding model named `text-embedding-ada-002` for each document and the query string. A section titled "Similarity Computation" explains how the API assesses document similarity scores based on the obtained embeddings, ultimately identifying the top three corresponding documents. The console output includes specific example snippets illustrating matches, with contents labeled for clarity. Additionally, it suggests enabling CORS for handling requests and provides a sample API URL endpoint format for implementation. A green check button indicates correctness, and the user is prompted to send a POST request to this endpoint with the JSON body containing the specified `docs` and `query` fields. The visible environment suggests a web-based coding or testing interface, likely part of an educational platform or coding environment related to data science or API development.```Screenshot 2025-02-05 at 7.44.03 PM1920×1249 130 KB
while saving the 7th,8th question its alteranately getting incorrect
im getting 8.5 marks but while saving it gets deducted to 7 because of these 2 questions
this is really very frustrating since im working on this for so long like 5-8hours but still facing the same issue
what to do
@carlton @s.anand

**Post ID:** 590879

```Image was here: The image displays a coding interface in a web-based environment, likely a code editor or a Jupyter notebook related to a coursework assignment on large language models (LLMs). A section of the code shows a variable named `DATA` initialized with a JSON-like structure. It includes keys such as `"model"` with the value `"gpt-4-mini"` and `"messages"` which contains an array. Inside this array, there are two objects: the first specifies the role as `"system"` with the content requesting analysis of sentiment into categories such as GOOD, BAD, or NEUTRAL. The second object has the role as `"user"` containing a string with garbled characters. Below the code, there's an error message indicating that the user message must conform to the expected format. The console output area likely shows a script execution environment, implying debugging or testing of API calls using an authorization header with a dummy API key. Additionally, metadata about the completion time remains visible, indicating this is part of a timed assessment for students. Overall, the content relates to the use of LLMs for sentiment analysis within a programming context, alongside API interactions.```Screenshot 2025-02-05 at 8.07.34 PM1920×1249 138 KB
in the 1st as well both the outouts are exactly same but its still showing error
@carlton

**Post ID:** 590882

You can run 2 different severs on different port numbers.
http://127.0.0.1:8000 and http://127.0.0.1:8001

**Post ID:** 590891

I tried checking the JSON Output in the Networks tab. I am getting error as “Method Not Found”. But, I have allowed POST Method for question 7 as POST method is used in the question. I also tried checking my API by sending a POST request by the same parameters as given by the Website. I  am getting the proper response when I give an API request. Can you please help me out here? I have attached the screenshot  of the error as Picture -1 and the correct output what I get as Picture-2.  Please help me out as I am facing issue for all the API Questions though I am getting the right output. Thank You.
```Image was here: The image shows a snippet of JSON output indicating an error message with the key `"detail"` set to the value `"Method Not Allowed"`. This message typically arises in the context of web development, likely from an API response when an unsupported HTTP method is used for a specific endpoint. The format suggests that this output could be part of a response returned from a web server, related to RESTful API calls, indicating misuse of HTTP methods such as GET, POST, PUT, or DELETE. The background appears dark, reminiscent of code editors or development environments like VSCode, enhancing the focus on the textual content.```
```Image was here: The image displays a terminal or console output showing a series of textual messages formatted as JSON or a similar data structure. The visible content includes a key named "matches," which holds an array of strings as values. Each string represents a statement likely related to product updates or organizational changes, such as "The product update addresses reported bugs and introduces several enhancements," "The leadership team has approved the expansion of our global IT support network," and "The internal review process is underway." The context suggests that this output may pertain to a software application or service that retrieves and displays matched items based on certain criteria, possibly related to product management or system updates. There is no visible code or specific programming constructs; the focus is on the content of the output indicating recent company activities or software version changes.```

**Post ID:** 590905

And for Question-9, I tried 80 prompts and I tried every different way, but I am not getting a Yess from the LLM. Can you please say how to proceed for that? Thank You

**Post ID:** 590914

import numpy as np
def most_similar(embeddings):
words = list(embeddings.keys())
dot_product_df = 
for i in words:
for j in words:
dot_product_df.append(np.dot(embeddings[i], embeddings[j]))
return max(dot_product_df)
print(most_similar({“I experienced issues during checkout.”:[-0.10228022187948227,-0.057035524398088455,-0.03200617432594299,-0.1569785177707672,-0.11162916570901871,-0.017878107726573944,-0.06209372356534004,0.18209508061408997,-0.0027645661029964685,0.12928052246570587,0.17609500885009766,-0.11846645176410675,-0.2356770783662796,0.05536108836531639,-0.07102405279874802,0.21265356242656708,-0.03218059614300728,0.2578633725643158,-0.11707108467817307,0.23163051903247833,0.1780485212802887,0.17972294986248016,0.05302385240793228,0.06889612227678299,-0.13932715356349945,-0.14428070187568665,0.17149029672145844,-0.25590986013412476,0.22311879694461823,-0.06321001797914505,0.019430451095104218,-0.1841881275177002,0.14204810559749603,-0.09976856410503387,-0.17888574302196503,0.07890786230564117,-0.008947774767875671,0.08065207302570343,0.3131197988986969,-0.009226848371326923,-0.1460946649312973,0.16423441469669342,0.024331670254468918,0.055779699236154556,-0.08274511992931366,0.2355375438928604,0.06582632660865784,-0.13674572110176086,-0.003309630323201418,0.008324221707880497],“The return process was easy and hassle-free.”:[-0.13446587324142456,0.02539028227329254,-0.17796370387077332,-0.011354454793035984,-0.04654333367943764,0.15717478096485138,0.07627015560865402,0.22960494458675385,0.001469996408559382,0.1792878359556198,0.05905640497803688,-0.17240233719348907,-0.10083285719156265,-0.08322186022996902,0.00746894720941782,-0.013042726553976536,-0.13718034327030182,0.02444683574140072,-0.07938187569379807,0.04598057642579079,0.0351557731628418,0.1953098624944687,0.011594453826546669,-0.13267828524112701,-0.13718034327030182,-0.14909756183624268,-0.1765071451663971,-0.16776786744594574,-0.11473626643419266,-0.1473761796951294,0.15889616310596466,-0.12354176491498947,0.18882159888744354,-0.040121279656887054,0.18749746680259705,0.16869474947452545,-0.0547860711812973,0.13943137228488922,0.08275841921567917,-0.012976519763469696,0.026582002639770508,0.2568821310997009,0.13314174115657806,-0.08845219761133194,0.025257868692278862,0.35831084847450256,-0.22483806312084198,-0.005697916727513075,0.2899854779243469,0.1855112612247467],“Fast shipping and great service.”:[-0.1079404279589653,0.020684150978922844,-0.30074435472488403,0.11729881167411804,0.13952496647834778,-0.018052106723189354,-0.21843314170837402,0.13527116179466248,-0.09257353842258453,-0.09384968131780624,0.11293865740299225,-0.03900212049484253,-0.059287477284669876,-0.1008152961730957,-0.019155437126755714,-0.007078605704009533,-0.02967032417654991,0.03711449354887009,-0.18302017450332642,0.20056714117527008,0.09076566994190216,0.02584189549088478,0.0943814069032669,-0.03799184039235115,-0.25246360898017883,-0.1235731765627861,0.028952494263648987,-0.309251993894577,0.021375395357608795,-0.22204887866973877,0.2159872055053711,-0.11921302229166031,0.21928390860557556,-0.11432114243507385,0.017453914508223534,0.10065577924251556,-0.04200637340545654,0.17493793368339539,0.1322934925556183,0.17025874555110931,-0.15271177887916565,0.004682514350861311,0.2531017065048218,0.11580997705459595,0.014688937924802303,-0.11176885664463043,-0.292662113904953,-0.0397731214761734,0.13729171454906464,0.027570005506277084],“The payment process was secure and efficient.”:[-0.04701301082968712,-0.20167900621891022,-0.22099372744560242,-0.05536692962050438,0.03149012476205826,0.049234796315431595,-0.02104772813618183,0.1948062777519226,0.004417652729898691,-0.11180031299591064,0.25831976532936096,-0.1503705382347107,-0.14669717848300934,-0.15866521000862122,0.07601473480463028,-0.03744451329112053,-0.1256050169467926,-0.004232503939419985,-0.19717617332935333,-0.07204513996839523,0.07216363400220871,0.23426520824432373,0.005728506948798895,-0.08347994089126587,-0.09248558431863785,-0.16150909662246704,-0.10895642638206482,-0.3507460951805115,-0.1641159951686859,-0.1695667803287506,0.21696490049362183,-0.1385210007429123,0.196346715092659,-0.025669043883681297,-0.07808840274810791,-0.0023291732650250196,-0.03386003151535988,0.14717115461826324,0.06078808754682541,-0.0358448289334774,-0.1290413737297058,0.17335861921310425,-0.08033981174230576,0.1285673975944519,-0.040229152888059616,0.11511818319559097,0.10747523605823517,-0.3336827754974365,0.09313730895519257,-0.002255113562569022],“Customer service resolved my issue quickly.”:[-0.27243417501449585,-0.08034132421016693,-0.3335980772972107,0.03278002515435219,-0.0688093826174736,-0.11652996391057968,-0.13710907101631165,0.2432539016008377,0.07779283076524734,0.0949951708316803,0.1365993618965149,-0.05979407951235771,-0.17151375114917755,-0.040170662105083466,0.12054384499788284,0.10894818603992462,-0.1374913454055786,-0.008736561983823776,-0.2501348555088043,0.040648505091667175,0.20974119007587433,0.021232154220342636,0.1484498679637909,-0.07186757773160934,-0.26733720302581787,0.24248935282230377,-0.04475795477628708,-0.1304829716682434,-0.11914216727018356,-0.2516639530658722,0.16577963531017303,-0.1684555560350418,-0.08875136077404022,-0.1995472013950348,-0.10072928667068481,0.1209898293018341,0.11015872657299042,-0.053359128534793854,0.16705389320850372,0.0013867400120943785,-0.018269527703523636,0.014486604370176792,0.08320838212966919,0.06033563241362572,-0.07224985212087631,0.09869049489498138,-0.021837422624230385,0.1448819786310196,0.10996758937835693,0.058328691869974136]}))

**Post ID:** 590915

Jayeshbansal:

print(most_similar({“I experienced issues during checkout.”:[-0.10228022187948227,-0.057035524398088455,-0.03200617432594299,-0.1569785177707672,-0.11162916570901871,-0.017878107726573944,-0.06209372356534004,0.18209508061408997,-0.0027645661029964685,0.12928052246570587,0.17609500885009766,-0.11846645176410675,-0.2356770783662796,0.05536108836531639,-0.07102405279874802,0.21265356242656708,-0.03218059614300728,0.2578633725643158,-0.11707108467817307,0.23163051903247833,0.1780485212802887,0.17972294986248016,0.05302385240793228,0.06889612227678299,-0.13932715356349945,-0.14428070187568665,0.17149029672145844,-0.25590986013412476,0.22311879694461823,-0.06321001797914505,0.019430451095104218,-0.1841881275177002,0.14204810559749603,-0.09976856410503387,-0.17888574302196503,0.07890786230564117,-0.008947774767875671,0.08065207302570343,0.3131197988986969,-0.009226848371326923,-0.1460946649312973,0.16423441469669342,0.024331670254468918,0.055779699236154556,-0.08274511992931366,0.2355375438928604,0.06582632660865784,-0.13674572110176086,-0.003309630323201418,0.008324221707880497],“The return process was easy and hassle-free.”:[-0.13446587324142456,0.02539028227329254,-0.17796370387077332,-0.011354454793035984,-0.04654333367943764,0.15717478096485138,0.07627015560865402,0.22960494458675385,0.001469996408559382,0.1792878359556198,0.05905640497803688,-0.17240233719348907,-0.10083285719156265,-0.08322186022996902,0.00746894720941782,-0.013042726553976536,-0.13718034327030182,0.02444683574140072,-0.07938187569379807,0.04598057642579079,0.0351557731628418,0.1953098624944687,0.011594453826546669,-0.13267828524112701,-0.13718034327030182,-0.14909756183624268,-0.1765071451663971,-0.16776786744594574,-0.11473626643419266,-0.1473761796951294,0.15889616310596466,-0.12354176491498947,0.18882159888744354,-0.040121279656887054,0.18749746680259705,0.16869474947452545,-0.0547860711812973,0.13943137228488922,0.08275841921567917,-0.012976519763469696,0.026582002639770508,0.2568821310997009,0.13314174115657806,-0.08845219761133194,0.025257868692278862,0.35831084847450256,-0.22483806312084198,-0.005697916727513075,0.2899854779243469,0.1855112612247467],“Fast shipping and great service.”:[-0.1079404279589653,0.020684150978922844,-0.30074435472488403,0.11729881167411804,0.13952496647834778,-0.018052106723189354,-0.21843314170837402,0.13527116179466248,-0.09257353842258453,-0.09384968131780624,0.11293865740299225,-0.03900212049484253,-0.059287477284669876,-0.1008152961730957,-0.019155437126755714,-0.007078605704009533,-0.02967032417654991,0.03711449354887009,-0.18302017450332642,0.20056714117527008,0.09076566994190216,0.02584189549088478,0.0943814069032669,-0.03799184039235115,-0.25246360898017883,-0.1235731765627861,0.028952494263648987,-0.309251993894577,0.021375395357608795,-0.22204887866973877,0.2159872055053711,-0.11921302229166031,0.21928390860557556,-0.11432114243507385,0.017453914508223534,0.10065577924251556,-0.04200637340545654,0.17493793368339539,0.1322934925556183,0.17025874555110931,-0.15271177887916565,0.004682514350861311,0.2531017065048218,0.11580997705459595,0.014688937924802303,-0.11176885664463043,-0.292662113904953,-0.0397731214761734,0.13729171454906464,0.027570005506277084],“The payment process was secure and efficient.”:[-0.04701301082968712,-0.20167900621891022,-0.22099372744560242,-0.05536692962050438,0.03149012476205826,0.049234796315431595,-0.02104772813618183,0.1948062777519226,0.004417652729898691,-0.11180031299591064,0.25831976532936096,-0.1503705382347107,-0.14669717848300934,-0.15866521000862122,0.07601473480463028,-0.03744451329112053,-0.1256050169467926,-0.004232503939419985,-0.19717617332935333,-0.07204513996839523,0.07216363400220871,0.23426520824432373,0.005728506948798895,-0.08347994089126587,-0.09248558431863785,-0.16150909662246704,-0.10895642638206482,-0.3507460951805115,-0.1641159951686859,-0.1695667803287506,0.21696490049362183,-0.1385210007429123,0.196346715092659,-0.025669043883681297,-0.07808840274810791,-0.0023291732650250196,-0.03386003151535988,0.14717115461826324,0.06078808754682541,-0.0358448289334774,-0.1290413737297058,0.17335861921310425,-0.08033981174230576,0.1285673975944519,-0.040229152888059616,0.11511818319559097,0.10747523605823517,-0.3336827754974365,0.09313730895519257,-0.002255113562569022],“Customer service resolved my issue quickly.”:[-0.27243417501449585,-0.08034132421016693,-0.3335980772972107,0.03278002515435219,-0.0688093826174736,-0.11652996391057968,-0.13710907101631165,0.2432539016008377,0.07779283076524734,0.0949951708316803,0.1365993618965149,-0.05979407951235771,-0.17151375114917755,-0.040170662105083466,0.12054384499788284,0.10894818603992462,-0.1374913454055786,-0.008736561983823776,-0.2501348555088043,0.040648505091667175,0.20974119007587433,0.021232154220342636,0.1484498679637909,-0.07186757773160934,-0.26733720302581787,0.24248935282230377,-0.04475795477628708,-0.1304829716682434,-0.11914216727018356,-0.2516639530658722,0.16577963531017303,-0.1684555560350418,-0.08875136077404022,-0.1995472013950348,-0.10072928667068481,0.1209898293018341,0.11015872657299042,-0.053359128534793854,0.16705389320850372,0.0013867400120943785,-0.018269527703523636,0.014486604370176792,0.08320838212966919,0.06033563241362572,-0.07224985212087631,0.09869049489498138,-0.021837422624230385,0.1448819786310196,0.10996758937835693,0.058328691869974136]}))


```Image was here: The image features a code snippet in a Python environment, likely within a coding platform or integrated development environment (IDE) such as Jupyter Notebook or an online coding editor. It contains a for loop where `dot_product_df.append` is invoked to calculate dot products of embeddings indexed by `i` from a presumed `embeddings` list or array. The function returns the maximum value from the computed dot product DataFrame. A `print` statement follows, displaying the result of a `most_similar` function call with a specific string related to experiencing issues during checkout. The output appears to consist of a list of numerical values, possibly representing similarity scores or embeddings, indicating the context of similarity-based retrieval from an embedding space. The text at the bottom indicates a type error message, specifically `"TypeError: 'runPython'_1 is not a function"`, suggesting a problem with the execution of a function in the Python script. The image illustrates a technical discussion involving machine learning embeddings, similarity computations, and potential debugging related to function calls.```image1677×303 30.6 KB

**Post ID:** 590918

```Image was here: The image depicts a portion of a web interface related to API development or testing, specifically focusing on configuring an API endpoint. It shows a prompt asking for the API URL with an example provided: `http://127.0.0.1:8000/execute`. Below the input field, there's an error message stating "TypeError: Failed to fetch," indicating a problem with making the request to the specified URL. Additional instructional text elaborates that a GET request to this URL should include the query parameter `?q=...`, containing a task, followed by a note that it will verify the response against the expected one, emphasizing that the arguments must align with the function definition. The interface appears to be part of a tool for testing API functionality.```image1592×233 19.9 KB

**Post ID:** 590921

```Image was here: The image showcases two distinct sections: on the left, a web interface from a technical forum, possibly highlighting a task related to API request handling with a focus on JSON payloads and methods like POST. There is text discussing the importance of CORS configuration, emphasizing the requirement for allowing OPTIONS and POST methods and suggesting a potential API URL endpoint: `http://127.0.0.1:8000/similarity`. Instructions to send a POST request to this URL with a JSON body containing documents are also present. On the right, a development environment (likely Postman or a similar API testing tool) shows a recent API request. The request is to the URL `http://127.0.0.1:8000/similarity` with a POST method and a JSON structure in the body, which includes keys like "contents of document" and corresponding string values. Below the request, the console output indicates a successful response with a status code of 200 and a payload containing cached responses. The terminal logs show a successful application start with HTTP server running, indicating backend processing of the API calls, relevant to a potential Flask or FastAPI application structure.```image1915×999 143 KB
@carlton @Jivraj  Sir please look at the err on Q7.I am able to run on my system and getting the desired json but its not working in the portal. Today is the deadline sir please help me out!
I m attaching my codes:
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
from fastapi.middleware.cors import CORSMiddleware
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["OPTION","POST"],  
    allow_headers=["*"],
)

class SimilarityRequest(BaseModel):
    docs: List[str]
    query: str

def clean_text(text: str):
    """Clean text by lowering case, removing punctuation, and extra spaces."""
    text = text.lower()  
    text = re.sub(r'\s+', ' ', text)  
    text = re.sub(r'[^\w\s]', '', text)  
    return text

@app.post("/similarity")
async def find_similar_docs(request: SimilarityRequest):
    try:
        cleaned_docs = [clean_text(doc) for doc in request.docs]
        cleaned_query = clean_text(request.query)

        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(cleaned_docs + [cleaned_query])

        query_vector = tfidf_matrix[-1]
        doc_vectors = tfidf_matrix[:-1]
        similarity_scores = cosine_similarity(query_vector, doc_vectors)[0]

        top_indices = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)[:3]
        matched_docs = [request.docs[i] for i in top_indices]

        return {"matches": matched_docs}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/execute")
async def execute_query(q: str):
    return {"message": f"Executing query: {q}"}

**Post ID:** 590922

Hi,
I’m sorry if I’m asking an unrelated question, But I’m very confused with the concept of generating the token from https://platform.openai.com/api-keys
Could any one suggest the step by step process? I couldn’t able to find that similar question asked by anyone since the conversations are vast.
Please guide me on this. Also do i need to use my personal mail id or iitm mail id for accessing this token

**Post ID:** 590926

yes you have to use your IITM email id . Use this link and login you will get your token:
https://aiproxy.sanand.workers.dev/

**Post ID:** 590940

```Image was here: The image features an input interface related to API endpoint configuration, specifically asking for an API URL for an implementation. It displays an example URL: `http://127.0.0.1:8000/execute`, which indicates a local server address. Below this, there is an error message stating "SyntaxError: '[object Object]' is not valid JSON," suggesting that there was an attempt to process a JSON object that failed due to a syntax error. The presence of the error message implies that the context may involve debugging an API request or response handling in a web application or service. This scenario likely involves JavaScript or a similar language that handles JSON, indicating the usage of asynchronous programming or API calls in a web framework.```image1572×133 10.7 KB

**Post ID:** 590970

The error shows your code is getting wrong answers for the test cases. I looked into your code and noticed that you are using sklearn (I think which is not required in this case). Just get embedding vector for each document content and query by passing a valid POST request to http://aiproxy.sanand.workers.dev/openai/v1/embeddings with required headers. And, then calculate similarity_scores simply using
\cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| |\mathbf{B}|}
which in python syntax is-
np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

**Post ID:** 590974

Sir, Regarding the embedding questions, I had posted earlier. Now, I am writing the error I faced. I tried to use the OpenAI API, but I am getting the error as “The Maximum Quota has reached”. I tried using 5 new API Keys from OpenAI, from 5 different accounts. So, I had to use SentenceTransformers, Alibaba gte model. So, as the model has changed, I think so it is expecting answer as got from OpenAI Model, but as I used Alibaba gte model, I am getting different result. Can you please explain how to solve this issue? This will be helpful in my future codes. I could do chat requests but it is not giving output for Embedding requests, I tried it multiple times with multiple different keys.Thank You
```Image was here: The image displays a JSON-like structure presenting an error message, indicating an exceeded usage limit. The error message states: "You exceeded your current quota, please check your plan and billing details." This suggests a context in which a user is likely interacting with an API or a service that enforces usage quotas, commonly found in cloud-based platforms or software services. The output appears to be generated from a console or terminal interface, likely in a programming environment or during a debugging session, where the user is attempting to perform an operation that requires checking their billing or usage settings due to limits on resource usage. The format suggests technical interactions typical within software engineering contexts, potentially aligning with platforms that require API key management, such as cloud services or subscription-based software products.```

**Post ID:** 590975

This is my code for the 7th question of finding similarities. This code, I tried on my own, but it is showing Incorrect Matches. I think so it is due to the Aliababa GTE Model. Please correct me if I have gone wrong anywhere. Thank You
from fastapi import FastAPI, Query
import httpx
from typing import List
import numpy as np
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from sentence_transformers import SentenceTransformer
from sentence_transformers.util import cos_sim

model = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["OPTIONS", "POST"],  # Allows all methods (GET, POST, OPTIONS, etc.)
    allow_headers=["*"],  # Allows all headers
)

class similarity1(BaseModel):
    docs: list[str]
    query: str
@app.post("/similarity")
async def similarity(similarity1: similarity1):
    docs = similarity1.docs
    query = similarity1.query
    results_docs = model.encode(docs)
    results_query = model.encode(query)
    similarities = {}
    output = []
    for i in range(len(results_docs)):
        c = np.dot(results_docs[i], results_query) / (np.linalg.norm(results_docs[i])*np.linalg.norm(results_query))
        similarities[c] = docs[i]
    k = sorted(list(similarities.keys()))
    for i in k[::-1][:3]:
        output.append(similarities[i])
    return {"matches" : output}
if __name__ == "__main__":
  (uvicorn.run(app))

**Post ID:** 590987

```Image was here: The image contains a user interface belonging to a software application, displaying a session that has ended on "Wed, 5 Feb, 2025, 11:59 pm IST." The top section indicates a score of "0" and features buttons labeled "Check all" and "Save." Below, there is a message stating that the user is logged in as "24f2005437@ds.study.iitm.ac.in," accompanied by a "Logout" button. The lower part of the interface highlights recent saves, showing two entries from "5/2/2025": one loaded at "11:20:33 pm" with a score of "6," and another from "11:20:20 pm" with the same score. The overall layout suggests functionality typical of a web-based educational or collaborative software platform, possibly related to coding or technical discussions, given the context of the user details and nature of "saves."```image925×544 25.9 KB
i submitted the assignment on time but i am still getting assignment not submitted. And it also show zero marks. Same thing happened with graded assignment 2. @Jivraj

**Post ID:** 591016

@Jivraj @carlton
I have submitted ga3 still showing not submitted , why sir?
```Image was here: The image displays a web interface for an online course titled "TDS 2025 Jan GA3 - Large Language Models". The visible content includes instructional text regarding course participation and question submissions. Specifically, sections show "Instructions" for students, mentioning the review process for exam answers, including support for query submissions. Below the instructional area is a feedback section labeled "Recent saves," detailing user actions within the course. The bottom part of the interface indicates progress on "Module 3: Large Language Models" and presents a summary of grades for "Assignment 3," noting a peer average and median score, alongside a status showing that the assignment has not been submitted. The interface appears to facilitate educational assessments with emphasis on user interaction, grading transparency, and course material related to large language models.```Untitled design1414×2000 314 KB

**Post ID:** 591017

@Jivraj @carlton
please reply why its showing not submitted in ga3 but i have submitted that
```Image was here: The image displays a web interface for an educational platform, specifically showing a submission portal for "TDS 2025 Jan GA3 - Large Language Models." The top section includes instructions for an assignment, alerting users to engage with queries related to the subject matter. Below this, there is an area for participating in discussions. The main body showcases details about "Module 3: Large Language Models," including the status of "Graded Assignment 3," with fields indicating "Your Score," "Peer Average," and "Median Score." The assignment was due on “5 Feb 2023” and is marked as "Not Submitted." The interface suggests interaction with an online learning system, potentially linked to educational technology, highlighting engagement with topics in artificial intelligence and machine learning.```Untitled design1414×2000 314 KB

**Post ID:** 591060

@carlton, @Jivraj
Both the api based questions i am unable to get the output it always says bad request
```Image was here: The image displays a code snippet within a Python file named `main.py`, located in the `app` directory of a project titled `GA3_Q8`. The visible code defines a function `parse_query(query: str)` that uses regular expressions to match patterns in a query string, specifically for processing scheduling and expense balance requests. It includes conditional structures that check for matches like "Arrange meeting" and "Show expenses," indicating a context related to scheduling system functionalities. Below the code, a terminal output section shows a series of log messages indicating errors: an HTTP 404 Not Found error for a POST request, stating "Query format did not match any predefined patterns." The terminal also notes a bad request while attempting to execute a GET request for scheduling meetings. The environment suggests this is within a development context, likely using VSCode or a similar IDE, and the project may utilize Python libraries for regex operations. File names present in the structure include `requirements.txt`, which typically contains dependencies, indicating possible use of external libraries.```Screenshot 2025-01-30 at 3.55.56 PM1920×1200 219 KB
```Image was here: The image shows a web-based coding environment featuring an exam interface focused on function calling in a programming context. Prominently displayed is a JSON object containing keys "name" and "arguments," where "name" is set to "get_ticket_status" and "arguments" contains a stringified JSON with a "ticket_id" of 83742. Below this, a message advises the user to enable CORS (Cross-Origin Resource Sharing) to allow GET requests from any origin. The user is prompted to specify the API endpoint for their implementation, with an example provided. An attempt to access the suggested URL (http://127.0.0.1:18000/execute) results in an error message indicating "Failed to fetch: Bad Request." The bottom of the interface contains an option to get an LLM (Large Language Model) to respond to the task indicated by "1 mark." The web browser’s address bar shows a site specific to coding assessments, indicating a test environment likely for a software engineering or programming course.```Screenshot 2025-01-30 at 3.57.17 PM2048×1280 284 KB
all other questions i have finished. even in Ga2 all these api and flask creates a lot of issues. if there is any complete guide to understand this also pls help us.

**Post ID:** 588065

Hi @23ds1000022 ,
Check network tab, there check for response of http://127.0.0.1:8000/api request.

**Post ID:** 591063

I have counted the number of tokens in gpt-4o-mini but when I was entering the answer in portal it was showing incorrect please take a look and provide a solution for it .
```Image was here: The image displays the OpenAI Platform interface, specifically within the context of an API usage console. It shows a JSON-like output that appears to include encoded tokens generated from a language model, with visible segments such as "Tokens: 406" and "Characters: 625," indicating metrics related to the processing of user input. There are multiple model options available, including "GPT-4o & GPT-4 mini," "GPT-3.5 & GPT-4," and "GPT-3 (Legacy)." The displayed data features alphanumeric strings that likely represent identifiers or parameters associated with API responses or model outputs. UI elements such as "Clear," "Show example," and links to documentation and an API reference are visible, suggesting that this interface is designed for testing and interacting with OpenAI's language models in a programming or software development context.```Screenshot 2025-02-01 1806272458×1183 284 KB

**Post ID:** 588807

There are few more tokens for the user prompt, I think if you add 7 or 8 then you would get correct answer.
Other way to do this question is send a request to anand sir’s aiproxy and in response you will get number of input tokens.

**Post ID:** 588820

I inspected the JavaScript code of this website, I saw that the answer took my input and added 7 to it, why is it programmed this way? Even if I were to use the AI proxy that was given shouldn’t the number of tokens remain unaffected?

**Post ID:** 588839

When you send request to openai through anand sir’s proxy it takes some tokens for user prompt.
When you use tokenizer from openai’s webpage then it doesn’t take care of that.

**Post ID:** 591066

How to answer the 3rd question in ga 3 i have to no clue (tired inspecting its html pages)

**Post ID:** 590399

drive.google.com



2025-02-04 03-50-48.mkv
Google Drive file.

**Post ID:** 591069

Q3 how to generate answer box ,I am not able to do it. kindly guide me with that.
Q7 & Q8 in these questions the problem is the same my app couldn’t fetch the details from the file.
`from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List
import openai
from fastapi.responses import JSONResponse
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Initialize FastAPI app
app = FastAPI()

# Add CORSMiddleware with more restrictive settings
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Allow only this specific origin
    allow_credentials=True,
    allow_methods=["POST", "OPTIONS"],  # Allow only POST and OPTIONS methods
    allow_headers=["Content-Type", "Authorization"],  # Allow only specific headers
)

# OpenAI API key (use your own key)
openai.api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJlbWFpbCI6IjI0ZjIwMDY3NDlAZHMuc3R1ZHkuaWl0bS5hYy5pbiJ9.tMJtqZrzRqREY7E3wsFMd9PkElXEbRBpCkb533ORGEU'

# Request body model for /similarity endpoint
class SimilarityRequest(BaseModel):
    docs: List[str]
    query: str

# Function to get embeddings (using OpenAI API)
def get_embedding(text: str):
    response = openai.Embedding.create(
        model="text-embedding-ada-003",  # Use the correct model
        input=text
    )
    return response['data'][0]['embedding']

# POST /similarity endpoint
@app.post("/similarity")
async def similarity(request: SimilarityRequest):
    docs = request.docs
    query = request.query
    query_embedding = get_embedding(query)
    doc_embeddings = [get_embedding(doc) for doc in docs]
    
    # Cosine similarity
    similarities = [cosine_similarity([query_embedding], [doc_embedding])[0][0] for doc_embedding in doc_embeddings]
    ranked_docs = [docs[i] for i in np.argsort(similarities)[::-1]]
    
    return JSONResponse(content={"matches": ranked_docs[:3]})

# Optionally, handle requests to the root (GET /)
@app.get("/")
async def root():
    return {"message": "Welcome to the similarity API!"}
`

and for Q8
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Dict, Any
import re

# Create the FastAPI app
app = FastAPI()

# CORS configuration to allow any origin
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers
)
def get_ticket_status(ticket_id: int) -> Dict[str, Any]:
    # Mock response for illustration purposes
    return {"ticket_id": ticket_id, "status": "open"}

def schedule_meeting(date: str, time: str, meeting_room: str) -> Dict[str, Any]:
    # Mock response for illustration purposes
    return {"date": date, "time": time, "meeting_room": meeting_room, "status": "scheduled"}

def get_expense_balance(employee_id: int) -> Dict[str, Any]:
    # Mock response for illustration purposes
    return {"employee_id": employee_id, "balance": 1000.0}

def calculate_performance_bonus(employee_id: int, current_year: int) -> Dict[str, Any]:
    # Mock response for illustration purposes
    return {"employee_id": employee_id, "current_year": current_year, "bonus": 500.0}

def report_office_issue(issue_code: int, department: str) -> Dict[str, Any]:
    # Mock response for illustration purposes
    return {"issue_code": issue_code, "department": department, "status": "reported"}
import re

def extract_parameters(query: str) -> Dict[str, Any]:
    """Extract parameters from the query string."""
    # Convert the query to lowercase for case-insensitive matching
    query = query.strip().lower()

    if match := re.match(r"what is the status of ticket (\d+)\?", query):
        return {
            "name": "get_ticket_status",
            "arguments": {"ticket_id": int(match.group(1))}
        }
    elif match := re.match(r"schedule a meeting on (\d{4}-\d{2}-\d{2}) at (\d{2}:\d{2}) in (.+)\.", query):
        return {
            "name": "schedule_meeting",
            "arguments": {
                "date": match.group(1),
                "time": match.group(2),
                "meeting_room": match.group(3)
            }
        }
    elif match := re.match(r"show my expense balance for employee (\d+)\.", query):
        return {
            "name": "get_expense_balance",
            "arguments": {"employee_id": int(match.group(1))}
        }
    elif match := re.match(r"calculate performance bonus for employee (\d+) for (\d{4})\.", query):
        return {
            "name": "calculate_performance_bonus",
            "arguments": {
                "employee_id": int(match.group(1)),
                "current_year": int(match.group(2))
            }
        }
    elif match := re.match(r"report office issue (\d+) for the (\w+) department\.", query):
        return {
            "name": "report_office_issue",
            "arguments": {
                "issue_code": int(match.group(1)),
                "department": match.group(2)
            }
        }
    return {}

@app.get("/execute")
async def execute_query(q: str):
    # Extract the function name and arguments from the query
    result = extract_parameters(q)
    
    if not result:
        return JSONResponse(content={"error": "No matching function found for the query"}, status_code=400)
    
    # Call the respective function
    func_name = result["name"]
    arguments = result["arguments"]
    
    # Call the function dynamically based on func_name
    if func_name == "get_ticket_status":
        response = get_ticket_status(**arguments)
    elif func_name == "schedule_meeting":
        response = schedule_meeting(**arguments)
    elif func_name == "get_expense_balance":
        response = get_expense_balance(**arguments)
    elif func_name == "calculate_performance_bonus":
        response = calculate_performance_bonus(**arguments)
    elif func_name == "report_office_issue":
        response = report_office_issue(**arguments)
    
    # Return the response in the requested format
    return JSONResponse(content={"name": func_name, "arguments": arguments}, status_code=200)

Please kindly guide me with these problems as I am trying to do it since last 3 days. I am exhaust now, Please help me with this. @Jivraj , @carlton , @Saransh_Saini

**Post ID:** 590401

Hi Sakshi



 Sakshi6479:

Q3 how to generate answer box ,I am not able to do it. kindly guide me with that.




drive.google.com



2025-02-04 03-50-48.mkv
Google Drive file.






For question 7



 Sakshi6479:

import openai



You won’t be able to send request through openai python module, here is one example how you would make a request
headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {OPENAI_API_KEY}'
}

json_data = {
    'model':'gpt-4o-mini',
    'messages':[
        {
            'role':'user',
            'content':'What is 2+2?'
        }
    ]
}
r = httpx.post('http://aiproxy.sanand.workers.dev/openai/v1/chat/completions', headers = headers, json = json_data, timeout=10.0)

You would need to use professor Anand’s proxy or some other api key through which request can be made.
Url’s for free api keys:

AI Proxy
OpenAI GPT-4o · GitHub Models

The way to use api’s is demonstrated in live sessions, also refer to this documentation sanand0/aiproxy: Authorizing proxy for LLMs.

For question 8, you’ll need to use OpenAI’s function calling feature and identify which function needs to be called and arguments to be used, we discussed in last Friday’s session on functions like order and cancel_order.
Kind regards

**Post ID:** 591072

Hello sir,
While working on this question, I’m encountering this problem. It looks like the request is being made successfully (and I verified it by a POST request via Postman ), however while submitting my URL at the assignment portal, I’m getting an error.
```Image was here: The image displays console output from a server or development environment, indicating an API interaction. It shows an INFO log that includes an IP address (`127.0.0.1`) and a port (`59423`) with HTTP method calls, specifically "OPTIONS" and "POST" requests to the `/similarity` endpoint, both returning a status code of `200 OK`. The log indicates a successful collection reset, creation of a new collection named `documents`, and the addition of 10 new documents to a database. A query is performed regarding internal training for addressing cybersecurity challenges, which yields found matches in the form of two text strings: one about employee training on cybersecurity best practices and another regarding the implementation of automated testing protocols by a quality assurance team. The context suggests the use of a backend server potentially in a Flask or similar framework for handling document storage and retrieval.```image1550×207 22.2 KB
```Image was here: The image displays a console output or code editor interface referencing a local API endpoint. A URL is shown: `http://127.0.0.1:8000/similarity`, suggesting a service related to calculating similarity metrics, possibly for a machine learning model or data processing application. Below the URL, there is an error message indicating "Got incorrect matches," accompanied by text relating to employee training on cybersecurity best practices and updates to an operational handbook, implying a context of automated testing or content validation. The overall scenario suggests a debugging activity linked to an API testing environment, indicating tools or systems involving local server interactions, likely within a software development or data science context.```image1288×138 7.33 KB
I even tried deploying on a public URL using render. My guess is there is a formatting issue or it’s not sorting correctly based on the similarity score and not returning the top 3.
Would appreciate if I can get some clarity on the same
Thanks and Regards
Shalini

**Post ID:** 590400

Hello, I think the format of the response body should be like: { “matches” : [ “ABC”, “ABC”, “ABC”]}. I think it is because of your formatting issue.
```Image was here: The image depicts a Postman interface configured to make a POST request to the URL `http://127.0.0.1:18000/similarity`. The interface shows no authorization type selected, indicating that the request does not require authentication. In the Body section, the format is set to JSON, with content displaying an array under the key `"matches"`. The array contains three strings: "FastAPI is great for APIs.", "Embedding models improve NLP.", and "Machine learning is evolving." An HTTP status code of 200 OK is displayed in green, suggesting a successful request. The console output reflects response details, including the execution time of 17.26 ms and the size of the response of 232 bytes. The overall context indicates the user is likely testing an API endpoint relevant to NLP and machine learning applications using FastAPI.```Screenshot_20250204_032923991×615 43.7 KB
I had used (well gpt) the below two decorators to format:
class SearchRequest(BaseModel):
    docs: List[str]  # The list of documents to search through
    query: str       # The search query string

class SearchResponse(BaseModel):
    matches: List[str]  # The list of matched documents

.........

@app.post("/similarity", response_model=SearchResponse)


.........

return SearchResponse(matches=sorted_matches[:3])

It basically checks the Request  and Response formatting. This worked for me. Hope it helps. And thanks btw for mentioning using POSTMAN, as I had never used it before, so it clicked in my mind after reading your post only that I can basically debug using POSTMAN. Thank you for that

**Post ID:** 590402

{
  "matches": ["Contents of document 3", "Contents of document 1", "Contents of document 2"]
}

Check if your response is in this format.
kind regards
Jivraj

**Post ID:** 591079

Does the final submission get graded, or is the highest-scoring submission considered?
I’m facing an issue where my score dropped from 8 to 6.5 when I checked all the answers one last time before submitting. I suspect the drop is due to the 3rd and 7th questions.
```Image was here: The image displays a user interface section titled "Recent saves," indicating a record of saved states or sessions along with corresponding timestamps and scores. Three entries are visible, each featuring a "Reload" button. The timestamps reflect dates from February 5, 2025, with specific times listed: 11:59:18 PM, 11:30:37 PM, and 10:44:08 PM. The scores associated with these saves are 6.5, 8, and 6.5 respectively, suggesting a scoring system likely related to performance or relevance metrics. The design uses a dark background with light-colored text and buttons, possibly indicative of a web application or software tool focused on session management or automated retrieval. The context implies ongoing development or testing activities where recent saves are monitored for evaluation or debugging purposes.```Screenshot 2025-02-06 001446810×296 14.8 KB

**Post ID:** 591077

```Image was here: The image displays a web interface for an exam titled "TDS 2025 Jan GA3 - Large Language Models," with a timestamp indicating the exam ended on February 5, 2025, at 11:59 PM IST. Prominently featured are the instructions for participants, emphasizing the importance of learning the required material and outlining operational steps: users should click "Check" to verify answers, "Save" to submit responses (with a note that multiple saves are permitted and only the last submission will be evaluated), and possible issues with browser compatibility. The text explicitly states that participants may utilize various resources, including tools like ChatGPT, and encourages exploring the code for additional hints, highlighting a flexible and resourceful approach to the exam. The layout appears user-friendly, featuring navigation elements for scoring and saving answers, and visually includes cartoon eyes next to the "Instructions" heading, contributing to a less formal and engaging design. No specific programming languages or code snippets are present, but the context suggests a focus on leveraging technology and online tools for exam preparation.```Screenshot 2025-02-06 at 11.27.07 am2570×1136 358 KB
The score drops because some questions may require you to either keep a server turned on or some dynamic changes may occur for some questions (The dynamic changes are intentional in some questions, in order to get students to learn by doing. So if you solved everything and the score is the maximum… just make that your last submission. The score you see is the score you will get for your last submission).
If you want check a question without submitting. Then just use the check button instead. But your last submission is whats scored.

**Post ID:** 591133

Same problem with my submission

**Post ID:** 591272

```Image was here: The image presents a bar graph titled "GA3 Active Score Distribution," depicting a distribution of scores segmented into ranges: (0, 10], (10, 20], (20, 30], (30, 40], (40, 50], (50, 60], (60, 70], (70, 80], (80, 90], and (90, 100]. Each score range is represented by a blue bar enumerating the count of active scores that fall within that range. The highest count, noted as "249," is displayed in the range (90, 100], with the total number of student submissions indicated as "1,001" in a boxed label. The Y-axis quantifies the "Active Score Count," while the X-axis specifies the score ranges. No specific technologies or coding environments are present, but the context relates to performance metrics possibly used in educational or assessment platforms.```Screenshot 2025-02-06 at 8.11.15 pm3444×1394 188 KB
For those that are interested.

**Post ID:** 591894

sir why the GA marks is not being reflected in the course page. We are getting a sign of non submission.
Is there any way getting the score.

**Post ID:** 592815

Hello sir ,I find a issue with submission of GA4.  Actually i submitted ga3 on “Technical Assessment”        with full marks but in the course >grade portal it is saying it is not submitted. what’s the issue is this?

**Post ID:** 593680

I also have same problem

**Post ID:** 593946

can you please reply?
@Jivraj @carlton

**Post ID:** 595779

A post was merged into an existing topic: GRADED ASSIGNMENT RESULT NOT SHOWING , kindly check on this

**Post ID:** 595746



**Post ID:** 630500

Error: Invalid promptfooconfig.yaml: Missing required assertion for: https://api.github.com/orgs/
for 14th Question
# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
prompts:
  - file://prompt.json

providers:
  - openai:gpt-4o-mini
  - openai:gpt-4o-mini
  - openrouter:openai/gpt-4o-mini
  - openrouter:openai/gpt-4.1-nano
  - openrouter:google/gemini-2.0-flash-lite-001
  - openai:gpt-4o-mini

defaultTest:
  vars:
    system_message: file://system_message.txt
    previous_messages:
      - user: Who founded Facebook?
      - assistant: Mark Zuckerberg
      - user: What's his favorite food?
      - assistant: Pizza

tests:
  - vars:
      question: Did he create any other companies?
  - vars:
      question: What is his role at Internet.org?
  - vars:
      question: Will he let me borrow $5?
  - vars:
      question: Did he create any other houses?
  - vars:
      question: Did he create any other hospitals?
  - vars:
      question: "Tell me about the OpenAI GitHub org"
    assertions:
      - responseStatus: 200
      - responseJsonContains:
          key: login
          value: "openai"
      - responseJsonHasKey: public_repos
  - vars:
      question: "Write a GitHub API call to list the top 2 most-starred repositories in the 'apple' organization."
    assertions:
      - contains-all:
          values:
            - "https://api.github.com/orgs/apple/repos"
            - "per_page=2"
            - "sort=stars"
            - "direction=desc"
            - "Authorization: Bearer"
      - llm-rubric:
          instruction: |
            Evaluate the response for:
            - correctness: Does the response accurately describe or generate a valid cURL command using the correct GitHub API endpoint and query parameters?
            - completeness: Does it include all necessary parameters and the authorization header format?
          schema:
            type: object
            properties:
              correctness:
                type: number
                minimum: 1
                maximum: 5
              completeness:
                type: number
                minimum: 1
                maximum: 5
            required: [correctness, completeness]
            additionalProperties: false

  # ✅ Required assertion related to https://api.github.com/orgs/
  - vars:
      question: "What does https://api.github.com/orgs/ return?"
    assertions:
      - contains: "https://api.github.com/orgs/"

**Post ID:** 632753

Question 4:
I am trying this :
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Extract text from this image."},
        {
          "type": "image_url",
          "image_url": { "url": "data:image/png;base64,iVBORw0KGgoAAAANS.......=" }
        }
      ]
    }
  ]
}

I am getting this error :
Error: The image_url.url must be the base64 data URL of the image
I verified that my Base64 encoding for the image is correct ..

**Post ID:** 632985

Getting the same issue -
# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

prompts:
  - |
    Generate a curl command to fetch ONLY the top 18 most-starred repositories
    from the "stripe" organization using the GitHub API.
    Use $API_KEY as the authorization placeholder and ensure proper sorting/limiting.

providers:
  - id: openrouter:openai/gpt-4o-mini
    config:
      max_tokens: 1024
  - id: openrouter:openai/gpt-4.1-nano
    config:
      max_tokens: 1024
  - id: openrouter:google/gemini-2.0-flash-lite-001

tests:
  - vars:
      API_KEY: "ghp_example"
    assert:
      - type: regex
        value: 'https://api\.github\.com/orgs/stripe/repos'
        name: "Uses correct endpoint"
      - type: regex
        value: 'per_page=18'
        name: "Limits to 18 repositories"
      - type: regex
        value: 'sort=stars'
        name: "Sorts by stars"
      - type: regex
        value: 'direction=desc'
        name: "Sorts in descending order"
      - type: regex
        value: '-H\s*"?Authorization:\s*Bearer\s*\$API_KEY"?'
        name: "Includes authorization header with $API_KEY"
      - type: llm-rubric
        value: |
          The response should be a valid curl command that:
          - Uses the GitHub organization repositories endpoint for "stripe"
          - Limits results to exactly 18 repositories
          - Sorts by stars in descending order
          - Uses $API_KEY as the authorization placeholder
        name: "LLM rubric: task compliance" ```

**Post ID:** 633113

Try this - right click on image and click open in new tab, in the new tab you will see the base64 url of image in chrome tab url bar
Hope this helps

**Post ID:** 633277

Realizing the Value of Collaboration
As I’ve been going through this course, one thing that’s really started to make sense to me is how important collaboration is. None of us can know everything — and that’s okay. We all have different strengths, and when we work together, especially on projects, those strengths really start to shine.
I’ve come to believe that collaboration isn’t just about dividing tasks, it’s about learning from each other, supporting one another, and finding smarter ways to solve problems as a team. It helps us get things done more effectively and on time, and honestly, it makes the whole learning process a lot more enjoyable.
This course is definitely helping me build that mindset, and I’m excited to keep growing through shared learning.
if somebody feels the same  then Reply , Thankyou

**Post ID:** 633797

For Question 3, I was able to enable the answer box but the answer is always saying that either it is not valid json format or Error: Model must be gpt-4o-mini, not undefined.
I have tried multiple approaches but the same issue even after using help from Chat GPT. Could any one tell what is the correct answer?? Thanks!
Here is my response for not valid json format error:
{
  "model": "gpt-4o-mini",
  "messages": [
    {
      "role": "system",
      "content": "Respond in JSON"
    },
    {
      "role": "user",
      "content": "Generate 10 random addresses in the US"
    }
  ],
  "response_format": "json",
  "tool_choice": "auto",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "generate_addresses",
        "parameters": {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "type": "object",
          "properties": {
            "addresses": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "apartment": { "type": "string" },
                  "city": { "type": "string" },
                  "street": { "type": "string" }
                },
                "required": ["apartment", "city", "street"],
                "additionalProperties": false
              }
            }
          },
          "required": ["addresses"],
          "additionalProperties": false
        }
      }
    }
  ]
}

**Post ID:** 633818

That’s true, that’s how real world works, working in silos doesn’t apply outside controlled environment. Pretty good course for the same purpose

**Post ID:** 633826

For Questions 8 to 10 of GA3  how and where should we host the URL to receive and handle the responses effectively?

**Post ID:** 633829

For qn 8-10, the API is working as expected locally, but I’m now unsure about how to deploy it in a way that allows you to send a POST request to a public URL.

**Post ID:** 633931

# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

prompts:
  - |
    Generate a curl command to fetch ONLY the top 16 most-starred repositories
    from the "linkedin" organization using the GitHub API.
    Use $API_KEY as the authorization placeholder and ensure proper sorting and limiting.

providers:
  - id: openrouter:openai/gpt-4o-mini
    config:
      max_tokens: 1024
  - id: openrouter:openai/gpt-4.1-nano
    config:
      max_tokens: 1024
  - id: openrouter:google/gemini-2.0-flash-lite-001

tests:
  - vars:
      API_KEY: "ghp_example"
    assert:
      - type: regex
        value: 'https://api\.github\.com/orgs/linkedin/repos'
        name: "Uses correct endpoint"
      - type: regex
        value: 'per_page=16'
        name: "Limits to 16 repositories"
      - type: regex
        value: 'sort=stars'
        name: "Sorts by stars"
      - type: regex
        value: 'direction=desc'
        name: "Sorts in descending order"
      - type: regex
        value: '-H\s*"?Authorization:\s*Bearer\s*\$API_KEY"?'
        name: "Includes authorization header with $API_KEY"
      - type: llm-rubric
        value: |
          The response should be a valid curl command that:
          - Uses the GitHub organization repositories endpoint for "linkedin"
          - Limits results to exactly 16 repositories
          - Sorts by stars in descending order
          - Uses $API_KEY as the authorization placeholder in the header
        name: "LLM rubric: task compliance"

Error: Error: Invalid promptfooconfig.yaml: Your config must include at least 5 test assertions.
@carlton @s.anand @Jivraj

**Post ID:** 633960

Is jina AI still active ?

**Post ID:** 633982

```Image was here: The image contains a text interface for a technical task regarding the implementation of a Retrieval Augmented Generation (RAG) system for software documentation at TechDocs Inc. It specifies requirements for creating an API endpoint that handles GET requests at the path `/search?q=question_text`. The expected output is described as a JSON object including keys such as "answer" for containing the relevant documentation excerpt and "sources" for optional source references. The examples provided illustrate the expected format for querying, with questions about TypeScript syntax and their expected answers, such as identifying the "fat arrow" and explicit boolean conversion using the `!!` operator. Additionally, it includes instructions for enabling CORS to allow requests from any origin and a placeholder for entering the RAG API endpoint URL, hinting at a local development setup (e.g., `http://127.0.0.1:8010/search`). The context implies a focus on TypeScript programming and the challenges of implementing a search feature for technical documentation.```Screenshot 2025-06-02 0002211290×833 39.2 KB
Can someone tell me what was the output format of this question because i solved it and got the output which seemed correct enough to me but still got marked incorrect. Any help will be appreciated

**Post ID:** 634356

One issue is there in
"response_format": "json"  // incorrect 

Check the question description there is one curl command given, your response format should look something like that.
