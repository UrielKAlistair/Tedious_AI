## project 1 llm based automation agent discussion thread tds jan 2025
https://discourse.onlinedegree.iitm.ac.in/t/project-1-llm-based-automation-agent-discussion-thread-tds-jan-2025/164277


**Post ID:** 581882

Please post any questions related to Project 1 - LLM-based Automation Agent.
Deadline: Sunday, February 16, 2025 6:29 PM
Update on 27 Jan 2025:
A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub
You can use this to validate your code for Project 1.
Please note:

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in the evaluation script slightly to test variations


Your AI Proxy usage resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who submit their code by Friday 31 Jan, I will run a sample evaluation and share the results.

**Post ID:** 581888



**Post ID:** 582037

sir show us all the way to do project

**Post ID:** 582038

Hi Shouvik,
We will have live sessions to guide on how to do project.
Kind regards
Jivraj

**Post ID:** 582333

Will those session be on youtube too?

**Post ID:** 582334

Hi Sakthivel,
Yes all sessions are being recorded and are available on youtube within a day.
Jan 25 TDS Playlist
Kind regards

**Post ID:** 584016

```Image was here: The image presents a snippet of text that appears to be part of technical documentation or instructions pertaining to a software engineering task. It specifies the installation of a tool called `uv`, suggesting that it may be necessary for the task at hand. A URL is provided, leading to a script located in a GitHub repository, specifically pointing to a Python file named `datagen.py` within a public project related to data science. The instructions indicate that the script should be executed with a variable `${user.email}` as the sole argument, implying that an email address is required for the script to function properly. Additionally, there is a note highlighting that running this script will generate data files essential for subsequent tasks, emphasizing its role in a broader workflow. The context suggests usage in data generation or preprocessing within a data science pipeline, possibly utilizing command line interface tools or a notebook environment for execution.```Screenshot 2025-01-23 1516141281×125 18.1 KB
sir @Jivraj after editing line 127 in datagen.py i got those  required data files. is it allowed ? also i had to run datagen.py MANUALLY(is this process also should be automatic)?

**Post ID:** 584052

Hi Guddu ,
I didn’t make any changes to file and it worked for me. Can you mention what is need of making changes ?
command that I used :
uv run datagen.py 22f3002542@ds.study.iitm.ac.in --root ./data
here --root option defines the folder where you want to store generated data. by default it would try to create a folder in root directory of operating system.
Kind regards
Jivraj

**Post ID:** 584083

getting this issue :
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}

**Post ID:** 584107

Hi Aishik,
Pls add context to your query, without that we won’t be able to understand, where exactly you are facing problem.



 23f2005325:

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}



Possible reasons for this issue:

Not using anand sir’s proxy url for sending requests.
Token not being correct.

**Post ID:** 585092

yes I was not setting the base url to the proxy. I have fixed it thank you .

**Post ID:** 585171

While implementing task A5, I am confused about what recent actually means in the phrase “recent log file”, mentioned under task A5, in the problem statement. This confusion arises because there are no dates corresponding to the log files. Should I consider log-0 as the most recent one? or the log-<largest_number> file? Please clarify.

**Post ID:** 585547

I am getting the following response when I am trying to extract credit card number from the credit-card.png :
{'id': 'chatcmpl-<redacted>', 'object': 'chat.completion', 'created': 1737872397, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': "I'm sorry, but I can't assist with that.", 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 946, 'completion_tokens': 11, 'total_tokens': 957, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': '<redacted>', 'monthlyCost': 0.07715699999999998, 'cost': 0.0029040000000000003, 'monthlyRequests': 31, 'costError': 'crypto.createHash is not a function'}

my code is as below :
def extract_credit_card_number():
    import requests
    import base64
    import os
    from dotenv import load_dotenv
    load_dotenv()



    BASE_URL = "http://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.environ["AIPROXY_TOKEN"]}"
    }

    image_path = "../data/credit_card.png"

    with open(image_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode("utf-8")

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {
                "role": "system",  
                "content": "You are a helpful assistant that provides detailed and accurate descriptions of images. Focus on describing the objects, colors, textures, the overall scene, and most importantly, the text and numbers in the image. Be concise but thorough."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "You are given an image containing a credit card number. Extract the credit card number from the image"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
    }

    
    response = requests.post(BASE_URL, headers=headers, json=payload)

    
    if response.status_code == 200:
        result = response.json()
        print("RESULT:", result)
        cno = result["choices"][0]["message"]["content"]
        print("CREDIT CARD NUMBER:", cno)
    else:
        print(f"Error: {response.status_code}")
        print(response.text)

please guide @Jivraj @Saransh_Saini

**Post ID:** 586263

do we have to do these tasks in the linux? As in some of the GA1, the linux answers only accepted. Please tell me that, do we can do it in the desktop or we have to use linux?
@Jivraj @carlton

**Post ID:** 586429

The bash commands are usually run in a linux machine, but you can easily run those commands in VSCode without installing any virtual machines. Download the WSL extension in VSCode and you will get a WSL terminal to work with.
For more information watch this video https://youtu.be/q74CP4fB7cY?si=M_zw8WzpmMCyVQat or watch TDS Live Sessions.
Regards,
TDS TA

**Post ID:** 586506

what frameworks can we use? hopefully anything?
or what frameworks can’t we use?
@carlton @Jivraj

**Post ID:** 586519

Project 1 deliverables are all that matter. How you accomplish them is not very relevant. The keys to a successful Project 1 are:
Deliverables,
and an example of the Evaluation has been provided.
If your project runs in accordance with the Evaluation methodology then it is considered.
```Image was here: The image contains instructions related to setting up a GitHub repository for a software project involving AI, specifically an API interaction with a model named "GPT-40-Mini." It outlines the following steps: create a new GitHub repository, add a file named `MIT_LICENSE`, write and test code using an endpoint (`POST /run?task=...`), and push the code to the repository. Instructions for creating a Dockerfile to build and push an image to Docker Hub are included, along with commands to run the application using Podman, specifying environment variables for AI proxy tokens. Notable environment variable instructions point out using `AI_PROXY_TOKEN`, ensuring it is not committed to the repository, and additional guidance on managing token limits. The image references project deliverables and includes a note encouraging the user to maintain concise prompts for the AI interactions, with an emphasis on making each call to the API within a certain time constraint.```Screenshot 2025-01-27 at 8.35.23 am1764×1764 374 KB
Please read the documentation carefully from top to bottom.
So the main question is how do you test if the script will run according to the evaluation? The whole point is for it to run not just on your system. It should be deployable anywhere on any machine. Your solution should work anywhere we test it. Thats why you package it in a docker container. How you achieve that is up to you. But if we cannot run your docker container according to the specification we have provided then it has failed this crucial test.
Kind regards

**Post ID:** 586522

@23f1002382
You can use any library as long as your Project 1 meets the deliverable requirements and does all the (20+) API tasks.
Kind regards

**Post ID:** 586786

A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub
You can use this to validate your code for Project 1.
Please note:

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in the evaluation script slightly to test variations


Your AI Proxy usage resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who submit their code by Friday, I will run a sample evaluation and share the results.

@carlton @Jivraj @Saransh_Saini - please socialize this during the live sessions.

**Post ID:** 586801

By clicking the project link ,I am getting the notes…but no project is available in my project 1

**Post ID:** 586802

by clicking the link
```Image was here: The image depicts a user interface for a project management tool, specifically showing details for "Project 1." On the left side, there is a collapsible sidebar that highlights "Project 1" with an indication of its status, likely signifying it is currently selected or in progress. The main content area displays a question labeled "1)" followed by a statement: "I have seen Project 1 available at this link and have attempted it," with "this link" formatted as a hyperlink. Below the text, there are two radio button options labeled "Yes" and another option presumably indicating the contrary, allowing for user input. The layout suggests a survey or feedback mechanism related to the project. The visible context points to user interaction within a software platform geared towards project tracking or feedback collection.```image1198×136 9.49 KB
```Image was here: The image displays a technical forum interface, highlighting a project titled "Project 1 - LLM-based Automation Agent." The project deadline is specified as February 15, 2025, with results to be announced by February 25, 2025. A sidebar lists various topics, including “Tools in Data Science,” “Development Tools,” and “Large Language Models,” indicating a structured layout for accessing related discussions. The background section describes participation in the operations team at DataWorks Solutions, focused on processing large volumes of log files and generating actionable insights using a Large Language Model (LLM) to enhance operational efficiency. The text mentions integrating these tasks into a Continuous Integration (CI) pipeline, suggesting a context involving software automation, machine learning, and data processing. No specific code snippets, error messages, or console outputs are evident in the image.```image1750×581 70.9 KB
I am getting this opened.

**Post ID:** 586908

Hi @Divya1 ,
There won’t be any project1 page such as GA1s, there is a google form(which can be found in same page) which needs to be filled after you do project1.

**Post ID:** 586910

Hi @23f2005325 ,
Extracting details from credit cards is sensitive, try using strong prompts or take code from LLM and execute it in script.
kind regards

**Post ID:** 587088

Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environment using maybe ollama(local llm as now there is deepseek opensource, i doubt we would need to use openai for testing, just for production(test submission)  would be enough) and also some agent(langchain, autogen, crewai) just a quick how-to on setting up and problems while setting up if possible
More resources on docker. Using docker as a virtual environment. Editing and executing code in Dockerfiles (like when you change code in src a web framework automatically reloads page(hot reload)), something along the lines of this .
@carlton @Jivraj

**Post ID:** 587185

23f1002382:

Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen


In Tuesday’s(21 January) session we had discussed docker towards ending of session.
What was discussed in that live session regarding docker:

Search for existing containers on repositories such as dockerhub.
Pull an existing docker image.
Run that image inside a container.
Enter to that container and modify something(such as installing python inside a ubuntu container, for customization or create some file)
Once done you can commit it.
And push customized container’s image to docker hub.

Regarding local models running for project1, it’s a good idea, we will see if it’s possible to discuss in session.

**Post ID:** 587326

In the google forms , I have 2 questions in one form now to submit should it is compulsory that to answer the both the questions?

**Post ID:** 587355

Hi @Divya1
```Image was here: The image contains a set of instructions labeled “Deliverables” related to a software engineering task involving GitHub and Docker. It outlines the steps to create a public GitHub repository, add an MIT license file, and write and test code by calling a specified API endpoint (POST /run?task=...). It instructs to verify the functionality with a GET request to /read?path=... and emphasizes committing and pushing the code to the repository. Additionally, it describes creating a Dockerfile for building the application and provides a command for running the image using Podman. The command includes setting an environment variable for an API proxy token and mapping ports (8000:8000) for accessing the API. Finally, it requires submission of the GitHub repository URL and Docker image name through a Google Form, with an example format given for clarity, specifically highlighting the GitHub URL structure (https://github.com/user-name/repo-name).```Screenshot 2025-01-29 at 8.19.05 am1738×982 122 KB
Please do very carefully all things mentioned in the Deliverables as well as look at the Evaluation Section.
```Image was here: The image displays guidelines for evaluating a software repository, highlighting essential prerequisites for eligibility. It specifies that the GitHub repository must be publicly accessible and contain a LICENSE file under the MIT license. Additionally, a valid Dockerfile is required, and the Docker image should also be publicly accessible, runnable via the command `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000`. The content suggests a focus on containerization with Podman, emphasizing the importance of alignment between the Dockerfile in the repository and the deployed Docker image, which is pertinent in the context of Dockerized application development and deployment. The setting suggests a technical evaluation related to software quality assurance or open-source compliance in a software engineering context.```Screenshot 2025-01-29 at 8.26.08 am1460×496 45.5 KB
We had a session on 28th Jan introducing all the important aspects of Project.
If you do not do everything exactly as mentioned especially the pre - requisites mentioned in the Evaluation section you will get 0 in the project and there will be no appeal for failing to meet the pre - requisites of the evaluation criteria.
In order for us to evaluate the project you have to provide the deliverables mentioned above.
Kind regards

**Post ID:** 587402

Subject: Request to Add Instructors to Private GitHub Repo
Message:
"Dear [Instructors’ Names],
I’ve set up the environment and dependencies for the project and was wondering if it would be appropriate to add you to my private GitHub repository. I’d appreciate any guidance on improving performance, scalability, and design principles. Please let me know if this is feasible or if there’s a more suitable way to seek feedback. Apologies if this request is out of scope.
Thank you for your time!
Best,
[Your Name]"*
ChatGPT can make mistakes. Check important info.

**Post ID:** 587464

@23f1002382 - You’re welcome to use the evaluation script in this post for private repos.




Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub 
You can use this to validate your code for Project 1. 
Please note: 

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in t…
  

For public repos submitted in the form, I’ll run this script over the weekend and share preliminary results.

**Post ID:** 587475

T  h  a  n  k      y  o  u         sir.

**Post ID:** 587763

For A6, /data/docs/ has subfolders with .md files from which we have to extract the heading level 1’s (#) right? Apparently there are few files with different content but the same name. Can someone confirm the same? If yes how to address these files @Jivraj @carlton

**Post ID:** 587764

I had set up the environment and dependencies and everything was working fine. When i tried to recreate it from scratch in a new codespace it broke. I fixed almost everything except this error
@ANdIeCOOl ➜ /workspaces/TDS-Project-1 (main) $ crewai create crew b2b
Traceback (most recent call last):
  File "/home/codespace/.python/current/bin/crewai", line 5, in <module>
    from crewai.cli.cli import crewai
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/__init__.py", line 3, in <module>
    from crewai.agent import Agent
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agent.py", line 7, in <module>
    from crewai.agents import CacheHandler
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/__init__.py", line 2, in <module>
    from .parser import CrewAgentParser
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/parser.py", line 6, in <module>
    from crewai.utilities import I18N
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/__init__.py", line 13, in <module>
    from .embedding_configurator import EmbeddingConfigurator
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/embedding_configurator.py", line 4, in <module>
    from chromadb import Documents, EmbeddingFunction, Embeddings
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/__init__.py", line 6, in <module>
    from chromadb.auth.token_authn import TokenTransportHeader
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/auth/token_authn/__init__.py", line 24, in <module>
    from chromadb.telemetry.opentelemetry import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py", line 13, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/__init__.py", line 25, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.exporter import (  # noqa: F401
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py", line 72, in <module>
    from opentelemetry.sdk.metrics.export import MetricsData
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/__init__.py", line 16, in <module>
    from opentelemetry.sdk.metrics._internal import Meter, MeterProvider
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/__init__.py", line 56, in <module>
    from opentelemetry.sdk.metrics._internal.measurement_consumer import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/measurement_consumer.py", line 29, in <module>
    from opentelemetry.sdk.metrics._internal.metric_reader_storage import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/metric_reader_storage.py", line 26, in <module>
    from opentelemetry.sdk.metrics._internal._view_instrument_match import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/_view_instrument_match.py", line 22, in <module>
    from opentelemetry.sdk.metrics._internal.aggregation import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/aggregation.py", line 48, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.exponent_mapping import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/exponent_mapping.py", line 25, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.ieee_754 import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.py", line 15, in <module>
    from ctypes import c_double, c_uint64
  File "/usr/local/python/3.12.1/lib/python3.12/ctypes/__init__.py", line 8, in <module>
    from _ctypes import Union, Structure, Array
ImportError: /usr/local/python/3.12.1/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0

i updated the libffi package using sudo but while breaking something else can someone pls help me? @carlton @Jivraj @s.anand



history of commands in new codespace
    1  crewai --version
    2  pip install crewai crewai-tools
    3  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    4  export PATH=/opt/conda/bin:$PATH
    5  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    6  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    7  crewai create crew <project_name>
    8  crewai create crew b2b
    9  history



UPDATE: IT’s WORKING if you do this in order
    1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    2  export PATH=/opt/conda/bin:$PATH
    3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    5  pip install --no-cache-dir --force-reinstall typing_extensions pydantic crewai crewai-tools
    6  conda install -c conda-forge typing_extensions
    7  exec bash
    8  crewai create crew "Project 1 - LLM-based Automation Agent"

Something about different environment conda and python can the instructors please help me understand it(resources ), so i can trouble shoot this later with better accuracy come precision

**Post ID:** 587902

evaluate.py
TDS course repo

```Image was here: None```
github.com


tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ·...
Contribute to sanand0/tools-in-data-science-public development by creating an account on GitHub.





line 20
from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)

but we get datagen.py only in a1 task
line 69
async def a1(email: str, **kwargs):
    await run(
        f"""
Install `uv` (if required) and run the script `https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py`
with `{email}` as the only argument
"""
    )
    return email in await read("/data/format.md")

The issue is importing datagen before ensuring it exists
just checking
@carlton @Jivraj

**Post ID:** 588062

Hi @23f1002382,
Yes datagen.py must be present in same directory from where you  are executing evaluate.py.
Oh, You trying to use crewai locally for Project1
kind regards

**Post ID:** 588063

Hi @JoelJeffrey ,
Filepath is unique for every file, which needs to be inserted to json file.

**Post ID:** 588156

Ok. So just to confirm, since there are files with the same name, the json file should map the filepath and not the filename to the title right?
```Image was here: The image displays a technical task description outlining a process for processing Markdown (.md) files located in the directory `/data/docs/`. It instructs to find all Markdown files, extract the first header line (designated by `#`) from each file, and create an index file at `/data/docs/index.json`. This index is meant to map each filename, excluding the path, to its corresponding title as shown in the example JSON structure `{ "README.md": "Home", "large-language-models.md": "Large Language Models", ... }`. The context implies a script or function likely written in a programming language capable of file I/O operations, and it may pertain to a larger documentation or knowledge management system. The task emphasizes the use of JSON for structured data representation, suggesting familiarity with programming paradigms involving data serialization and manipulation.```Screenshot from 2025-01-31 12-25-29790×117 19.9 KB

**Post ID:** 588190

no crewai, it takes really long i put time out for 300 secs(in run(task:str) in evaluate.py) still sometimes its not enough. I’ll try with autogen next and then langchain

**Post ID:** 588192

INFO:     127.0.0.1:65085 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
data/format.md 81ms
INFO:     127.0.0.1:65149 - "POST /run?task=%0AFormat+the+contents+of+%60%2Fdata%2Fformat.md%60+using+%60prettier%403.4.2%60%2C+updating+the+file+in-place%0A HTTP/1.1" 200 OK
INFO:     127.0.0.1:65251 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
INFO:     127.0.0.1:65263 - "POST /run?task=The+file+%60%2Fdata%2Fdates.txt%60+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+%60%2Fdata%2Fdates-wednesdays.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65298 - "GET /read?path=/data/dates-wednesdays.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65312 - "POST /run?task=Sort+the+array+of+contacts+in+%60%2Fdata%2Fcontacts.json%60+by+%60last_name%60%2C+then+%60first_name%60%2C+and+write+the+result+to+%60%2Fdata%2Fcontacts-sorted.json%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65350 - "GET /read?path=/data/contacts-sorted.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65361 - "POST /run?task=Write+the+first+line+of+the+10+most+recent+%60.log%60+file+in+%60%2Fdata%2Flogs%2F%60+to+%60%2Fdata%2Flogs-recent.txt%60%2C+most+recent+first HTTP/1.1" 200 OK
INFO:     127.0.0.1:65390 - "GET /read?path=/data/logs-recent.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65402 - "POST /run?task=Find+all+Markdown+%28%60.md%60%29+files+in+%60%2Fdata%2Fdocs%2F%60.%0AFor+each+file%2C+extract+the+first+occurrance+of+each+H1+%28i.e.+a+line+starting+with+%60%23+%60%29.%0ACreate+an+index+file+%60%2Fdata%2Fdocs%2Findex.json%60+that+maps+each+filename+%28without+the+%60%2Fdata%2Fdocs%2F%60+prefix%29+to+its+title%0A%28e.g.+%60%7B%22README.md%22%3A+%22Home%22%2C+%22path%2Fto%2Flarge-language-models.md%22%3A+%22Large+Language+Models%22%2C+...%7D%60%29 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65436 - "GET /read?path=/data/docs/index.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65452 - "POST /run?task=%60%2Fdata%2Fcredit_card.png%60+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+%60%2Fdata%2Fcredit-card.txt%60 HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65482 - "GET /read?path=/data/credit-card.txt HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65503 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:49154 - "GET /read?path=/data/ticket-sales-gold.txt HTTP/1.1" 200 OK

result after running evaluate.py:
 Score: 0 / 10
why sir @Jivraj @Saransh_Saini  what is the problem here??
please do a live session of complete project process with one or two tasks if possible

**Post ID:** 588200

Hi Guddu,
We are planning several project sessions in order to show the workflow of creating a successful project.
Although you are returning a 200 ok, the get request file must match the expectation. In other words after running the first task for example, has the new format.md been formatted correctly and matches the expected output.
In this case you would write out the the expected variable in the evaluate.py and see if result variable matches the expected. Then you can figure out what went wrong.
Kind regards

**Post ID:** 588211

Ok sir
But please try to take those sessions sooner
Because it’s taking too much time for me to do any problem(plus two more courses and one oppe you know) .so I just want to build the project before deadline.

**Post ID:** 588237

Please give the date, time and agenda also please.

**Post ID:** 588244

Yes sir ,
As soon as we know we will send an announcement.
Kind regards.

**Post ID:** 588510

the model keeps wrong answer, it says uvicorn for uv and has no info on how to run uv even after explicitly giving instructions(basically an older model) , basic “ls” command is also wrong, among other things. You can check your logs with respect to my api key.
Do you think we could access a better model?
Maybe Download Deepseek 70b or even 671b and create an api while y’all run the model locally, in the long it would be cheaper for the course?
because the model doesn’t know basic commands after telling how to do it.
So if the model gives us wrong commands 2/3 times then how would we even solve the question.
I spent a week on this just saying
@s.anand @carlton @Jivraj

**Post ID:** 588521

sent pull request maybe accept it then please

**Post ID:** 588583

```Image was here: The image features a colorful collage representing various tools and elements associated with data science. Prominent text overlays state "TOOLS IN DATA SCIENCE." Visuals include icons of a target graph, a globe, various charts and graphs (bar, line, and pie), a color palette, a magnifying glass, and interconnected nodes showcasing data relationships. There are representations of coding instruments like pens and geometric shapes symbolizing algorithmic concepts. The background includes subtle indicators of datasets and analytical methods, reinforcing the theme of data manipulation and visualization. The overall aesthetic emphasizes a modern, tech-oriented approach to data science tools and practices.```


can we have the code for this session please?
@Jivraj @carlton

**Post ID:** 589264

i need some help can you send me your repo?

**Post ID:** 590035

Hello, I recently started working on the project. I understood how to do all the phase A tasks on a high level but I’m struggling to start the implementation of the first task in phase A. I’m confused mainly about how the /data directory is supposed to be created, I don’t know how to generate the data and a little confused about the output formats. I would appreciate if I could get in contact with anyone who could guide me in the right direction.

**Post ID:** 590128

Hello everyone, @s.anand @carlton
I had a few queries regarding the project;

I am preloading my docker image with uv and generating the /data files when the container is ran. For task A1, I am automating my server to remove the /data directory that’s already present and run datagen.py again. Is this fine?
For /read endpoint, is there a standard for parameters like “path=/data/format.md” or the parameter could be a plain english sentence like “path=show the data in format.md”?
Are we concerned about what’s shown on the console if I run a /run command as long as it gets the job done?
For tasks A1-10, are the file paths provided in the project doc standard or even they’re flexible? Ex. “Count the number of Wednesdays in file /data/format.md, and write just the number to /data/out.txt”

**Post ID:** 590164

+1

**Post ID:** 590213

Dear Sir,
Can we have a mentorship program for TDS for those who have no experience in programming like me ?
thanks & regards.
ULAGAOOZHIAN

**Post ID:** 590283

For Project-1 to complete, it requires:
"You MUST complete ALL these 3 steps to get a score. Failure to do so will result in getting 0 in the project. If you do not do ALL these 3 steps before the deadline, there will be no appeal available.
• Fill the form that is on the Project Page
But I did not get the form; where is it? While I checked inside the project pages also.

**Post ID:** 590282

Hi Dewang,
```Image was here: The image contains a technical forum-style interface displaying a checklist of deliverables for a project related to data science tools. It includes specific tasks such as creating a new public GitHub repository, adding an MIT LICENSE file, and executing test cases using POST and GET methods to interact with an API at specified localhost endpoints (http://localhost:8000/run?task=... and http://localhost:8000/read?path=...). The context suggests using Podman for containerization, where an environment variable named AIRPROXY_TOKEN is utilized. There are instructions to submit the Google Form with the URLs for the GitHub repository and Docker image, emphasizing the importance of not committing sensitive information like the AIRPROXY_TOKEN. The image also refers to a specific AI Proxy token limit and mentions the GPT-4-Mini model, highlighting its compatibility with generative tasks. The overall activity centers on setting up and publishing a Dockerized application while adhering to best practices for handling sensitive credentials and ensuring concise and clear code execution within specified parameters.```Screenshot 2025-02-03 at 6.27.39 pm 12268×1766 491 KB
Please read the Project page Deliverables carefully as well as the Evaluation Pre - Requisites.
Kind regards

**Post ID:** 590523

github.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-


README.md

main

# TDS-Project1-Ollama_FastAPI-
## Info
- Create codespaces on main or evalution script branch
Use history.txt to get sqlite to version 3.45.3 into bash session 
   - 64  export PATH=/opt/conda/bin:$PATH
   - 65  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
   - 66  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"

- cd to latest_ai_development and run cmd [ crewai run] which set up server 
- Then in a separate bash terminal run "python evaluate.py" 
- also make sure to enter openai or sanand api key in crew.py

# Simple history of commands
1. Terminal 1 
    - 1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 2  export PATH=/opt/conda/bin:$PATH
    - 3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    - 4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 5  cd latest_ai_development/
    - 7  pip install crewai crewai-tools




  This file has been truncated. show original





My take on autonomous agents. Limited by model capabilities to some extent. Will use function calling hence forth but here is a quick look at using crewai for agent tasks.

**Post ID:** 590531

Sir   @carlton @Jivraj just saying,
If possible Please do 40-50% of project in upcoming live sessions so that we all have atleast something to submit.

**Post ID:** 590917

I am using ubuntu. How do I use python 3.13. It says my python version is 3.12 even after installing python 3.13
Someone please help

**Post ID:** 590984

@s.anand sir, I see that the project 1 timeline was changed from February 7 - 17, 2025 to January 17 - February 15 which undoubtedly is a good increase in duration. However, I have my GATE DA exam on Feb 15 and the exam center is unexpectedly far. So, I request you to consider pushing the deadline to at least Feb 16. If not, I’ll still do my best.

**Post ID:** 591128

Hello! @carlton @s.anand
Is the proxy server down right now?
I am getting this error when I am accessing the endpoint:
{‘id’: ‘chatcmpl-Axq55TzulOVjHYuXYIhkRQzCC3PNl’, ‘object’: ‘chat.completion’, ‘created’: 1738824915, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: …, ‘costError’: ‘crypto.createHash is not a function’}
Or, do I have to install crypto module?

**Post ID:** 591135

@21f3002390 - AI Proxy is working and you did get the result. You can ignore any costError. It won’t happen in the future anyway.
What’s happening? I was trying to generate a unique hash for each request, as a precursor to caching requests. But I made a mistake in the code. Specifically, crypto.createHash is not supported in CloudFlare. I fixed that by removing this. I’ll introduce caching later if required.

**Post ID:** 591170

For the question #A8 on recognizing the credit card number in the image, Open AI doesn’t seem to be recognizing the number correctly and as a result the evaluation is failing. What should be the solution?
```Image was here: The image displays a console output from a server interaction involving an HTTP-based API for processing an image containing a credit card number. The output indicates that a task is being executed on the file located at `/data/credit_card.png`, with the purpose of extracting the credit card number and saving it to the file `/data/credit-card.txt`. The HTTP request shown is a POST request to `http://localhost:8000/run`, with parameters that specify the function `extract_numbers_from_image`, including input and output file paths as arguments. A successful HTTP response with status code `200 OK` confirms that the task was processed correctly. The subsequent GET request to `http://localhost:8000/read?path=/data/credit-card.txt` also returned `200 OK`, and the expected output and result display the same extracted credit card number, `4026399336539536`, which confirms the operation's success. The context suggests the use of a local server environment, likely built with a framework supporting HTTP requests, and involves image processing for extracting sensitive data.```image913×498 13.6 KB

**Post ID:** 591224

When will live sessions for demo project start? If started please provide link for that as I am unable to get what the project is about and what are the initial steps to start project.

**Post ID:** 591326

Getting the following error :
127.0.0.1 - - [07/Feb/2025 01:44:54] "GET /run?task=generate%20data%20for%20ujanaishik109@gmail.com HTTP/1.1" 200 -
  File "/tmp/datagenyhqKlO.py", line 1
    404: Not Found
    ^^^
SyntaxError: illegal target for annotation


when executing the following code :
Main.py
@routes.route("/run", methods=["GET", "POST"])
def run():
    task = request.args.get("task")
    try:
        res = get_func_name(task)
        func_name = res["func_name"]
        args = res.get("arguments", [])
        print("ARGUMENTS : ", args)
        if args:
            generated_func = globals()[func_name](*args)
            print("GENERATED FUNC :",generated_func)
            res = f"{func_name} executed successfully"
        else:
            generated_func = globals()[func_name]()
            print(generated_func)
            res = f"{func_name} executed successfully"
    except Exception as e:
        res = None
        print("error : ", e)
    return jsonify(res)


Tasks.py
def generate_data_files(user_email: str):
    subprocess.Popen(
        [
            "uv",
            "run",
            "https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py",
            f"{user_email}",
            "--root",
            "../data",
        ]
    )
    print("data generated successfully")

Please Guide @s.anand @carlton @Jivraj

**Post ID:** 591514

A query regarding the task description in the query given to LLM for phase A.
For task A3, we have been asked to count wednesdays and the python file corresponding to A3 does count for wednesday alone. However the example says the LLM might be asked to count Sundays or other days. Should we be modifying task A3 code? Or was that just an example and only Wednesdays would need to be counted?

**Post ID:** 591582

@carlton @Jivraj  Please respond .

**Post ID:** 591761

When will the project session be held? If I have missed it, can I get the recording?
@carlton

**Post ID:** 591780

Tuesday is when we are currently planning a project session.
Kind regards

**Post ID:** 591783

Tasks in Phase A are defined but that does not mean it has to do one precise thing. If that was the case then there is no use for an LLM.
Your application should be able to take parse the input and be able to run commands that do similar things in parameterised fashion. It could be Wednesdays or Sundays or it might be in Arabic days or anything. So coding to precisely do something very specific is not the goal.
The program has to be intelligent to do a certain type or class of tasks.
We had a session introducing project. Week 3 session 1. But we will have a more hands on session on Tuesday.
Kind regards

**Post ID:** 591814

the last date of project submission is gonne get extended?

**Post ID:** 591822

Project 1 was released over a month ago. So there will be no extension for Project 1

**Post ID:** 591824

how to handle this error
```Image was here: The image shows a terminal interface running a Python script located at `/mnt/e/IITM/New/TDS/LLM_Project/2025-01/project-1/evaluate.py`. The output indicates a traceback error, specifically a `ModuleNotFoundError`, stating "No module named 'datagen'", which suggests that the script is attempting to import the `datagen` module on line 20, but the module is not found in the current environment. The command prompt displays a prior command that sets an environment variable for the OpenAI API key and runs a command linked to a GitHub URL, likely executing a FastAPI or similar server application using `uvicorn`. The presence of `#` in the command prompt indicates potential use of a behavior typical in Linux terminal interfaces, and the context suggests that the user is engaged in troubleshooting a Python project, possibly related to machine learning or data science workflows involving API interactions.```image1425×490 11.1 KB
@carlton @s.anand

**Post ID:** 591879

expected = sum(1 for date in dates if parse(date).weekday() == 2)
    if result.strip() != str(expected):
        return mismatch("/data/dates-wednesdays.txt", expected, result)
    return True```



 /data/dates-wednesdays.txt
 EXPECTED:
129
 RESULT:
“129”
If it is expecting str then why throw error sir  ? @carlton @Jivraj
or just tell me how to pass count as an int here
with open(output_file, "w") as f:
        f.write(str(count))

**Post ID:** 592061

@s.anand @carlton @Jivraj
I am getting below error message from LLM end points https://api.openai.com/v1/chat/completions or https://aiproxy.sanand.workers.dev/openai/v1/embeddings , while running my project .
```Image was here: The image displays a JSON-style error message indicating an API error with the code 429, typically associated with rate limiting. The content reveals that the error occurs when a user reaches a spending threshold, specifically referencing a usage amount of $2.002295600000011, which surpasses the allowable limit of $2. The specific date mentioned is February 2025. The format indicates this is likely part of a console output from a programming environment or an API response, hinting at a cloud service context where financial limits on API usage are enforced. JSON keys such as "error" and "message" are present, signifying structured error handling within the software, likely in a scenario where monitoring API usage is critical, possibly relating to systems utilizing billing or quota management for API calls.```
Kindly help me to resolve this issue.

**Post ID:** 592078

@carlton Will there be evaluation script for tasks in group B also?
Some questions about ‘B’ group tasks:
Q1: For the following tasks (B5, B7, B9, and B10) tasks, how will input files be provided? Will it be URL or will datagen.py also generate files for these?
Q2: For the above tasks as well as for B6 ( Extract data from (i.e. scrape) a website), how should output be returned?
Q3: In task B8, for transcribing audio file, which Python package is recommended or do we need to use OpenAI API?
B5. Run a SQL query on a SQLite or DuckDB database
B7. Compress or resize an image
B8. Transcribe audio from an MP3 file
B9. Convert Markdown to HTML
B10. Write an API endpoint that filters a CSV file and returns JSON data

**Post ID:** 592079

its expecting to  match every single detail in that even " and ’ .
in that case changing evaluate.py will result in zero or less marks.
llm will only handle  -calling function based on query and parameter   . What is it going to do about the logic of functions.
If i still focus on passing evaluate.py will it be any good sir @carlton @s.anand
🔴 /data/contacts-sorted.json
⚠️ EXPECTED:
[{'first_name': 'Kevin', 'last_name': 'Aguirre', 'email': 'ricardocarlson@example.net'}, {'first_name': 'Andrew', 'last_name': 'Anderson', 'email': 'kimberly08@example.com'}, {'first_name': 'Robert', 'last_name': 'Arnold', 'email': 'hunterpamela@example.com'}, {'first_name': 'Isaac', 'last_name': 'Barker', 'email': 'jessicabriggs@example.net'}, {'first_name': 

My output was in good looking structured form but I had to make it look like this just to pass the evaluation.
⚠️ RESULT:
[{"first_name": "Kevin", "last_name": "Aguirre", "email": "ricardocarlson@example.net"}, {"first_name": "Andrew", "last_name": "Anderson", "email": "kimberly08@example.com"}, {"first_name": "Robert", "last_name": "Arnold", "email": "hunterpamela@example.com"}, {"first_name": "Isaac", "last_name": "Barker", "email": "jessicabriggs@example.net"}, {"first_name": "Anthony", "last_name": "Barrett", "email": "kevinknox@example.org"}, {"first_name": "Monique", "last_name": "Bass", "email": "lindsaymcgrath@example.net"}, {"first_name": "Michael", "last_name": "Berry", "email": "an

**Post ID:** 592372

Sorry, sir, not trying to be rude, but there isn’t a single full-fledged project session. It’s a bit difficult to dive into the project without guidance on how to do it. It would be nice to have a full project session where we can start a project from the beginning and follow it to completion.
@carlton @Jivraj @s.anand

**Post ID:** 592385

Yes. I am very worried about this project. I have been trying to do this. But have gotten nowhere until now.

**Post ID:** 592429

@carlton sir I request you demonstrate atleast few tasks, I spent last 2 days trying to implement but din’t reach anywhere, its really demotivating sir.

**Post ID:** 592466

Can you please demonstrate it by just doing One task or provide sample example code of 1 similar task in the way you explained here. It will be very helpful right now it is very confusing.

**Post ID:** 592508

We will be doing project session on Tuesday 9 Feb [correction] Tuesday 11th of Feb (thanks @23f1002382 @23f2000237) . Project 1 uses the things you learnt in week 1-3. But mostly week 2 & 3.
We dont do it in the beginning, (but introduced it 2 weeks ago in a live session), to give students chance to practise the new learnings from week 2 & 3.
The plan has always been to demonstrate a few tasks and have you try doing the rest.
Kind regards

**Post ID:** 592517

@s.anand @carlton @Jivraj
I am getting below error message from LLM end points https://api.openai.com/v1/chat/completions or https://aiproxy.sanand.workers.dev/openai/v1/embeddings , while running my project .
```Image was here: The image displays a JSON-like response indicating an API error with status code 429, which signifies that the request limit has been exceeded. The structure includes an 'error' key with the message "API Error: 429," followed by a 'message' key providing more details: "On 2025-02 you used $2.00229560000011, exceeding $2." This output suggests a structured feedback mechanism typical in RESTful APIs, likely related to a usage monitoring feature. The implication is that the user has surpassed a monetary threshold for API consumption, relevant for software engineering discussions about API limits, error handling, and budget management in API usage.```
Kindly help me to resolve this issue. I am unable to proceed with my project.

**Post ID:** 592531

Today’s 9th Feb and it’s a Sunday.

**Post ID:** 592835

s.anand:

Update: 27 Feb 2025:


Sir, does this mean 27th is submission deadline?

**Post ID:** 593296

Hi Aindree,
No its a typo (and will be corrected soon). In the context of what was written it clearly means it was updated on 27th January. The update being that the evaluation.py file was provided so that you could test your code against it.
Thanks for bringing it to our attention.
Kind regards

**Post ID:** 593354

Hi
This would be only for a selected few questions right because say for the credit card question, where the LLM is involved, to get the card number itself, we have to give a fine-tuned and strong query.

**Post ID:** 593461

Try using the eval() function, that seemed to work for me

**Post ID:** 593493

@carlton @s.anand @Jivraj  Sir, could you please share some guidance on the above?

**Post ID:** 593507

@jivraj,@carlton
I have done the a1 to a10 task and tried querying through localhost and its working fine basically all these ten steps but dont know whether its enough or not. also steps in phase B i am confused that should we create separate endpoints for these tasks or should it be with same /run endpoint and query. then will the input be random by any user. what about the output . where should it be given. phase b needs more explanation.

**Post ID:** 593514

At what time will the session be happening tomorrow sir can you please give the details?

**Post ID:** 593593

Hi @carlton @Jivraj
Facing some issues in running my project. Taking an example of the Phase A - A3 task.
I am able to read my files through the GET/read/data/dates.txt query.
I am also able to use the count_wednesdays function through the POST/run task/count_wednesdays.
But when I am entering a query such as “count_wednesdays in data/dates.txt” I am unable to get a response.
```Image was here: The image displays a formatted output from an API response in a technical interface, likely a tool for testing web services such as Postman or a similar application. It shows an HTTP status code of 200, indicating a successful request was received by the server. Below this, the "Response body" section reveals a JSON structure containing an error message: `{"error": "Could not understand the task"}`. The JSON is presented in a dark background with green text, typical of code syntax highlighting, suggesting that the focus is on analyzing server responses and debugging API functionality. The context implies troubleshooting communication between a client and server, potentially involving natural language processing or task execution failures within an application.```image618×246 6.28 KB
Please advice. Thank you.

**Post ID:** 593646

```Image was here: The image depicts a snippet of text from a technical document or forum post, containing specific instructions for processing files. It includes two distinct points labeled "A7" and "A8". The first instruction, A7, mentions that a file located at `/data/email-sender.txt` should be processed to extract the sender’s email address. The second instruction, A8, refers to a PNG file located at `/data/credit-card.png`, which contains a credit card number. It instructs to pass this image to a large language model (LLM) to extract the card number, specifying that it should be saved without spaces to `/data/credit-card.txt`. The visible paths suggest a context of file handling and data extraction, potentially related to a software application or a script for automating data processing tasks, possibly within a Python environment or a similar programming framework. There are no visible code snippets or error messages, just plain text detailing procedural steps for file manipulation and data extraction within a software engineering context.```image1215×112 19 KB
On task A8, credit-card.png is given, but it is in credit_card.
it makes the errors. I checked that 2 to 3 tasks depend on these, and we create the ouput file with ‘-’ this only. please clarify that output and input files name ‘-’ or ‘_’   @carlton @Jivraj

**Post ID:** 593647

On tomorrow live sessions, kindly explain how to use docker, evaluations, github, what generally we have to do submit, please get some tuturials for us to submit those answers. Thankyou Sir  @Jivraj @carlton

**Post ID:** 593670

(post deleted by author)

**Post ID:** 593684

(post deleted by author)

**Post ID:** 593685

(post deleted by author)

**Post ID:** 593686

Score: 9 / 10
Almost done with A tasks. Please use this for local llm to verify output
Also Ollama doesn’t require Schemas
CHECK OUT THE REPO AND ANY INPUTS ARE WELCOME
Link to ReadMe and also repo

**Post ID:** 593709

Hi Andrew,
You have done a great job with the Phase A tasks. Very methodical, well structured, logical and even incorporates (unnecessarily) two different ways of evaluating its performance via local llm or the project proxy.
I just want to forewarn you (and others who are tempted to just blindly copy and paste) that evaluate.py is not meant to give you an exact expectation of what prompts will be sent to your application.
In other words getting 10/10 in evaluate.py does NOT guarantee 10/10 or even 5/10  or 1/10 in the real evaluation.
So do not write your code so rigidly that it will only work in the very strict interpretation of evaluate.py. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general idea of the task.
That said, evaluate.py is a good way to know what to expect. Some of Phase A tasks although given a detailed specification in the project description, will still be given challenging prompts (i.e. hard difficulty, and requires some clever self correcting mechanism). Some of the tasks will be given straight forward prompt (i.e. easy for your application).  Some of the tasks will be given with some level of parameterisation that deviates from the strict interpretation (i.e. medium difficulty).
Hope that helps with how you deal with Phase B tasks (and making your Phase A more robust to a stronger evaluation.)
A word of caution: (i.e. this is just some advice, not a set in stone recommendation) Your requirements.txt is massive. If your code does not execute a task (possibly your first task) within 20 seconds (on our server) then it will fail that task. You might want to consider a dynamic, flexible way of installing only required libraries when necessary and keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.
Kind regards

**Post ID:** 593744

Respected @s.anand @carlton and @Jivraj ,
Is anyone actively monitoring the Discourse page? I have been raising this issue for the past few days, but there has been no response. Does this mean the TAs are not addressing students’ concerns?
I am encountering the following error while running my project with these LLM endpoints:

https://api.openai.com/v1/chat/completions
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
```Image was here: The content displayed in the image appears to be a JSON-like error message formatted as a dictionary, indicating an API error with the code 429. The specific message within the dictionary states, "On 2025-02 you used $2.00229560000011, exceeding $2". This suggests rate limiting or quota exceeded for API usage, commonly associated with API services. The formatting includes escape sequences for newline characters (\n), indicating that it might be a response from a web server or API service regarding usage limits. This type of message is typically encountered in programming contexts involving API calls, suggesting troubleshooting in a software development or testing environment where monitoring of API usage is critical. The overall context is likely related to debugging or handling API usage errors in a software engineering application.```
This issue is blocking my progress, and I urgently need assistance to resolve it. Kindly provide guidance or suggest a solution at the earliest.

Looking forward to your response.
Thanks,
Telvin Varghese

**Post ID:** 593754

Hi,
I am not able to understand how to do the Project 1. The date is also very near.
The problem I am facing is, When I did the Modules the page was different, but now in the Project 1 I am not getting any section to submit the project.
Please let me know where are the questions and how tot submit that.
The deadline is near.

**Post ID:** 593756

carlton:

o do not write your code so rigidly that it will only work in the very strict interpretation of evaluate.py. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general idea of the task.


This where I need help, i tried doing with agentic framework but i failed with the model in llm proxy, which was highly suspect because, that model should have known what the uv framework but it seemed to me to be outdated. Hence executing code Interpreter tools failed as the model gave outdated code. I have raised this issue before
Hence i moved to function calling, using local llms as cost-effective solution and it was quite robust.
I just need to understand how the function should be general, maybe 2-3 tasks you could provide the general description along with all the ways one would query the agent llm(ie our project). This general function is what i need help with. Please kindly do the needful.

**Post ID:** 593765

carlton:

keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.


Any tentative size cutoff for the docker image?

**Post ID:** 593802

Hi Telvin
You have run out of tokens. Thats what the message is saying. You ran out 3 days ago. It was clearly mentioned that the limit is $1. You have exceeded $2.
```Image was here: The image captures a webpage focused on "Large Language Models" within a Data Science tools section. It outlines practical usage guidelines for large language models (LLMs) with a specific emphasis on an API subscription model, indicating potential costs associated with usage. The text highlights that API keys are provided by sending an email to a specified address, referencing specific model identifiers such as "gpt-4-0-mini" and "text-embedding-3-small." A cautionary statement points out that usage is limited to $1 per calendar month for the course. It suggests employing an "AI Proxy" instead of directly using OpenAI, with instructions to replace the API URL and the `OPENAI_API_KEY` with the corresponding `AIRPROXY_TOKEN`. The layout includes navigational elements on the left pane indicating sections like "Prompt engineering," "TDS API Instructions," and "LLM Text Extraction," suggesting it is an educational or instructional interface designed for software engineers or data scientists. The environment implies an online learning context, possibly hosted on a platform designed for technical discussions or project documentation.```Screenshot 2025-02-11 at 3.36.50 pm2078×1276 305 KB
In our current internal build of project 1, we have yet to exceed $0.50
As to whether it can be renewed is something we have still not yet decided, because the question you have raised equally would apply to everyone. Raising it for you means raising it for everyone. $1 for everyone equals raising it by $1600+ (i.e Rs 1.39 Lakhs) for us!
The budget question then involves more than one person. It also involves the BS Team Operations and not just the TDS team and therefore instead of responding with a response that is not useful, we typically try to solve the problem first and then respond.
In short we are working on it. But as we have mentioned repeatedly in our sessions, use APIs efficiently, thats part of the skill. As soon as we have a resolution we will inform everyone via an announcement and an email.
Kind regards

**Post ID:** 593807

Thanks for your response, @Carlton. It seems I won’t be able to proceed with the project until this issue is resolved. Also, I haven’t used LLM so much until February 7th to cost $2.

**Post ID:** 593809

Every request you send, gives you a response back with exactly how much that request cost. So you can track your usage.

**Post ID:** 593816

I’m aware of that. I’ve mostly noticed a cost of $0.0003 per request, so I haven’t been tracking my total monthly expenses. Moving forward, I’ll keep a record of the cost for each request. Also, do strong prompts impact the overall cost?

**Post ID:** 593820

@carlton Is the project session happening today? I don’t have the link. Can you please send it if it’s happening?

**Post ID:** 593821

Hi, where is the link for todays Project 1 demo session? @carlton @Jivraj

**Post ID:** 593822

https://meet.google.com/odh-ycbm-ahj?authuser=0

**Post ID:** 593823

request
http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt](http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt)

output
{    "detail": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid\_request\_error', 'param': None, 'code': 'invalid\_issuer'}}"}

@carlton sir I am getting this issue while running my script. Please help!

**Post ID:** 593826

I’m getting an error in task a2, def do_a2():
“”“Format markdown using prettier”“”
format_md_path = DATA_ROOT / “format.md”
subprocess.Popen([“prettier”, str(format_md_path), “–write”, “–parser”, “markdown”])
print(“data formatted successfully”)
any idea how to fix this? Also in A8, a 5 and a 3 is getting interchanged. Can someone help why that is hapening, I changed the prompt to include caution about not switching 3 and 5 as well, that didn’t help either

**Post ID:** 593832

what is  the session time?

**Post ID:** 593836

```Image was here: The image displays terminal output from a script execution in a Unix-like environment, likely related to a data science project given the file paths and commands. The user, identified as "Abhro014," is executing a Python script named `datagen.py`, located in a project directory under "Diploma/TDS/Project1." The command used is `uv run`, suggesting the use of an environment or tool related to running or managing web applications, potentially for a FastAPI or similar server.

The output indicates an error trace due to the script attempting to create a directory specified by the key `"root"` in a configuration dictionary but encountering a `PermissionError`. The error message reads: `Permission denied: '/data'`, indicating that the script lacks the necessary permissions to write to the `/data` directory. Key elements include the specific line of code causing the error (`os.makedirs(config["root"], exist_ok=True)`) and relevant paths. The script is being executed from a temporary directory, as indicated by the path `/tmp/datagen2eQ208.py`. Overall, this context suggests an activity focused on debugging a filesystem permission issue during the execution of a data generation script.```Screenshot 2025-02-11 1814531459×207 15.3 KB
Could you kindly help me with this

**Post ID:** 593884

in checking for the task of json my code is outputting json with double quotes (valid json) and evaluate.py has exact same json but with single quotes , what should I do?

**Post ID:** 593885

check out my repo and download the datagen and evaluate file for testing

**Post ID:** 593886

it should work, use fastapi text response when /read api

**Post ID:** 593897

Has anyone used a local LLM for testing? If so, could you please share the request URL and the request body format? I attempted to use a local LLM, but I was unable to succeed

**Post ID:** 593911

use ollama it is openai api compatible, supports function calling without json schema for tool usage. Check it out

**Post ID:** 593930

NEED HELP. CAN SOMEONE CONTACT OLLAMA AND ASK THEM TO CHECK THEIR CODE ITS HAS SOME SILLY MISTAKES IN CODE EXAMPLES. I DONT KNOW HOW TO DO IT.
LINK TO PAGE WITH CODE EXAMPLE
```Image was here: The image features a snippet of Python code focused on embedding documents in a vector database and retrieving relevant information based on user queries. The first part of the code iterates through a list of documents, using the `enumerate()` function to access both the index and document. Each document is embedded using the `ollama.embed()` function with the model named "mxbai-embed-large", and the resulting embeddings are stored in a collection alongside unique IDs and the original documents. The second part outlines a retrieval process, where an example input prompt asking about the relationship between llamas and other animals is processed. The input is embedded similarly, and the `collection.query()` method is used to find the most relevant document, limiting results to one. The response structure is accessed to obtain the relevant document data. The code suggests integration with a document retrieval system in contexts like natural language processing or machine learning applications.```Screenshot 2025-02-11 232608919×714 22.4 KB

correct code in step 2 collection query step
response = ollama.embed(
  model="nomic-embed-text:latest",
  input=task
)
results = collection.query(
  query_embeddings=response["embeddings"], #here embeddings and also not list of list as response embeddings already gives correct format
  n_results=1
)
data = results['documents'][0][0]

@s.anand @Jivraj @carlton

**Post ID:** 593963

@s.anand @carlton @Jivraj
While implementing the Phase B tasks, can I take the data (csv file, git repo, audio, sqlite/duckdb database, website, image and markdown file) of my choice and perform any operation on them as long as they meet the critetia mentioned in the Phase B task list? Please guide.

**Post ID:** 593966

@s.anand @carlton @Jivraj
In the Task B5, where we have to run an SQL query on a sqlite or duckdb database, should I create a database on my own and then take the query to be ran on it as an argument? Or should I take the query as an argument and run it on the ticker_sales.db in ./data folder? Please guide

**Post ID:** 593967

same issue on my side as well

**Post ID:** 593968

on using the AIPROXY_TOKEN from here https://aiproxy.sanand.workers.dev/
getting this error :
Error: Your authentication token is not from a valid issuer.
@carlton @Jivraj  please help!

**Post ID:** 593971

@carlton @Jivraj Can the link to the live session (for project) be provided?

**Post ID:** 593972

As in the previous session for task a1 we use llm just to get the url and email , so after retriving the both arguments can i use them in a function and got the work given in work done in function.
Also, am i correct that we use llm only to retrive url or location ??
@carlton @Jivraj

**Post ID:** 593974

Anyone whom have done have done any one task of phase a and one task of phase b, please help…

**Post ID:** 593976

Can you do one task from each phase in today’s session. Please @carlton @Jivraj

**Post ID:** 593977

thanks for the reply I will check

**Post ID:** 593981

TDS project  Tedious project

**Post ID:** 593993

can anyone share the link of yesterdays live session if there in youtube

**Post ID:** 593997

Its updated in the TDS live sessions playlist


```Image was here: The image features a visually engaging design with various abstract graphical elements representing data visualization concepts. Prominently displayed in the center are the words "Week 5 Session 1," implying a structured educational or training context. Surrounding this text are diverse illustrations including charts, graphs, and icons like a radar chart, pie charts, and line graphs. There are also visual elements suggestive of data analysis tools—such as rulers, pencils, and geometric patterns—indicating a focus on analytical and visualization techniques. The overall aesthetic implies an emphasis on analytics, possibly within a software engineering, data science, or management training scenario. The content could relate to courses on data visualization, analytics tools, or project management principles.```

**Post ID:** 594022

For task A2:

A2. Format the contents of /data/format.md using prettier@3.4.2, updating the file in-place

I am getting the following error:
🔴 A2 failed: Command '['npx', 'prettier@3.4.2', '--stdin-filepath', '/data/format.md']' returned non-zero exit status 1.
However, running a POST request to https://localhost:8000/run?task=Format+/data/format.md+with+prettier+3.4.2 gives successful output.
{"success":true,"message":"Formatted and verified successfully!"}% 
Here is my code snippet:
def format_file(filepath):
    while True:  # Loop until formatting and verification pass
        try:
            result = subprocess.run(
                ["npx", "prettier@3.4.2", "--write", filepath],
                check=False,  # Don't raise exception automatically
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                return {"success": False, "message": f"Prettier write failed: {result.stderr}"}

            if verify_prettier_formatting(filepath):
                return {"success": True, "message": "Formatted and verified successfully!"}
            else:
                logging.info("Verification failed. Retrying formatting...") #Log the retry
                # If verification fails, the loop continues and prettier --write is executed again.

        except Exception as e:
            return {"success": False, "message": str(e)}

def verify_prettier_formatting(filepath):
    try:
        subprocess.run(["npx", "prettier@3.4.2", "--check", filepath], check=True, capture_output=True, text=True) #Capture output
        return True  # File is formatted correctly
    except subprocess.CalledProcessError as e:
        logging.error(f"Prettier check failed: {e.stderr}") # Log the error from prettier check
        return False  # File is not formatted correctly

What am I missing here?

**Post ID:** 594041

I am getting the same error. Did you find any solution?

**Post ID:** 594042

Has anyone succeeded in the extraction of credit cards details task? The LLM seems to consider it as illegal task and if I use pytessaract the docker image size will become really large. What to do in this case?
@carlton @Jivraj

**Post ID:** 594043

Hi @carlton @Jivraj,
I followed what you taught in Feb 11 session and tried implementing task A1. My understanding is once i run the subprocess, datagen.py file should be run and /data folder should be created in the project folder. But it is not happening to me. I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/datagen4COEF3.py", line 284, in <module>
    os.makedirs(config["root"], exist_ok=True)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 227, in makedirs
OSError: [Errno 30] Read-only file system: '/data'

If i can’t automate this process, i don’t see the point writing code for other tasks. Can anyone help me solving this error?

**Post ID:** 594045

shell = true in evaluate.py, remove it meaning comment it out, task a2 thats causing the error

**Post ID:** 594046

the admin banned me from using laughing emoji  @jkmadathil

**Post ID:** 594057

For task A6,

HTTP Request: GET http://localhost:8000/read?path=/data/docs/index.json “HTTP/1.1 200 OK”

⚠️ EXPECTED:
{'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}

⚠️ RESULT:
{'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}

If I am not wrong, both the expected and actual result contain the same entries. It is just that the ordering is different. The expected result also doesnt follow any particular format (so does the actual result).
Kindly advise on this @carlton
EDIT : Resolved on a later evaluation

**Post ID:** 594058

For the task - * B10. Write an API endpoint that filters a CSV file and returns JSON data
Do we have to handle prompts for converting CSV to JSON or for writing an endpoint for doing so?
@carlton @Jivraj

**Post ID:** 594061

yeah i am also facing the same doubt

**Post ID:** 594062

+1…
@Jivraj @s.anand

**Post ID:** 594068

could someone please share their repo for reference. it would be very much helpful

**Post ID:** 594069

Dear Instructors (@carlton, @iamprasna):
Confirming, just to be needfully pedantic:
It will solely be the responsibility of the Project Evaluator (human or machine) to parse the correct AIPROXY_TOKEN generated against my IITM email ID (presumably, per some database which holds all such generated AIPROXY_TOKENs of the students who have generated one); and the correct $IMAGE_NAME (to-be-submitted by myself in the Project Submission Google Form) in podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000, correct?
Asking this seemingly obvious question, as (apparently) the actual AIPROXY_TOKEN is not to be included anywhere in the code, or the repository, or the dockerfile.

**Post ID:** 594074

I am also facing the same issue, just that the ordering is different.
Sorting by keys also didn’t help.
Please help on this @carlton @Jivraj

**Post ID:** 594086

sir will the tasks of Phase A and Phase B change? like currently do we need to make llm write the code for all tasks dynamically or can we write a pre defined python code to execute tasks after the llm parses the task and runs python code

**Post ID:** 594087

Check length of result and length of expected, one is 98 and other is 298
expected = {'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}
result  = {'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}
print(len(set(result)), len(set(expected)))
count = 0
print("length of result", len(result))
print("length of expected", len(expected))
for y in result:
    if y not in expected:
        count += 1
        print(f"{y}:{result[y]} IS EXTRA FILE")
        print(count)

**Post ID:** 594091

s.anand:

A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub


Sir there is an error in the evaluation script for task A1, url - https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py doesn’t exist,
instead this should - https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

**Post ID:** 594109

@23f2001978
That error is usually if you are using the wrong endpoint (ie. using open ai libraries instead of sending requests to aiproxy).
Without seeing the request its hard to tell you what the cause of the error is.
Kind regards

**Post ID:** 594121

@21f2000709 @23f1002382
B10 → Create a service that creates a specified endpoint that receives a CSV and returns a JSON data . Where the JSON is expected, whether in the response body of the endpoint , or in a file will be specified by the task master 
Kind regards

**Post ID:** 594129

hi @carlton @Jivraj
for A2 i am getting this particular error and i don’t know what i am doing wrong in this
```Image was here: The image displays a terminal interface showing the output of a task to format a Markdown file located at `/data/format.md` using the Prettier code formatter version 3.4.2. It features an HTTP POST request to `http://localhost:8000/run/format` with specific arguments including the function name `format_file_with_prettier`, the file path `/data/format.md`, and the Prettier version used. The console output confirms an HTTP 200 response status, indicating the request was successful. Additionally, there is a GET request shown for `http://localhost:8000/read/path/data/format.md` that also returned a 200 OK status. The result shows the formatted Markdown with noted extra spaces and trailing whitespace, further listing items labeled as “First item,” “Second item,” “Third item,” and “Fourth item.” There is also a Python snippet: `print("user@example.com")` at the bottom, suggesting it might be used for displaying user-related information. The context indicates usage within a local development environment, likely while debugging markup formatting in a practical software engineering scenario.```Screenshot from 2025-02-12 19-31-471501×564 44.7 KB

**Post ID:** 594131

issue with evaluate.py , post the code snippet in task a2, where it calculates the result and checks with expected.

**Post ID:** 594133

you mean screenshot of evaluate.py file?
```Image was here: The image displays a segment of Python code within a code editor, likely Visual Studio Code, focused on asynchronous file handling and formatting. The function definition `async def a3(email: str, file: str, **kwargs):` indicates that it deals with an email and a specific file path. It imports necessary functionalities from `subprocess` for running an external command, specifically with a focus on using the `prettier` tool for formatting JavaScript or Markdown files. The code snippet shows a call to `get_markdown(email)` and prepares to run the command with `subprocess.run`, capturing output and ensuring that the execution is compatible with Windows environments. The method checks whether the reformatted content matches the expected result after reading the file through `await read(file)`. Specific configurations like `input=True`, `capture_output=True`, and `text=True` highlight the handling of standard input/output. The intention is to format the contents of the file using `prettier@3.4.2`. Overall, the snippet is primarily concerned with debugging or ensuring proper file formatting in an asynchronous context.```Screenshot from 2025-02-12 20-21-561501×564 61.8 KB

**Post ID:** 594143

running in docker?
////////////////////////////

**Post ID:** 594144

Yes, I commented out check=True to see the error

**Post ID:** 594158

@carlton @Jivraj
could you please help me out on how to start with TDS Project-1, as I am stuck at the moment and don’t know where to start from. This project is very much unfamiliar for me and I need some guidance on how to start with it. It would be really great if you could provide some help through resources/materials/videos and help me complete the project. Thanks in advance!

**Post ID:** 594167

then im not sure exactly wait lemme check

**Post ID:** 594169

issue with evaluate py, specifically , how it formats the file, maybe shell=True should be uncommented if commented out. then im not sure. Im not in composing docker files yet

**Post ID:** 594177

Could anyone please help me with the project… I am trying to do it but I’m always getting errors even while starting.

**Post ID:** 594189

My final docker image size is coming 1.25 gb, I am using the ubuntu base image as I thought it would be appropriate given the tasks. Is it ok with that size?
PS - Also I would be running out of token if I need to test again with some other base image now.
@carlton

**Post ID:** 594190

Go through the week 1-3 assignments once, you would be good to go with Phase A tasks.
@23f2003413 @AnvithaV

**Post ID:** 594192

You do not need the whole of ubuntu!
Just python and uv
More like 128mb image.
Please watch Tues week 5 session 1
Kind regards

**Post ID:** 594194

Will there be more live sessions on project ?
@carlton

**Post ID:** 594196

I could pull it down to 610 mb, using python:3.9-slim now, but there are some essential libraries that is needed which is taking up the space…will it be ok? I mean installing on the go with uv might lead to timeout during evaluation…

**Post ID:** 594202

How did you corrected it ?

**Post ID:** 594210

I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb

**Post ID:** 594215

could you help later, when i need to construct docker image, via gmeet? PLEASE

**Post ID:** 594216

ANY SUGGESTIONS (just one digit away) ::
import easyocr
from pathlib import Path
import re

def extract_credit_card_number(input_image: str, output_file: str):
    
    input_path = Path(f".{input_image}")
    output_path = Path(f".{output_file}")

    if not input_path.exists():
        raise ValueError(f"Image file {input_path} does not exist.")

    # Step 1: Use OCR to extract text from the image
    reader = easyocr.Reader(['en'])
    try:
        result = reader.readtext(str(input_path))
    except Exception as e:
        raise ValueError(f"OCR processing failed: {str(e)}")

    # Combine all extracted text into a single string
    extracted_text = " ".join([text for (_, text, _) in result])

    # Step 2: Use the LLM to refine the extracted text and extract the credit card number
    prompt = f"""
    The following text was extracted from an image. It may contain a credit card number. 
    Extract the credit card number and return only the number without spaces or dashes. 
    If no credit card number is found, return "None".

    Extracted text: {extracted_text}
    """
    try:
        response = chat_completion(prompt)
        card_number = response.get("choices", [])[0].get("message", {}).get("content", "").strip()

        # Validate the card number (basic check for 16 digits)
        if card_number.lower() == "none" or not card_number.isdigit() or len(card_number) != 16:
            raise ValueError("No valid credit card number found in the image.")

        # Write the card number to the output file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(card_number)

        return f"A8 Completed: Credit card number extracted and written to {output_file}"
    except Exception as e:
        raise ValueError(f"Failed to process text with LLM: {str(e)}")

 /data/credit-card.txt
⚠️ EXPECTED:
4026399336539356
⚠️ RESULT:
4026399338539356

**Post ID:** 594218

<Response [200]>
{‘id’: ‘chatcmpl-B0De8V66WZAucAweJe6e32BWSLnpT’, ‘object’: ‘chat.completion’, ‘created’: 1739392156, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: “I’m sorry, but I can’t assist with that.”, ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘stop’}], ‘usage’: {‘prompt_tokens’: 874, ‘completion_tokens’: 11, ‘total_tokens’: 885, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_bd83329f63’, ‘monthlyCost’: 0.048128640000000014, ‘cost’: 0.0026880000000000003, ‘monthlyRequests’: 51}
def query_gpt_image(image_path: str, task: str):
    print("🔍 Image Path:", image_path)
    image_format = image_path.split(".")[-1]
    with open(image_path, "rb") as file:
        image_data = base64.b64encode(file.read()).decode("utf-8")
    response = requests.post(
        "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {"APIKEY"}",
                "Content-Type": "application/json"},
        json={
            "model": "gpt-4o-mini",
            "messages": [
                {
                "role": "user",
                "content": [
                    {"type": "text", "text": task},
                    {
                    "type": "image_url",
                    "image_url": { "url": f"data:image/{image_format};base64,{image_data}" }
                    }
                ]
                }
            ]
            }
                     )
    response.raise_for_status()
    print(response)
    print(response.json())
    result = response.json() 
response = query_gpt_image("data/credit_card.png","Extract the credit card number from image")

Why is this not working?
EDIT: Requires prompt engineering as “credit card” is sensitive information 
<Response [200]>
{‘id’: ‘chatcmpl-B0Dlie1ZIS68PZBCT0XJKhLKbyPAC’, ‘object’: ‘chat.completion’, ‘created’: 1739392626, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: ‘The numbers extracted from the image are:\n\n- 3009 1429 5211 59\n- 09/29\n- 113’, ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘stop’}], ‘usage’: {‘prompt_tokens’: 871, ‘completion_tokens’: 31, ‘total_tokens’: 902, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_bd83329f63’, ‘monthlyCost’: 0.05092764000000002, ‘cost’: 0.002799, ‘monthlyRequests’: 52}
response = query_gpt_image("data/credit_card.png","Extract number from image")

**Post ID:** 594228

Sir in main.py file I’m defining task with different variables . But in evaluate.py tasks are defined by different variables to test and when I’m testing it using python evaluate.py it returns unsuccessful . I’m testing all my tasks of main.py with Postman it returns successful.
My query is that how the tasks get evaluated and do i need to change my variables in main.py ? And what are the other things i have to change.
Also plss update evaluate.py fie with phase B tasks
@s.anand @carlton @Saransh_Saini

**Post ID:** 594235

@22f3001777
Yes there will be one more session today (13th Feb) at usual time 8pm to 10pm
Kind regards

**Post ID:** 594241

Hi instructors and TAs,
For the different tasks in Phase B, I don’t have a clear idea of what type of a response you expect.
eg.

Run a SQL query on a SQLite or DuckDB database & Extract data from (i.e. scrape) a website & Transcribe audio from an MP3 file - Do you want the query’s response on an output file like A10? or as a response?

I understand that these are broad problems you except us to solve, but it would be helpful to know what type of response you would require.
Thanks,
Trebhuvan

**Post ID:** 594247

Hi,
Pls tell us how to use evaluate.py script to check our codes

**Post ID:** 594250

Output specifications will be detailed in the “task” sent to the endpoint.
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve all tasks using the same function !
Kind regards

**Post ID:** 594252

Okay sure!! Ping me when you require to generate…

**Post ID:** 594254

Hello sir,
Is yesterday’s session not uploaded to YouTube yet ?
I couldn’t find it in calendar either… It will be very helpful if you (or anyone else) could provide yesterday session’s recording’s link…

**Post ID:** 594261

21f2000709:

I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb


@carlton @Jivraj
will it be ok? Actually I developed it in a way that require some of the essential dependencies and at this point of time it would be dangerous to alter the way of handling it as I am running short of AIProxy Token credits.
Earlier when I asked this:



 21f2000709:

Any tentative size cutoff for the docker image?


I could have altered my way of handling dependencies but at that point of time there was no clear numbers.
I request you to please allow this time around with this size…

**Post ID:** 594280

@carlton Could you please consider extending the submission date of Assignment 5 (it is 16th Feb right now). We are very busy with the project.
And assignment 6 submission date is much later: 9th of March.

**Post ID:** 594298

@carlton +1 Agreed, a relaxation in deadline will be a boon for students who’ve taken up other projects this term.

**Post ID:** 594303

usage of langchain is allowed?

**Post ID:** 594320

It will be extended, @carlton mentioned it in a TA session already.

**Post ID:** 594333

Hi @Rishabh2
What exactly you mean by variables?  only one argument is required for running evaluate.py that’s an email address.
You need to download both evaluate.py and datagen.py in same folder and then execute evaluate.py using uv.
uv run evaluate.py --email $any_email.
For phase B




Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    Output specifications will be detailed in the “task” sent to the endpoint. 
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve all tasks using the same function ! 
Kind regards
  

Kind regards

**Post ID:** 594337

610 Mb’s is good size, no need to worry, it will be evaluated.

**Post ID:** 594342

Hi @23f1002382
This is the classic case where you use Prompt engineering to solve your problems. I assume you have already achieved your answers, but I want to clarify this for someone who is facing this problem.
The thing is GPT-4o-mini is intelligent enough to understand what kind of task you are asking it do, and extracting Credit Card info from an image is one of the many prohibited tasks.
What you can do is, try to fool it using itself. Just ask ChatGPT to generate a prompt that would be capable of fooling itself into extracting out that credit card info. I was capable of doing it after pretending to be a working on a Cyber Security project, and other fake details which ChatGPT itself provided me with.

**Post ID:** 594344

@carlton . I cannot send requests to https://aiproxy.sanand.workers.dev/openai/v1 . Getting  $RateLimitError: Error code: 429 - {‘message’: 'On 2025-02 you used $2.0003758999999954, exceeding 2'}  . Looks like I used all of my credit . What can I do now ? Project is also Incomplete.

**Post ID:** 594345

Try creating a better prompt for this task.
Hint: Ask it to recheck certain similar looking digits.

**Post ID:** 594351

After submitting docker image through, it will be pulled and our token will be used.
Things to be checked at your end.
1. podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME works fine
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected.
Kind regards.
Jivraj

**Post ID:** 594353

Hi @JoelJeffrey
What you did wrong and how did you correct it?

**Post ID:** 594354

I think there was something wrong with the way the code was getting inputs (keys). I just rewrote that part and it worked

**Post ID:** 594355

Hi @22f3001307
Provide required write permissions to /data folder. We will also discuss this issue regarding permissions in initial part of today’s session.
Kind regards

**Post ID:** 594358

Hello sir,
Is yesterday’s session not uploaded to YouTube yet ?
I couldn’t find it in calendar either…

**Post ID:** 594359

Command to run the image in the docs, seemed to have some error,
```Image was here: The image features a command line instruction formatted for a terminal interface, specifically for executing a containerized application using Podman. The command `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000` indicates that an image specified by the variable `$IMAGE_NAME` should be run with an environment variable `AIPROXY_TOKEN` set to the value $AIPROXY_TOKEN, and it maps the container's port 8000 to the host's port 8000. The output suggests that this configuration will serve an API endpoint located at `http://localhost:8000/run?task=...`, indicating an interactive component likely related to API requests or task execution. The overall context reflects a setup process for a backend service, possibly written in a programming language suitable for web APIs, emphasizing the usage of containerization for deployment.```
The command:
podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000
gives the error:
crun: executable file `-e` not found in $PATH: No such file or directory: OCI runtime attempted to invoke a command that was not found
However the correct command seems to be:
podman run -e AIPROXY_TOKEN="$AIPROXY_TOKEN" -p 8000:8000 $IMAGE_NAME
This works totally fine.
```Image was here: The image displays a terminal interface output from a macOS environment, indicating the execution of a command using Podman, a container management tool. The command is structured to run a containerized application from the specified project directory 'tds-project-pradeep-mondal' while passing an environment variable 'AIPROXY_TOKEN'. The log messages show the server's operational status, including that the server process has started, it is waiting for application startup, and that the application has successfully started. The final line indicates that Uvicorn, an ASGI server commonly used with Python web frameworks like FastAPI, is running on the address http://0.0.0.0:8000, with instructions to press CTRL+C to quit, highlighting the setup of a development environment for a web application.```
@Jivraj

**Post ID:** 594361

nvm i can laugh nw xD

**Post ID:** 594372

One final question @Jivraj @carlton , will our projects be evaluated with our AIPROXY_TOKEN or a different one.
Because my project is done but for evaluation if my AIPROXY_TOKEN is used, it might be out of credits.

**Post ID:** 594378

Thanks. Do you know the new date?

**Post ID:** 594385

That wasn’t said, but it was not this weekend for sure.

**Post ID:** 594394

my automation is happening and prompt distribution too but it just isnt able to pass any test after 1st in evaluation.py did someone else face same problem if yes then how to solve it please help

**Post ID:** 594398

actually that easyocr is directly sending the clear text(no confusion) to llm and llm is just extracting the  exact numbers from it .

**Post ID:** 594409

[quote=“23f2001975, post:211, topic:164277, full:true”]
@s.anand @carlton
While running the evaluation.py i am facing several issues because my output isnt strictly adhering sometimes to it will the checking be on such a basis only
for example in A3
 EXPECTED:
129
 RESULT:
“129”
this is the error i get while it is the function in eval.py checking problem as it gets response as text and doesnt strip (“”)
Please guide what should i do

**Post ID:** 594416

21f2000709:

podman run -e AIPROXY_TOKEN=“$AIPROXY_TOKEN” -p 8000:8000 $IMAGE_NAME


Yes this is correct command, we will update in project page.

**Post ID:** 594420

Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    After submitting docker image through, it will be pulled and our token will be used. 
Things to be checked at your end. 
1. podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME works fine 
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected. 
Kind regards. 
Jivraj

**Post ID:** 594421

@Jivraj sir I get this error
but my app.py is able to get the server running on localhost and not on 0.0.0.
```Image was here: The image displays a console output from a terminal session, showing an error traceback related to a Python application. The user, identified as "vikramjncasr@ANJANEYA," is attempting to run a command using Podman (`podman run 20511982f949`) from the directory `/mnt/c/IIT_Madras/TDS_Project`. The error message indicates a `ModuleNotFoundError`, specifying that the Python script located at `/app/app.py` on line 1 failed to import the FastAPI module. This suggests that the FastAPI library is not installed or recognized in the current environment, which may indicate issues with the Python environment or dependencies for this project. The terminal prompt is indicative of a Linux-like shell environment.```image1014×190 18.2 KB
could you please help ?

**Post ID:** 594422

When i am trying evaluate the code, I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/evaluateyea70I.py", line 20, in <module>
    from datagen import (
    ...<9 lines>...
    )
ModuleNotFoundError: No module named 'datagen'

can someone tell me what i should do?
@carlton @Jivraj @Saransh_Saini

**Post ID:** 594424

@22f3001307
Install datagen.py in the same folder from where you are executing evaluate.py.
@vikramjncasr Check how you are executing, use uv or else install required modules globally
Kind regards

**Post ID:** 594426

Sir,
the folder already exists in that folder
besides, I am using OPENAI_API_KEY=$AIPROXY_TOKEN uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py from Anand sir’s page to run the code in my system

**Post ID:** 594427

Sir would the belowformat be ok when you evaluate ?
```Image was here: The image displays a command line interface (CLI) output from a PowerShell terminal, indicating the activity of starting a Uvicorn server for a project located in the directory `C:\IIT_Madras\TDS_Project`. The command executed is `uvicorn app:app --host 127.0.0.1 --port 8000`, signifying that the server is hosted locally on the IP address `127.0.0.1`, port `8000`. The console output includes several informational logs, such as "Finished server process", "Started server process", "Waiting for application startup", and "Application startup complete". Additionally, it states that the Uvicorn server is running on `http://127.0.0.1:8000`, with a final line confirming a successful HTTP GET request having a response status of `200 OK` for `127.0.0.1:54184 - "GET / HTTP/1.1"`. This indicates the context of running an asynchronous web application likely developed with FastAPI or a similar framework that utilizes Uvicorn as the ASGI server.```image985×211 24.1 KB

**Post ID:** 594428

But when I use podman i keep getting errror.

**Post ID:** 594438

Hello,
Can anyone please reset my AIProxy limit. I am getting this error, {“detail”:“Agent error: 429 Client Error: Too Many Requests for url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions”}
Thank you.

**Post ID:** 594439

i am getting unauthorized error in A9 again and again, i have pasted my code if someone can help please look into this.
# /// script
# requires-python = ">=3.11"
# dependencies = [
#   "numpy",
#   "httpx",
#   "fastapi",
# ]
# ///


import httpx
import numpy as np
import datetime
import os

from fastapi import HTTPException


now = datetime.datetime.now()

OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"


# async def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
    # """Calculate cosine similarity between two texts."""
    # emb1 = await embed(text1)
    # emb2 = await embed(text2)
    return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))


# async def embed_list(text_list: list[str]) -> list[float]:
async def embed_list(text_list: list[str]) -> list[float]:
    OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
    OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"
    """Get embedding vector for text using OpenAI's API."""
    try:
        async with httpx.AsyncClient() as client:
            # with httpx.AsyncClient() as client:
            response = await client.post(
                # response = httpx.post(
                OPENAI_API_URL,
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                
                json={"model": "text-embedding-3-small", "input": text_list},
            )
        # print(f'{response.json()["data"][0]["embedding"]}')
        emb_list = [emb["embedding"] for emb in response.json()["data"]]
        print(f"Number of embeddings returned = {len(emb_list)}")
        return emb_list

    except KeyError as e:
        print(f"INSIDE EMBED_LIST IN A9. KeyError occurred while querying GPT: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    except Exception as e:
        print(f"INSIDE EMBED_LIST IN A9. General Error while querying gpt: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def most_similar(embeddings):
    # Extract the phrases and their corresponding embeddings
    phrases = list(embeddings.keys())
    emb_values = list(embeddings.values())

    # Initialize variables to track the maximum similarity
    max_similarity = -1  # Start with the smallest possible similarity value
    most_similar_pair = None

    # Compute cosine similarity between each pair of embeddings
    for i in range(len(emb_values)):
        for j in range(i + 1, len(emb_values)):  # Avoid repeating pairs
            similarity = get_similarity_from_embeddings(emb_values[i], emb_values[j])
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_pair = (phrases[i], phrases[j])

    return most_similar_pair


# async def get_similar_comments(input_file_path: str, output_file_path: str):
async def get_similar_comments(input_file_path: str, output_file_path: str):
    print(f"Reading the input file: {input_file_path}")
    with open(input_file_path, "r") as file:
        comments = file.readlines()

    print(f"Embedding the comments")
    # embeddings = await embed_list(comments)
    embeddings = await embed_list(comments)
    embed_dict = dict(zip(comments, embeddings))
    most_similar_pair = most_similar(embed_dict)
    print(f"Most similar comments: {most_similar_pair}")

    with open(output_file_path, "w") as file:
        for comment in most_similar_pair:
            file.write(f"{comment.strip()}\n")
        # file.write(f"Most similar comments: {most_similar_pair}")


if __name__ == "__main__":
    # import asyncio

    input_file_path = "/data/comments.txt"
    output_file_path = "/data/similar_comments.txt"
    # asyncio.run(get_similar_comments(input_file_path, output_file_path))
    get_similar_comments(input_file_path, output_file_path)

**Post ID:** 594447

@Jivraj @carlton sir can you take my doubt in today’s session please , i have successfully run docker server but endpoints are not working…
```Image was here: The image displays a development environment where a FastAPI application is being developed and tested. On the left, a web browser is showing a local server response from `http://localhost:5000`, which returns a JSON object with an error message indicating `{"detail": "Not found"}`, suggesting a possible routing or endpoint issue. On the right side, the code editor (likely Visual Studio Code) shows the `app.py` file containing a FastAPI application setup. The code snippet includes imports from `fastapi`, a defined route in the FastAPI application that responds with "Hello from the Automation Agent", and logging configuration using `logging.basicConfig`. Below, there are terminal logs reflecting a Git operation that includes `3 files changed`, `3 insertions`, and `2 deletions`, indicating updates made to the repository. The terminal also shows commands executed, such as pushing changes to the remote repository. The context includes Python programming, web application development, and source control management.```Screenshot 2025-02-13 1659121917×1024 124 KB
If anyone have knowledge about this , please help

**Post ID:** 594449

How did u resolve the issue?  @JoelJeffrey

**Post ID:** 594451

I am also facing the same issue.
Evaluation Output:
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

🔴 A9 failed: 'data'

❌ A9 FAILED

I sense ‘Authentication Problem’ happens only with the evaluation script, as the curl requests seems to work fine.
INFO:httpx:HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 200 OK"
INFO:     127.0.0.1:60849 - "POST /run?task=%60%2Fdata%2Fcomments.txt%20contains%20a%20list%20of%20comments,%20one%20per%20line.%20Using%20embeddings,%20find%20the%20most%20similar%20pair%20of%20comments%20and%20write%20them%20to%20%2Fdata%2Fcomments-similar.txt,%20one%20per%20line HTTP/1.1" 200 OK

Any views? @carlton @Jivraj

**Post ID:** 594512

@Jivraj @carlton Sir i keep getting this error
```Image was here: The image displays a terminal output from a command line interface, indicating the execution of a Python application using the command `uv run app.py` within the context of a project named "tds-project-1." The username is "vidushilinux," and the current directory is shown as `~/tds-project-1`. Following the command, there is a traceback error indicating a failure in the execution, specifically a `ModuleNotFoundError` related to the FastAPI module. The error message states "No module named 'fastapi,'" highlighting that the FastAPI library is not installed or accessible in the current Python environment. The file path for the Python script is presented as `/home/vidushilinux/tds-project-1/app.py`, with the error originating from line 9 of this script where the import statement for FastAPI is located. This setup suggests that the user is attempting to run a web application built with FastAPI.```image671×109 8.64 KB
even though i have downloaded the packages globally and tried installing them by making a venv but nothing seems to work please help

**Post ID:** 594531

what is the base url?

**Post ID:** 594556

use your api key guys

**Post ID:** 594557

we are using that only bro, only for A9 it says unauthorized

**Post ID:** 594558

network mapping or something, even im working that out

**Post ID:** 594559

Even i am facing the same problem. I am unable to resolve it ,i tried many ways.
could anyone please help

**Post ID:** 594561

2 ways, try command line package installing, or inside venv, try which python,etc and make paths reconcile, or inside venv, uv pip install , if that doesn’t work, inside venv pip install

**Post ID:** 594564

thanks , already it work out

**Post ID:** 594621

@Jivraj @carlton sir please help
When I am downloading the data folder after processing datagen.py , it is trying to download in root folder and it is facing permission error . how can we overcome this ?
needs sudo permission all the time…
```Image was here: The image displays a terminal window with a command-line interface, likely within a Unix-like operating system. The prompt indicates a user named "vikramjcasr," currently located in the directory `/mnt/c/IIIT_Madras/TDS_Project/`. The user has executed the command `ls /`, which lists the contents of the root directory. The output reveals several subdirectories including `bin`, `boot`, `etc`, `init`, `lib`, `lost+found`, `mnt`, `proc`, `run`, `media`, `opt`, `root`, `sbin`, `snap`, `sys`, `tmp`, `usr`, and `var`, with the directory `lib.usr-is-merged` appearing twice, indicating a possible symbolic link or merged filesystem. The terminal suggests a focus on file system navigation and possibly configurations or data management related to a project in the TDS (Technical Development Studies) context. The visible command output and structure imply activities related to exploring file paths or preparing for data handling tasks.```image1368×124 19.9 KB

**Post ID:** 594626

Hello Sir @carlton @Jivraj
What are implications on missing the project 1.
Due to some personal reasons I wasn’t able to start any work on my project 1. It seems difficult for me to complete it.
Could you please tell what will be the implications of missing it. Will I in anyway be able to cover up and pass in the subject doing future assignments and projects?
Thank you
PS: This isn’t any request to extend dates. I accept my fault and respect the dates provided by the team.

**Post ID:** 594642

Sir I haven’t initaiated the podman earlier.
Now when i try to use podman using the wsl via the code “sudo apt install -y podman” it is asking for the password…
The problem is:

I haven’t set any password for podman earlier.
Though it is asking for password but it is not taking any input.(ie I am unable type anything there).
what should I am supposed to do…
```Image was here: The image displays a terminal interface likely within a Visual Studio Code (VSCode) environment, showing a series of console outputs related to a Unix-like operating system command-line activity. The user, identified as "psychocode2011," is attempting to run several commands requiring superuser privileges, denoted by the use of "sudo." The commands include `sudo apt update` and `sudo apt install -y podman`, indicating that the user is updating package lists and installing Podman, a container management tool. Multiple prompts for the user's password are visible, with messages indicating incorrect password attempts. The terminal is organized in a dark theme, and the right pane appears to show a file explorer likely listing directories or files relevant to the user's project. The ongoing activity suggests a focus on software environment setup or package management within a development environment.```image1612×359 21.3 KB

**Post ID:** 594654

@s.anand @Jivraj I think the evaluation.py test case is broken for A8 because I can manually see more folders and markdown files than the expected case output of A8 evaluation. And also is there any evaluation file for Part B

**Post ID:** 594657

password are not visible in wsl when typed, just type and enter if it matches, the process will continue

**Post ID:** 594660

Sir If possible please extend the Project deadline.

**Post ID:** 594677

same error the execution is correct but format.md file is not modified with correct markdown format

**Post ID:** 594685

@carlton @Jivraj
can u please upload the video that was recorded on 12th Feb, as I am able to view only the video that was last recorded on 11th Feb (3 hrs 57 mins video). As I am doing the project completely from the recorded videos, please post those videos in youtube at the earliest.

**Post ID:** 594689

Hi @23f2003413
Because of some technical issues we could not record 12 Feb session. That was doubt clearing session regrading project1.
Kind regards

**Post ID:** 594692

Can we submit project number of times before deadline…

**Post ID:** 594696

thanks for you feedbacak I have figured it out! Thanks it means a lot…

**Post ID:** 594701

A silly Doubt though but still a doubt!
Could we create an image first of our project in initial stage(ie the my “app.py” is not completely ready) but I have build an docker image including the app.py and other dependencies.
Should I give the same url now and then carry on updating the app.py
Or, Should first complete and then upload in the form!
plz reply!!

**Post ID:** 594785

Can you send the link for the video on 11th Feb?

**Post ID:** 594794

How did you resolve the file cannot be found error?

**Post ID:** 594823

```Image was here: The image displays a console output related to a program attempting to process a credit card image. It shows a running task for a specified image file located at `/data/credit_card.png`, aiming to extract the credit card number and save it to `/data/credit-card.txt`. The output includes several HTTP requests with POST and GET methods directed to `localhost:8000`, revealing a sequence of errors. A 500 Internal Server Error is indicated, stating "Error extracting credit card: Image file ... does not exist." A subsequent GET request responds with a 404 Not Found error for the same text file, and additional failures with error messages such as "A8 failed: Cannot read /data/credit-card.txt" and "A9 failed: 'data'." The context suggests a debugging session related to file handling and HTTP API interactions, potentially using Python or a similar environment where local server operations are applied. The visible structure includes elements like request URLs, error codes, and file paths indicative of a configuration or coding problem concerning file accessibility and retrieval.```image872×550 16.5 KB
pls help with this error

**Post ID:** 594831

Sir, could you please mention the title of youtube videos in which the project session are covered?

**Post ID:** 594837

Hi,
When yesterday’s recorded video will be uploaded in youtube?

**Post ID:** 594842

Thanks for the prompt reply @Jivraj . I have done the project setup till whatever was covered on the 11th Feb session. I am not able to proceed further as I have no clue on how to work on this. Can you please help me out as it would mean a lot.

**Post ID:** 594844

@carlton @23f1002382

**Post ID:** 594845

```Image was here: The image features a vibrant visual representation labeled "Week 5 Session 1," incorporating various abstract icons and graphical elements commonly associated with data visualization and analytics, such as pie charts, line graphs, and statistical plots. The design includes geometric shapes and drawing tools symbolizing programming or data analysis activities. Although no explicit code, error messages, or specific programming environments are visible, the overall context suggests a focus on analytics, possibly within a software engineering curriculum or workshop dealing with data science or visualization techniques. Tools or technologies might include data analysis libraries or platforms, but these are not directly indicated in the imagery.```

**Post ID:** 594846

Are you subscribed to the TDS channel? If you were it would notify you immediately when it was uploaded. (10am this morning).
Please subscribe to the channel. It was also on the main page for TDS.
https://tds.s-anand.net/#/README

```Image was here: I'm unable to process the content of images directly. However, if you can provide me with a text description or key details from the image, I can help you formulate a detailed semantic embedding based on that information.```
YouTube


```Image was here: The image features a visually engaging design centered around the phrase "TOOLS IN DATA SCIENCE", prominently displayed in bold typography. Surrounding the text are various graphical elements representing a variety of data science tools and concepts, such as icons for laptop computers, charts, graphs, and data flow diagrams. There are abstract representations of databases, code snippets, and network connections. The color palette is vibrant, incorporating shades of blue, red, yellow, and green, emphasizing the multifaceted nature of data science. The imagery suggests a focus on software engineering practices, data visualization, and analytics methodologies, making it suitable for discussions about data science technologies and tools like Python libraries, data processing frameworks, and statistical analysis software commonly used in the field.```
Tools in Data Science
Share your videos with friends, family, and the world





Kind regards

**Post ID:** 594849

Thanks sir, Now I subscribed to the channel.

**Post ID:** 594852

Hi @carlton sir! Is this video (Week-5 Session-3) the continuation video from the previous session (Week-5 Session-1), since the Session-2 video has not been recorded and uploaded. I am totally relying on these videos to complete the project sir. Please help me out!

**Post ID:** 594859

offical answer is you dont, you let run it in docker and it would apparently work , im not there yet, bus as of of now , create your docker image and start testing there

**Post ID:** 594862

The deadline is at 11:59 pm right Saturday? Feb 15th? Google Standard Time?

**Post ID:** 594863

Yes feb 15 11:59 PM indian standard time.

**Post ID:** 594865

Hi @23f2003413
Session 3 was continuation of session1.
Session 2 was DCS(doubts clearing session)
Kind regards

**Post ID:** 594868

Got it. Thank you sir!

**Post ID:** 594870

Hi @Jivraj, @carlton, @Saransh_Saini sir,
I’m getting the following error while post mapping, I couldn’t able to fix it.
I’m getting status code as 400 from the llm api response. How to fix it sir?
   "json": {
        "message": "Invalid JSON body: SyntaxError: Unexpected token 'm', \"model=gpt-\"... is not valid JSON"
    }

**Post ID:** 594873

There is some problem with the json that you are using.
Try to debug it with GPT.

**Post ID:** 594874

week5 session 1 and session3

**Post ID:** 594875

```Image was here: The image displays a Visual Studio Code interface, with a pop-up error message indicating that "The window is not responding." This window suggests options to "Reopen," "Close," or "Keep Waiting." Below the pop-up, a partial code snippet is visible, showing a comparison operation (`10 == 0`) and a reference to an environment variable (`os.environ.get("AIPROXY")`). The context indicates an issue in executing code potentially related to API proxy settings, highlighting a debugging scenario. The bottom panel shows the "TERMINAL" section, likely indicating active processes or environments related to the user's coding activity, with an emphasis on Python environment management. This scenario reflects common challenges encountered during software development, particularly in troubleshooting unresponsive applications or script executions.```image929×427 11.7 KB
Is someone else are also getting this kind of error messages…
I have a low end system, then shifted to high one then again this popped up…
Does anyone know how to come over this…

**Post ID:** 594887

Hello @carlton @Jivraj @Saransh_Saini sir, I have implemented the code for B3 & B6 but unfortunately as per the instructions given in project for B3 & B6 —


B6. Extract data from (i.e. scrape) a website


B3. Fetch data from an API and save it


They are almost similar and it’s getting confusing in both cases, it’s given output based on B3 and not reading the input for B6, so could you please help me out with this?
Is anyone else facing this or a similar issue?

**Post ID:** 594890

Two solutions

give proper permissions.
use docker containers this is what we will test on.

I would prefer 2nd approach

**Post ID:** 594892

For B tasks use LLM to write code on the fly and execute it, use better prompts. In evaluation script detailed task will be provided with what data needs to be scraped, endpoints, parameters, etc.

**Post ID:** 594895

{‘error’: {‘message’: “Invalid ‘tools[6].function.description’: string too long. Expected a string with maximum length 1024, but got a string with length 4384 instead.”, ‘type’: ‘invalid_request_error’, ‘param’: ‘tools[6].function.description’, ‘code’: ‘string_above_max_length’}, ‘monthlyCost’: 0.08569882000000002, ‘cost’: 0, ‘monthlyRequests’: 82}
i cant send long prompts then what is the point?

**Post ID:** 594896

local llm also we cant use you because you have some limit on file size, we send long prompt also it doesn’t work xD . What do we do?
@s.anand @carlton @Jivraj @anybodywhowouldatleastreplyONCE

**Post ID:** 594899

Hi,
If you read these questions carefully then they are not similar, one is asking you to extract data from a webpage, meaning you have to do something related to the HTML code. And the other is simply sending a request to a given endpoint.

**Post ID:** 594912

Hi @carlton @Saransh_Saini @Jivraj ,
In task A6
Find all Markdown (.md ) files in /data/docs/ . For each file, extract the first occurrance of each H1 (i.e. a line starting with #  ). Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title (e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...} ).
Here expected output JSON “key” is file name or file path without prefix /data/docs/ as prompt is bit confusing . when “path/to/large-language-models.md” is given in example is actually referring to file path or filename itself is “path/to/large-language-models.md”.

**Post ID:** 594917

This can easily be checked by runing the evaluate.py file.
Anyways, a file present in data/docs/folder_a/folder_b/md_file should be folder_a/folder_b/md_file as key.

**Post ID:** 594919

hey @23f2001975 did you find the solution to this problem ?
i am facing the exact same issue

**Post ID:** 594944

@carlton
Sir, my token limit has crossed the $1 limit. Will I receive new limit or a fresh token ? I still need to complete my project.
Thank you

**Post ID:** 594945

/data/credit-card.txt
 EXPECTED:
30091429521159
 RESULT:
3009142952159
{‘role’: ‘assistant’, ‘content’: ‘3009142952159’, ‘refusal’: None} if LLM is giving wrong output. I hope y’all look into edge cases. Some people tried really hard. to prompt it xD   .
You can check the logs

(venv) @ANDIECOOLER2 ➜ /workspaces/TDS-Project-1/app (checking-with-open-ai) $ uv run evaluate.py 
🟡 Running task: Install `uv` (if required) and run the script `https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py`
with `23f1002382@ds.study.iitm.ac.in` as the only argument
HTTP Request: POST http://localhost:8000/run?task=
Install+`uv`+(if+required)+and+run+the+script+`https%3A%2F%2Fraw.githubusercontent.com%2FANdIeCOOl%2FTDS-Project1-Ollama_FastAPI-%2Frefs%2Fheads%2Fmain%2Fdatagen.py`
with+`23f1002382%40ds.study.iitm.ac.in`+as+the+only+argument
 “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/format.md “HTTP/1.1 200 OK”
 A1 PASSED
10.8.2
 Running task: Format the contents of /data/format.md using prettier@3.4.2, updating the file in-place
HTTP Request: POST http://localhost:8000/run?task=
Format+the+contents+of+`%2Fdata%2Fformat.md`+using+`prettier%403.4.2`%2C+updating+the+file+in-place
 “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/format.md “HTTP/1.1 200 OK”
 A2 PASSED
 Running task: The file /data/dates.txt contains a list of dates, one per line. Count the number of Wednesdays in the list, and write just the number to /data/dates-wednesdays.txt
HTTP Request: POST http://localhost:8000/run?task=The+file+`%2Fdata%2Fdates.txt`+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+`%2Fdata%2Fdates-wednesdays.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/dates-wednesdays.txt “HTTP/1.1 200 OK”
 A3 PASSED
 Running task: Sort the array of contacts in /data/contacts.json by last_name, then first_name, and write the result to /data/contacts-sorted.json
HTTP Request: POST http://localhost:8000/run?task=Sort+the+array+of+contacts+in+`%2Fdata%2Fcontacts.json`+by+`last_name`%2C+then+`first_name`%2C+and+write+the+result+to+`%2Fdata%2Fcontacts-sorted.json` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/contacts-sorted.json “HTTP/1.1 200 OK”
 A4 PASSED
 Running task: Write the first line of the 10 most recent .log file in /data/logs/ to /data/logs-recent.txt, most recent first
HTTP Request: POST http://localhost:8000/run?task=Write+the+first+line+of+the+10+most+recent+`.log`+file+in+`%2Fdata%2Flogs%2F`+to+`%2Fdata%2Flogs-recent.txt`%2C+most+recent+first “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/logs-recent.txt “HTTP/1.1 200 OK”
 A5 PASSED
 Running task: Find all Markdown (.md) files in /data/docs/.
For each file, extract the first occurrance of each H1 (i.e. a line starting with # ).
Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title
(e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...})
HTTP Request: POST http://localhost:8000/run?task=Find+all+Markdown+(`.md`)+files+in+`%2Fdata%2Fdocs%2F`.
For+each+file%2C+extract+the+first+occurrance+of+each+H1+(i.e.+a+line+starting+with+`%23+`).
Create+an+index+file+`%2Fdata%2Fdocs%2Findex.json`+that+maps+each+filename+(without+the+`%2Fdata%2Fdocs%2F`+prefix)+to+its+title
(e.g.+`{“README.md”%3A+“Home”%2C+“path%2Fto%2Flarge-language-models.md”%3A+“Large+Language+Models”%2C+...}`) “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/docs/index.json “HTTP/1.1 200 OK”
 A6 PASSED
 Running task: /data/email.txt contains an email message. Pass the content to an LLM with instructions to extract the sender’s email address, and write just the email address to /data/email-sender.txt
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Femail.txt`+contains+an+email+message.+Pass+the+content+to+an+LLM+with+instructions+to+extract+the+sender’s+email+address%2C+and+write+just+the+email+address+to+`%2Fdata%2Femail-sender.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/email-sender.txt “HTTP/1.1 200 OK”
 A7 PASSED
 Running task: /data/credit_card.png contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to /data/credit-card.txt
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Fcredit_card.png`+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+`%2Fdata%2Fcredit-card.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/credit-card.txt “HTTP/1.1 200 OK”
 /data/credit-card.txt
 EXPECTED:
30091429521159
 RESULT:
3009142952159
 A8 FAILED
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 200 OK”
 Running task: /data/comments.txt contains a list of comments, one per line. Using embeddings, find the most similar pair of comments and write them to /data/comments-similar.txt, one per line
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Fcomments.txt`+contains+a+list+of+comments%2C+one+per+line.+Using+embeddings%2C+find+the+most+similar+pair+of+comments+and+write+them+to+`%2Fdata%2Fcomments-similar.txt`%2C+one+per+line “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/comments-similar.txt “HTTP/1.1 200 OK”
 A9 PASSED
 Running task: The SQLite database file /data/ticket-sales.db has a tickets with columns type, units, and price. Each row is a customer bid for a concert ticket. What is the total sales of all the items in the “Gold” ticket type? Write the number in /data/ticket-sales-gold.txt
HTTP Request: POST http://localhost:8000/run?task=The+SQLite+database+file+`%2Fdata%2Fticket-sales.db`+has+a+`tickets`+with+columns+`type`%2C+`units`%2C+and+`price`.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+“Gold”+ticket+type%3F+Write+the+number+in+`%2Fdata%2Fticket-sales-gold.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/ticket-sales-gold.txt “HTTP/1.1 200 OK”
 A10 PASSED
 Score: 9 / 10 proof
EDIT CREDIT CARD NUMBERS are 16 digits, so even there is discrepancy

**Post ID:** 594946

usage’: {‘prompt_tokens’: 1384,
‘completion_tokens’: 67,
‘total_tokens’: 1451,
‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0},
‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}},
‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_13eed4fce1’,
‘monthlyCost’: 0.5243745800000005,
‘cost’: 0.004554000000000001
GPT-4o mini
Fine-tuning price
Input:--------------------------> CALCUATION: (1384/10^6)*$0.30 = 0.0004152
$0.30 / 1M tokens
Cached input:
$0.15 / 1M tokens
Output:------------------------->  CALCUATION: (67/10^6)$1.20 = 0.0000804
$1.20 / 1M tokens
Training:
$3.00 / 1M tokens
TOTAL = 0.0004152 + 0.0000804 = 0.0004956
‘cost’: 0.004554000000000001 MAKE IT MAKE SENSE?
‘total_tokens’: 1451, so only input and completion tokens used?




INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:root:10
INFO:root:Inside run_task with task:
Install uv (if required) and run the script https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py
with 23f1002382@ds.study.iitm.ac.in as the only argument
INFO:root:PRINTING RESPONSE:::PRINTING RESPONSE:::PRINTING RESPONSE:::
{‘id’: ‘chatcmpl-B0pChhrBiCN8x8ueL2u57rwQiucl7’, ‘object’: ‘chat.completion’, ‘created’: 1739536527, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: None, ‘tool_calls’: [{‘id’: ‘call_ULCgfFzpEcnGNditwVwGwRIS’, ‘type’: ‘function’, ‘function’: {‘name’: ‘install_and_run_script’, ‘arguments’: ‘{“package”:“uv”,“args”:[“23f1002382@ds.study.iitm.ac.in”],“script_url”:“https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py”}’}}], ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘tool_calls’}], ‘usage’: {‘prompt_tokens’: 1384, ‘completion_tokens’: 67, ‘total_tokens’: 1451, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_13eed4fce1’, ‘monthlyCost’: 0.5243745800000005, ‘cost’: 0.004554000000000001, ‘monthlyRequests’: 217}
@s.anand  How is the usage calculated? Just asking not implying
UPDATE:  ITS EVEN MORE CHEAPER, I gave benefir of doubt better its much cheaper? ???
```Image was here: The image displays a section of OpenAI's pricing webpage for two models: GPT-4o and GPT-4o mini. Each model is presented with a title and a brief description highlighting their capabilities—GPT-4o focuses on complex tasks with a 128k context length, while GPT-4o mini is described as affordable for everyday tasks, also featuring the same context length. Below the model descriptions, price details are provided organized under the "Price" section, listing input and output costs per million tokens for each model. Specifically, GPT-4o has an input cost of $2.50 (or $1.25 for cached input) and an output cost of $10.00 per million tokens. In contrast, GPT-4o mini shows an input cost of $0.150 (cached input priced at $0.075) and an output cost of $0.060 per million tokens. The page has a dark background with UI elements including a "Log in" button and a search feature at the top, indicating a user-friendly design. The general activity seems to focus on pricing comparison for AI models relevant in software engineering discussions, with potential use in application contexts such as chatbot integration or task automation.```Screenshot 2025-02-14 1838441695×879 52 KB

**Post ID:** 594952

You can continue to $2. Then you would need to ask for a new token.

**Post ID:** 594953

@carlton @Jivraj please upload recording of TDS Week 5 - Session 2. Only recordings of session 1 & 3 have been uploaded.

**Post ID:** 594958

github.com



```Image was here: The image displays a GitHub repository interface titled "ANdleCOOl/TDS-Project-1," indicating it is a software project hosted on GitHub. It shows the repository has 2 contributors, 0 issues reported, 1 star, and 0 forks. The repository icon is a simple graphic resembling a code block or project element, emphasizing its software nature. The layout is consistent with GitHub's design, which typically includes sections for project contributions and metrics, suggesting that this is a new or relatively simple project with no current issues or forks, potentially indicating early development or a personal project.```
GitHub - ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.






DONE WITH A TASK , you have to create DOCKER IMAGE THOUGH < HAVE ENV file with keys , check the key value pair names, an cheers guy , we all get 9 marks hopefully

**Post ID:** 594960

For as task description like this

Write the # of Thursdays in /data/extracts.txt into /data/extracts-count.txt

I have given the prompt in such detail to the LLM but it is still not able to understand the task because of the “#” symbol. The task is getting truncated even before it reaches to the LLM.
Can anyone help me on this because I have tried so many things to fix this but nothing seems to help.

**Post ID:** 594963

Hi @Jivraj, @carlton sir,
I have created a docker file and run the application but it’s throwing error for
A2 task
No such file or directory: ‘npx’
Do i need give the node install in docker file?

**Post ID:** 594964

Hash is just another way of writing “number”

**Post ID:** 594967

@carlton @Jivraj
sir i have tried to solve the A1. when I want to check the solution we are asked for the datagen module as the evaluate.py have
’
''from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)
'''

so do we need to download the datagen.py in the local system first…
Or it should be the part of the automation only…

**Post ID:** 594968

I am getting internal server error for task A1, I have been trying for a long time. It may be possible that i have issues with my ai_proxy token thus tell how to properly set the taken.

**Post ID:** 594973

Yes I know that but LLM does not know that # indicates number. And no prompt is fixing this issue because the task has to be passed as query parameter and by the time LLM reads the task, it is already half gone due to #.

**Post ID:** 594978

Where to find AIProxy token from?

**Post ID:** 594979

what if we are out of token sir how do we complete our project then?

**Post ID:** 594981

could u share your code once i think you should explicitly try to install npx in your code

**Post ID:** 594982

23f1002382:

ANDIECOOLER2


could you help me out with q2?

**Post ID:** 594983

Can you tell me where to get the AIPROXY Token from and also are u able to execute docker image push command it keeps showing as an error to me

**Post ID:** 594984

def format_with_prettier(file_path:str, prettier_version:str):
    if file_path and os.path.exists(file_path):
        print('Path exisit - will perform prettier')
        subprocess.run(["npx", f"prettier@{prettier_version}", "--write", file_path])
    else:
        raise FileNotFoundError()

This is my code

**Post ID:** 594986

this isnt also working are you sure its right?

**Post ID:** 594987

```Image was here: The image displays code in a file named `main.py` within a VSCode interface, showcasing a Python function `handle_task_A2` that takes in parameters `file_path` and `prettier_version`. The function checks if a file exists at the specified path; if it does, it prints a message indicating that "Path exist - will perform prettier" and executes a subprocess to run the Prettier formatter with the specified version on the file. An error handling mechanism raises a `FileNotFoundError` if the file doesn't exist. The terminal output below indicates a Markdown file located at `/data/format.md`, highlighting an expected output of unformatted Markdown with extra spaces and trailing whitespace, including a sample paragraph and items listed in Markdown format. The output under "RESULT" shows that the extra spaces remain, hinting at the Prettier tool's functionality. This suggests that the focus is on debugging Markdown formatting issues using a combination of Python code and the Prettier formatting tool, relevant to coding, Markdown processing, and error handling in software engineering.```image1027×917 28.1 KB

**Post ID:** 594989

okay but in my docker image when i tried to run that in local, its asking for npx and it doesnt work

**Post ID:** 594990

@carlton could you please give a hint as to why this isnt working

**Post ID:** 594991

im running locally first and then will use docker when i get a 10/10 score

**Post ID:** 594992

Okay, actually when i tried with local, i’m facing path error
./data/format.md
[WinError 2] The system cannot find the file specified

So that’s why i moved to docker but there also i’m getting error for A2.

**Post ID:** 594993

you should manually check if the file really exists or not because i think the code and the folder where datagen.py is downloading files(data folder) are different

**Post ID:** 594997

yes yes i moved the folder to current working directory

**Post ID:** 595006

If you are using the function calling approach, you could just parse the ‘#’ and change it to ‘number’ and then send the prompt to the llm for that particular task.
Or another approach is tell the llm,
If you ever see the phrase ‘count the # of’ in a task, please interpret it as ‘count the number of’. For example
Count the # of Fridays means
Count the number of Fridays

**Post ID:** 595010

```Image was here: The image displays a Visual Studio Code (VSCode) interface running in a WSL (Windows Subsystem for Linux) environment, with a script in Python focused on downloading and executing a Python script from a remote URL. The visible code includes imports and function definitions, specifically showing the `subprocess` module, which is used for running external scripts. The code snippet contains a comment about defining the script URL and an argument, along with a command to execute the downloaded script using `subprocess.run()`. The right panel contains an error message indicating that the name 'subprocess' is not defined, suggesting an issue with the import statement. The terminal section at the bottom displays detailed traceback information, including the file name "lm.py," indicating a failed attempt to run the script due to the missing import. Additionally, the file structure in the explorer indicates the presence of several files, including `__init__.py`, `app.py`, and a `Dockerfile`, suggesting a broader project likely involving web application development or data science. The context implies the user is debugging a script download and execution process, likely part of a larger workflow related to data or web applications.```Screenshot 2025-02-14 2018541919×1015 81.4 KB
@carlton @Jivraj this is showing while docker image is running

**Post ID:** 595016

in project page, ctrl+F and search ai proxy, one link s.anandProxy or something, there it will validate you email and get you your token.

**Post ID:** 595019

can you share your code for dynamic code generation, i dont have the base to start with , can you send me the code?
whatever this image is , llm_code,oy and etc

**Post ID:** 595024

What file should we have while pushing it to git and making image
should datagen file and data be there or not?

**Post ID:** 595026

Please read the deliverables and evalute section.
datagen.py and evaluate.py were for only for your testing purposes so that you have an idea of the workflow and how the evaluation works. They are NOT part of your project submission.
Only DO what the project page tells you in the deliverables and evalute sections.
Kind regards

**Post ID:** 595050

sir i am getting this error by running the docker image
```Image was here: The image displays a console output from a Python execution environment indicating an error during the import process of the FastAPI framework. The traceback reveals that the error occurred in the file located at "/app/app.py" on line 11, where the code attempts to execute the statement "from fastapi import FastAPI." The specific error message, "ModuleNotFoundError: No module named 'fastapi'," suggests that the FastAPI module is not installed in the current Python environment. This context indicates the user is likely engaged in developing a web application using FastAPI and is troubleshooting an environment setup issue. The environment might be a terminal interface or a code editor's integrated console. The presence of Python as the programming language and FastAPI as the relevant technology implies a focus on modern web development practices.```image656×116 3.28 KB
i tried troubleshooting this for hours but no luck could you please tell me what i did wrong here

**Post ID:** 595051

i can help you up, if you need my help you can email me

**Post ID:** 595068

@s.anand Sir please tell me this I am not using podman i am using docker for building and hosting is it fine sir ?

**Post ID:** 595073

Hey @carlton @Jivraj , I actually submitted the project already in the morning,
I included all the deliverables and things mentioned in the evaluation section.
But since I was actively testing with the - datagen.py and evaluate.py, I forgot to remove them before submission.
However these files do not play a role in my project execution in any way, they just sit idle. Will there be any issue?

**Post ID:** 595074

when trying to use function call way of open api
tools = [
    {
        "type": "function",
        "function": {
            "name": "extract_email_sender",
            "description": "Extract sender email from a specific file in directory",
            "parameters": {},
            "strict": True
        }
    },
    {
        "type": "function",
        "function": {
            "name": "count_day_of_week",
            "description": "To count the occurances of a specific day of a week in a file with various dates",
            "parameters": {
                "type": "object",
                "properties": {
                    "day_of_week": {
                        "type": "string",
                        "description": "day of week"
                    }
                },
                "required": ["day_of_week"],
                "additionalProperties": False
            },
            "strict": True
        }
    }
]

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": user_input},
                
        ],      
	"tools": tools,
    "tool_choice": "auto",
    "max_tokens": 500,
    "temperature": 0.7
    }

facing the below issue
ror’: {‘message’: “Invalid type for ‘tools[0]’: expected an object, but got an array instead.”

**Post ID:** 595078

when i run POST request t is showing output “HTTP/1.1 200 OK” but when i give GET request it is showing HTTP/1.1" 404 Not Found. Can you please say how can it be solved

**Post ID:** 595082

These files are inside a separate folder - evaluation in my project root directory. Since I already submitted please do consider.
Thanks & Regards
Pradeep

**Post ID:** 595086

This indicates your task execution returns  “HTTP/1.1 200 OK” but the execution doesn’t creates the required file in the given location that the evaluation script is requesting.

**Post ID:** 595087

If have doubts in building DOCKER stuff can you help me debug
PLEASE SENPAI

**Post ID:** 595088

sure!! how can I help?

**Post ID:** 595089

+1
SENPAI is right

**Post ID:** 595090

not yet maybe in an hour, im building, but after that running in docker is different ball game, thats why , i need quick debugs in a meeting, other people also can join, maybe tomorrow, i have an exam tomorrow, so preferably , collectively before project submission . IF YOU HAVE TIME

**Post ID:** 595091

23f1002382:


Sure tell me I would try, if I am online then otherwise tomorrow if it’s late

**Post ID:** 595097

I am getting this error while pulling docker image
ansh@Lenovo:~/llm_project$ podman pull docker.io/ansh205/llm_project:final
Trying to pull docker.io/ansh205/llm_project:final…
Error: parsing image configuration: Get “https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/07/079f65bc553514a8f38a08fd959e932ca984894a64eed71fca406f3353b71d3b/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250214%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250214T172706Z&X-Amz-Expires=1200&X-Amz-SignedHeaders=host&X-Amz-Signature=073575bf08338fcdda378b997ebe749b15a6b676ed7b80fbf4c3f8080a791152”: dial tcp: lookup docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com on 10.255.255.254:53: server misbehavingPreformatted text

**Post ID:** 595108

@carlton @Jivraj @s.anand @Saransh_Saini
sir please provide me other api key. My current request cost is full.
Full LLM Response: {‘message’: ‘On 2025-02 you used $2.000143640000001, exceeding $2’}

**Post ID:** 595109

curl -X POST http://localhost:8001/run?task=Extract%20sender%20email
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    36  100    36    0     0      9      0  0:00:04  0:00:03  0:00:01     9{"results":"wrighttara@example.net"}

is this expectation of having %20 for blanks in query string fine ?

**Post ID:** 595111

docker run -e OPEN_AI_PROXY_TOKEN=your_token_value 
-e OPEN_AI_PROXY_URL=your_proxy_url 
-e OPEN_AI_EMBEDDING_URL=your_embedding_url 
-p 8000:8000
how do we get out urls inside, hardcode?

**Post ID:** 595126

Can you help with docker size image?
is it 2 GB?

**Post ID:** 595131

I want to reset my aiproxys i have used them all if i could even buy some would work i need it to test my app or could iitm help in resetting it please tell

**Post ID:** 595132

could u help me in q9 thats the one left

**Post ID:** 595133

@carlton my aiproxy is also exhausted please help me out

**Post ID:** 595134

sir my api tokens limit reached to one dollar , hiw to reset it

**Post ID:** 595135

bro can you help me with q2

**Post ID:** 595139

How to handle task a8 ? I tried pytesseract but gave wrong results.EasyOCR is giving the exact answer so tried in docker but some Model download is interrupting the flow of evaluate.py resulting in error .
I appreciate any help/procedure or code to handle taska8.
Thanks in advance.

**Post ID:** 595140

Did you get any solution to this

**Post ID:** 595142

u can use groq api groq api is compatible with openai

**Post ID:** 595143

whats up?
/////////////////////

**Post ID:** 595145

bro can please check my repo i am only able to do 7 tasks.
repo url: GitHub - 23f2005593/tds-project-1: TDS Project 1

**Post ID:** 595148

got the docker working?

**Post ID:** 595149

@carlton @Jeeveash.k
sir i submitted the wrong docker image file while submitted the form. Can you please let me change it, or make it such that we can reupload it
thank you.

**Post ID:** 595151

22f3001011 I’ve enabled “Allow response editing” on the form. I think that means you can edit your response… but since you had submitted it before it was enabled, I’m not sure what the procedure is. Worst case, please submit again.

**Post ID:** 595152

Please make this change in evaluation.py
In evaluation script url of datagen.py is different than actual one please change it
evaluation.py line 72
Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
change this to
Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

**Post ID:** 595153

very true there is too much confusion Id like to ask if you know that evaluate.py is mean to run only for user@example.com or our own mail too  because there was written You MUST use your Student Id (eg. 22f3xxxxxx@ds.study.iitm.ac.in) to do the Project, otherwise your score will not be considered for evaluation.

**Post ID:** 595154

Hi any one have any idea on the below,
SyntaxError: illegal target for annotation

I’m getting this error only when i run the evaluate.py but in with postman it works as expected.
Anyone please help on this

**Post ID:** 595160

```Image was here: The image displays a segment of code written in Python within the Visual Studio Code (VSCode) interface, specifically focused on making requests with the requests library. The code snippet includes import statements for modules including `os` and `subprocess`, with comments indicating tasks such as printing the completed paths for a data folder and executing a script using subprocess. The command `subprocess.run()` is utilized to execute a script located at a constructed URL, with parameters for URL and error checking. Below the code, the terminal output shows an executed command (`python3 /data/raw/app.py`) and the resulting console log, detailing a request being made to a specific URL possibly related to a data science project. The log includes HTTP status codes (200 OK) and progressive data being uploaded or processed, indicating the script's operation in a backend or testing scenario related to network requests.```Screenshot 2025-02-15 0719101919×1021 71.3 KB
sir why the datagen.py in not created in the tree and the data folder please help me @s.anand @Jivraj @carlton

**Post ID:** 595163

created in toot, cd /data in docker will take you there.

**Post ID:** 595170

```Image was here: The image displays a Visual Studio Code interface focused on a Docker setup for a Python application. The visible code consists of a Dockerfile with instructions such as `FROM python:3.12-slim-buster`, and comments indicating the need for SSL certificate installation. There are commands for installing dependencies like `RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates` and setup for the Python environment with `RUN pip install --no-cache-dir -r requirements.txt`. The terminal at the bottom shows an execution of a Python script, `app.py`, with console outputs, including a warning about the pre-release nature of a script that interacts with the GitHub URL `https://github.com/.../tools-etc`. Additionally, it contains HTTP request logs indicating a POST request to a designated endpoint, further suggesting that the application is likely involved in web API interactions. Mentioned technologies and tools include Docker, Python, and VSCode as the IDE.```Screenshot 2025-02-15 0758431919×1017 70.9 KB
is changes is required in Dockerfile

**Post ID:** 595180

i too got the same error you can change the the tools part in your payload to
"tools": [{"type": "function", "function": schema} for schema in function_schema]

**Post ID:** 595182

i think you have to run the following command
uv run datagen.py <your_email> --root ./data

try to include --root ./data in your code

**Post ID:** 595185

sorry i forgot the change the name of function_schema to tools please you do that

**Post ID:** 595187

@carlton @Jivraj
Hello,
just a silly question, if my code runs well in docker environment with /data in root directory, will it be fine ?
or should i keep the relative ./data directory like in the lecture ?
Thanks

**Post ID:** 595189

The reason in the lecture they were using ./data was because they were debugging in their local machine not in the docker.
For the docker image (the official submission) you must use /data.
It is a clear requirement mentioned in the project page.
Thats why it works fine when you use it in the docker image.
Kind regards

**Post ID:** 595204

```Image was here: The image contains a form interface, likely from a web application for submitting project details. It features two primary input fields with prompt text. The first field prompts the user for a GitHub repository link formatted as "https://github.com/user-name/repository-name," with the example input provided being "https://github.com/Atimanas-Biswal421/proj1." The second field asks for the name of a DockerHub image, indicating that it should resemble "user-name/image-name"; the input shown is "atimanassbiswal/proj1-tds:final." There is also a warning message below this input, stating "Must match pattern," suggesting a validation check for the input format, which points to usage within a software deployment or versioning context. Technologies implied include GitHub for version control and DockerHub for container image management.```Screenshot 2025-02-15 101818858×521 24.4 KB
@Jivraj @carlton
hello sir i need help here. I have pushed my image into a docker repo and trying to submit it on ht google form. but it is not accepting it and asking to remove the tag .
What do i do ?

**Post ID:** 595208

Alright sir.  Thank you very much for your help.

**Post ID:** 595225

Are multiple submissions allowed for project?

**Post ID:** 595228

```Image was here: The image displays a coding environment, likely a Python IDE or text editor, showing the structure of a project comprising several files, including `taskA2.py`, `evaluate.py`, and `data/credit_card.png`. In the console output, there is a POST request attempting to access an endpoint at `https://alproxy.sandbox.weniors.com`. The output also shows a series of numbers formatted as credit card information ("090 6522 2038 7260"), with a subsequent validation message indicating "VALID" followed by "Invalid" or "FAIL" responses. The output confirms a failure with the error message "AB FAILED" in red text and indicates a problem related to the `data` directory, specifically targeting `credit-card.txt`. The environment suggests activities related to debugging API requests and validating credit card formats, possibly within a testing or validation tool integrated into the IDE.```A8720×1280 85.1 KB
@carlton @Jivraj
please check this one…

**Post ID:** 595230

Hi @carlton @Jivraj  sir,
For A2 do i need to install node in the docker? I’m getting error with npx.
please suggest some way sir?

**Post ID:** 595231

if i have two repo on docker , is there any problem in that

**Post ID:** 595251

```Image was here: The image displays a terminal or console interface showing a response from an API request, indicating a failure. The status line prominently features a "500 Internal Server Error" and provides additional metrics: a response size of "184 Bytes" and a response time of "792 ms." Below the status, the response body is formatted in JSON, detailing an error with code "401." It includes a message stating: "Your authentication token is not from a valid issuer," along with error type "invalid_request_error," no specific parameter listed, and error code "invalid_issuer." The interface appears to be equipped with tabs for Headers, Cookies, Results, and Docs, likely part of a tool like Postman or a similar API testing environment, intended for debugging API interactions.```image684×316 12.7 KB
why do i get this error? can someone please help me out @Jivraj @carlton…Anyone pls help

**Post ID:** 595252

can u please share the base proxy url

**Post ID:** 595257

I’m also getting the same error. I have used a proxy URL and token. Before, it was working, but now it’s not.

**Post ID:** 595262

sir or anyone can you please provide what should be the content inside the docker file … i am getting confuse like /data or python-slim etc
… i am done with locally testing and only this thing left.

**Post ID:** 595263

yes please explain somebody. What should be inside the dockerfile

**Post ID:** 595266

Hi ,
Anyone completed Task B, I don’t know how to combine task A (function calling) and task B (self creating python code)
can anyone suggest how to do that? It will be really helpful

**Post ID:** 595268

“http://aiproxy.sanand.workers.dev/openai/v1” use this as proxy URL. its working for me now!

**Post ID:** 595273

How to resolve this?
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ uv run app.py
Traceback (most recent call last):
File “/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro/app.py”, line 10, in 
from fastapi import FastAPI
ModuleNotFoundError: No module named ‘fastapi’
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip show fastapi
WARNING: Package(s) not found: fastapi
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip install fastapi
error: externally-managed-environment
× This environment is externally managed
╰─> To install Python packages system-wide, try apt install
python3-xyz, where xyz is the package you are trying to
install.
If you wish to install a non-Debian-packaged Python package,
create a virtual environment using python3 -m venv path/to/venv.
Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
sure you have python3-full installed.

If you wish to install a non-Debian packaged Python application,
it may be easiest to use pipx install xyz, which will manage a
virtual environment for you. Make sure you have pipx installed.

See /usr/share/doc/python3.12/README.venv for more information.

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.

**Post ID:** 595280

sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project…
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won’t believe but I am continuously trying since last week. Specially after the release of the sessions… Whole day and night have gone like nothing, infront of the computer…
Plz sir understand the situation and extend the deadline…

**Post ID:** 595281

23f2003413:

http://aiproxy.sanand.workers.dev/openai/v1


For me it says invalid path

**Post ID:** 595282

```Image was here: The image displays a JSON object containing an error message related to usage limits. The JSON structure features a single key "message" with a string value: "On 2025-02 you used $2.0037491399999996, exceeding $2". This indicates that a certain threshold of $2 has been surpassed in a given period (February 2025), emphasizing an exceeded usage cost. There are no additional elements, log outputs, or configuration settings visible, suggesting this is a specific response likely from an API or a financial monitoring tool within a software application context. The focus appears to be on tracking and managing financial limits, possibly related to cloud services or subscription-based software usage.```
@carlton @Jivraj

**Post ID:** 595285

same issue happening with me even though working for last whole week only got 4 correct . please extend some time so we can complete the project as weekends are the time when we get a day off from our primary college and can work with full attention on this project.

**Post ID:** 595295

it usually happens in some GNU/Linux OS. since you are using some distribution based on Debian namely Ubuntu or whatever try doing sudo apt install python-packagename (replace package name with fastapi for fastapi)
then it works. It usually happens due to manual intervention with pip3 the user might break some system dependencies which require some python3 package. No need to worry about it.
Another Fix: try using a virtual environment which is highly suggested since there is no chance for you to interfere with the system packages.
create a venv using python3 -m venv name_of_venv
add this line to your .bashrc in ~ folder as source /path/to/your/venv/location
and run source .bashrc. This time no error occurs as you do everything in your virtual environment you can install anything python3 package using pip3 install package name.
It even happened for me
```Image was here: The image displays a terminal session in a Python environment, specifically using a virtual environment named 'development.' A user attempts to install the NumPy library using the command `pip install numpy`, but the output indicates the environment is managed and provides instructions that discourage direct installation of packages. It suggests using the command `source /home/user/deploy/python/3/bin/activate` to properly activate the virtual environment. A subsequent command attempts to install NumPy again, with an output confirming that the requirement is already satisfied for version 1.22.2 located in the directory `/home/user/python3.8/site-packages`. The terminal's appearance indicates a Linux shell, with dark mode styling, typical for various development tasks, particularly within Python projects, suggesting a focus on package management and environment configuration.```Screenshot_20250215_1433573841×1009 237 KB

**Post ID:** 595296

Most of your questions and doubts will be solved in todays sessions. First 20 mins will be a clear overview of the logic and workflow and how evaluation actually works.
Rest of the session will be bug fixing and doubts.
Kind regards

**Post ID:** 595298

EXPECTED:
Everybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.
New customer green strategy.
Feeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.
During professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.
Wind develop world next. Impact appear capital cold stock we. Quality get run case huge that.
Use century general above more region. Radio him quality stage. Truth least military dinner growth.
Study maybe source. For expect imagine.
Analysis remain voice dog sit part. Safe them store spring life girl.
House bring challenge. Tell but rock able great.
Mouth president worker common Mr billion.
 RESULT:
“Everybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.\nNew customer green strategy.\nFeeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.\nDuring professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.\nWind develop world next. Impact appear capital cold stock we. Quality get run case huge that.\nUse century general above more region. Radio him quality stage. Truth least military dinner growth.\nStudy maybe source. For expect imagine.\nAnalysis remain voice dog sit part. Safe them store spring life girl.\nHouse bring challenge. Tell but rock able great.\nMouth president worker common Mr billion.”
it is the error i am facing but when i am opening manually, i am not getting any error, what should I do?
this same issue is with 3-4 questions

**Post ID:** 595316

when will the session be conducted and how can we join it sir?

**Post ID:** 595317

Hi Thanks.
Yes. it works when venv is created. But I see that it was working find in Week 5-Session 1 video without creating virtual environment.

**Post ID:** 595321

I will not submit project.

**Post ID:** 595326

Get authentication token from this AI Proxy and usage and follow documentation for sending requests.
sanand0/aiproxy: Authorizing proxy for LLMs

**Post ID:** 595327

No Problems, just fill form with correct image name in google forms.

**Post ID:** 595328

yes npx will require node to be installed.

**Post ID:** 595329

@Jivraj when would today’s live session be conducted and how can we attend it sir

**Post ID:** 595333

evaluate.py is not working sir.

**Post ID:** 595335

What if you run out of credits during or just before final evaluation?

**Post ID:** 595338

This is only for testing on local machine.
In docker image keep /data.

**Post ID:** 595339

One session is going live right now (from 3 to 5 pm).
It will be visible from calendra.

**Post ID:** 595342

sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project…
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won’t believe but I am continuously trying since last week. Specially after the release of the sessions… Whole day and night have gone like nothing, infront of the computer…
Plz sir understand the situation and extend the deadline…

**Post ID:** 595343

Sir, I have put my AIPROXY_TOKEN in .env file should I need to push the .env file also in the github

**Post ID:** 595348

yes sir do we have to put env file also @carlton sir @Jivraj sir

**Post ID:** 595357

In the evaluation.py there is an import require named from datagen import some stuff.
which means inorder to run the evaluation.py we need to manually bring the datagen.py in the working directory…
Because in order to run the evaluation.py we need the datagen. plz help…

**Post ID:** 595359

can someone send the meet link for the live session happening now

**Post ID:** 595362

Everytime I run datagen.py for the A1 task, the data file gets downloaded in the C drive instead of the current project folder. I even tried to set the current project folder as the root directory but it still downloads the files in C drive and I cant seem to find a workaround this. Can someone please help with this issue. Thanks!

**Post ID:** 595366

Can you please make the changes in the datagen.py file
config = {“root”: “/data”}
This is where I have been facing the issue.
The only solution I can think of is moving the /data folder from the root to the project directory. which I am not sure is a good way to solve this issue.

**Post ID:** 595369

```Image was here: The image displays a dark background typical of a video conferencing application, featuring a prominent orange circular icon with a capital "T" in white, suggesting it is a user profile or participant identifier. Below this icon, the name "TELVIN VARGHESE" is visible, indicating the username or display name of the participant. The top-right corner contains a small logo of Google Meet, confirming the platform used for the meeting. There are no visible code snippets, text logs, or technical UI elements relevant to software engineering discussions in this image. The context suggests a virtual meeting environment but lacks specific programming content or discussion details.```

**Post ID:** 595371

@carlton
please tell do we have to put this url in a variable for A1 task ?
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

**Post ID:** 595372

Task A9 fails.

HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 401 Unauthorized”
 A9 failed: ‘data’
 A9 FAILED

If I run
curl -X POST http://aiproxy.sanand.workers.dev/openai/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer $AIPROXY_TOKEN" -d '{"model": "text-embedding-3-small", "input": ["king", "queen"]}'

I get
{
  "message": "Missing Authorization: Bearer header. See https://github.com/sanand0/aiproxy"
}

@carlton @Jivraj @s.anand

**Post ID:** 595373

@carlton sir @Jivraj sir  do i have to put env file in docker

**Post ID:** 595380

you have to give the AIPROXY_TOKEN to the evaluate.py by either
bash - export AIPROXY_TOKEN="your token"
or
powershell - $env:AIPROXY_TOKEN="your token"
the evaluate.py file takes the token to send request to embedding end point for processing.
so you have to set AIPROXY_TOKEN in both terminals
i.e. app.py and evaluate.py teminals

**Post ID:** 595382

when I run the evaluation file, i get the following error -  Running task: Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py with user@example.com as the only argument  A1 failed: All connection attempts failed  A1 FAILED
I am getting the following error when running the evaluation scripts, can someone help me understand what this error is?

**Post ID:** 595385

Humble request to extend the deadline please. Finding it extremely difficult and having time atleast till Sunday will be really helpful for working professionals like me

**Post ID:** 595396

All my tasks are running except A9. I have created a .env file and added my token. Despite that I ran commands in both the terminals. A9 still fails.

**Post ID:** 595397

I second this, have been trying to debug the project for the past 1 week, spending over 4 hours daily and yet facing issues everytime I reopen. An extension of even 24 hours would be extremely appreciated. Please consider this. Thanks.

**Post ID:** 595402

same issue on my side as well

**Post ID:** 595404

how u did A2
could u please share ?

**Post ID:** 595411

@s.anand @jivraj @carlton
AIPROXY_TOKEN=$AIPROXY_TOKEN
what abt m url stuff?

**Post ID:** 595416

Sir, I request you to Please  extend the deadline, Because it is time consuming  and regular Students and Working professionals  have only saturday and sunday to complete this project.
Thanks

**Post ID:** 595417

also, in evaluate.py file, the embedding url is wrong and the AIPROXY_TOKEN is changed to OPENAI_API_TOKEN or something. i could send you edited evaluate.py… check your messages on discourse

**Post ID:** 595420

On bash it gives below output. On PowerShell it says missing authorization. A9 is failed.
```Image was here: The image displays a terminal console output from a bash shell, indicating an interaction with a web API for generating embeddings via a POST request. The user is logged into a project titled "TDS-Project-1-LLM" and has set an environment variable, `AIPROXY_TOKEN`, containing a token value needed for authentication with the API. The command executed is `curl -X POST` aimed at the URL `http://aiproxy.sanand.workers.dev/openai/v1/embeddings`, specifying headers for content type as `application/json`. The request payload includes a model identifier `"text-embedding-3-small"` alongside an input array containing two string values: `"king"` and `"queen"`. The API response shows a JSON structure indicating the object type as `"list"` and contains an array of embeddings, each accompanied by an index. The numeric values of the embedding are densely packed, revealing their respective dimensions, which likely represent high-dimensional vector representations of the input words. Console statistics such as "% Total", "Received", "Xferd", "Average Speed", and "Time" provide performance metrics for the API request, showing it completed in approximately three seconds. The technologies involved include bash for command-line operations, `curl` for HTTP```image907×661 26.5 KB
In PowerShell
```Image was here: The image displays a PowerShell terminal session where a `curl` command is executed to send a POST request to an endpoint at `http://aiproxy.sanand.workers.dev/openai/v1/embedding`. The command includes headers for JSON content type and authorization, using the Bearer token format represented by `$AIPROXY_TOKEN`. The body of the request is a JSON object specifying the model as "text-embedding-3-small" and providing an input array with the values "king" and "queen". The console output indicates an error message stating "Missing Authorization: Bearer header," along with a link to a GitHub page for further assistance, indicating a configuration issue regarding the required authorization header for API access. This context suggests an interaction with an API for generating embeddings in a natural language processing context, possibly within a software development or data science project.```image967×292 16.5 KB

**Post ID:** 595421

My data is getting generated -
```Image was here: The image displays a JSON output from a web interface running on a local server at the IP address 127.0.0.1:8000. The JSON object contains a key "files" with an array of strings representing various file names and types, indicating a structured dataset. The listed files include "comments.txt," "contacts.json," "credit_card.png," "dates.txt," "docs," "email.txt," "format.md," "logs," "ticket-sales-gold.txt," and "ticket-sales.db." Additionally, there's a "message" key stating "Data generation complete," suggesting that this output indicates the successful completion of a data generation task. The overall context points to activities related to file management or data processing, possibly in a web application or script that interacts with these various file types. The interface appears to utilize a pretty-print feature for better readability of the JSON response.```image459×454 12.7 KB
despite this I am getting an error when evaluating the file with no explanation of the error. Can someone please help with this.
 Running task: Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
with user@example.com as the only argument
 A1 failed:
 A1 FAILED

**Post ID:** 595423

```Image was here: The image depicts a snippet from a Markdown file (`format.md`) opened in a coding environment, likely Visual Studio Code (VSCode). The file includes a heading labeled “# Unformatted Markdown,” followed by a paragraph with inconsistent spacing and trailing whitespace. There is a list with varying bullet points: a dash for "First item," a dash for "Second item," a plus sign for "+Third item," and an asterisk for "* Fourth item," indicating differing list styles. Below the list is a block of code enclosed in triple backticks, specifying the language as Python (`py`). The code within this block executes a `print` statement designed to output an email address: `print("user@example.com")`. Also visible in the interface are relevant file names such as `.env`, `app.py`, and `evaluate.py`, suggesting a software engineering context involving Python development and potential testing or application management.```image820×404 12.3 KB
Even the markdown file shows the correct email. What are the possible issues that I could be facing with this one.

**Post ID:** 595429

```Image was here: None```
github.com


GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.





ATLEAST 6 minimum score use at own risk(MIT LICENCE xD)

BUILD TIME TAKES 2 mins
WITH DOCKER FILE
@ANdIeCOOl ➜ /workspaces/TDS-Project-1/tds-project-1 (main) $ docker build -t tds-project-1 .
[+] Building 123.9s (13/13) FINISHED                                                                       docker:default
 => [internal] load build definition from Dockerfile                                                                 0.0s
 => => transferring dockerfile: 1.18kB                                                                               0.0s
 => [internal] load metadata for docker.io/library/python:3.11-slim                                                  2.2s
 => [auth] library/python:pull token for registry-1.docker.io                                                        0.0s
 => [internal] load .dockerignore                                                                                    0.0s
 => => transferring context: 2B                                                                                      0.0s
 => [internal] load build context                                                                                    0.1s
 => => transferring context: 34.30kB                                                                                 0.0s
 => [1/7] FROM docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  8.7s
 => => resolve docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  0.0s
 => => sha256:2c2c44fb54acb184dbedee948d7ba6460b1075a60a014d66857ce46543d4d840 5.29kB / 5.29kB                       0.0s
 => => sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260 28.21MB / 28.21MB                     0.7s
 => => sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53 3.51MB / 3.51MB                       0.9s
 => => sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335 16.20MB / 16.20MB                     1.6s
 => => sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8b52eda 9.13kB / 9.13kB                       0.0s
 => => sha256:a66bd09b8d35bb52cd106a94c23a94ba22e6fde6bd13d6c5912ec4f5888a7f14 1.75kB / 1.75kB                       0.0s
 => => extracting sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260                            2.2s
 => => sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f 249B / 249B                           1.9s
 => => extracting sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53                            0.2s
 => => extracting sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335                            1.4s
 => => extracting sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f                            0.0s
 => [2/7] WORKDIR /app                                                                                               0.2s
 => [3/7] RUN pip install --upgrade pip setuptools wheel                                                             8.7s
 => [4/7] RUN apt-get update && apt-get install -y --no-install-recommends     gcc     g++     make     libffi-dev  84.5s
 => [5/7] RUN npm install -g prettier                                                                                1.5s
 => [6/7] COPY app /app                                                                                              0.1s
 => [7/7] RUN pip install uv                                                                                         4.5s
 => exporting to image                                                                                              13.4s
 => => exporting layers                                                                                             13.4s
 => => writing image sha256:39add91710bc7970d44dae04b3f4a0c4f227d1471fac4df7b01cec86ce7af3cf                         0.0s
 => => naming to docker.io/library/tds-project-1                                                                     0.0s

@ANdIeCOOl ➜ /workspaces/TDS-Project-1/tds-project-1 (main) $ docker images
REPOSITORY      TAG       IMAGE ID       CREATED          SIZE
tds-project-1   latest    39add91710bc   31 seconds ago   923MB
if this cause any issues please notify  @s.anand @carlton @Jivraj

**Post ID:** 595430

in phase B tasks are we supposed to create files to store the output or return it in the response ???
Please answer ASAP sir.

**Post ID:** 595431

@s.anand
Respected Sir,
I sincerely request you to kindly consider granting a one-day extension for Project 1. Many key clarifications were provided in today’s session, and we need just one additional day to effectively implement them. This extension would be immensely helpful in ensuring a more refined submission.
I truly appreciate your time and consideration.
Thank you.

**Post ID:** 595434

@all can everyone please test my image and let me know PLEASE. THIS IS THE MOST YOU ALL CAN DO FOR ME. I WILL BE BERY GRATEFUL

```Image was here: None```
github.com


GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.

**Post ID:** 595435

hey I have a few doubts, if something was said about this please say so.

in Phase be tasks do we have to store the output in files or just return it in the response
When I call my some of my endpoints using post man or CURL they work but if I run the evaluate.py it throws an error, this I think is a bug in the eval.py file.

any idea about these ?

**Post ID:** 595441

facing the issue on submission
```Image was here: The image displays a form input section related to a technical project, specifically requiring links to GitHub and DockerHub repositories. The first field prompts for the GitHub repository link related to "Project 1," suggesting a format like "https://github.com/user-name/repository-name." Below it, the user has entered "https://github.com/rsjay1976/TDS-Project1-Ja," which is likely an incomplete or erroneous link. The second field requests the name of the DockerHub image, with a specified format of "user-name/image-name." The input "rsjay1976/tds-project1-Jan25" has been entered but appears to produce a validation error indicated by red text stating "Must match pattern." This context implies the user is likely completing a form for project submission or configuration related to software deployment, integrating GitHub for version control and DockerHub for containerized application deployment.```image942×521 28.7 KB

**Post ID:** 595443

please ignore the above… there was a upper case issue  in image name… now fine

**Post ID:** 595447

Is it import to use python 3.13?
It is not stable yet

**Post ID:** 595449

```Image was here: The image displays a console output from a Python application, specifically within the context of integrating the OpenAI API. It indicates an error message raised by the OpenAI client during initialization, located in the file "/usr/local/lib/python3.12/site-packages/openai/_client.py" at line 110. The error message reports an `OpenAIError` stating that the `api_key` client option must be set, either by passing an `api_key` directly to the client or by setting the `OPENAI_API_KEY` as an environment variable. Additionally, there is a trace of the call stack showing the sequence of file references, highlighting an issue in the script located at "/app/app.py" on line 35, where the `OpenAI` client is instantiated. This setup points to a debugging scenario where the developer is troubleshooting an authentication problem with the OpenAI API within a Python framework.```image1831×146 7.91 KB
can someone help me fix this error @Jivraj @carlton

**Post ID:** 595450

for the datagen script is it ok to hardcode the scripts url and my email id? I understand the script itself may change but can I count on the link remaining the same? Also is it necessary to pass the email as argument?

**Post ID:** 595451

from dotenv import load_dotenv
load_dotenv()

**Post ID:** 595454

yahh i have it in my code…still facing the issue

**Post ID:** 595457

@Jivraj @carlton [filler to extend length]

**Post ID:** 595460

whats the image’s name on Docker?

**Post ID:** 595461

just completed my sem exams started worrking on the project from 2 days please give extension of deadline for the project sir

**Post ID:** 595468

dont we have to add the data folder or folder like datagen in the repo?

**Post ID:** 595470

thats confidential, im not an idiot xD, that will get me definitely  in trouble

**Post ID:** 595471

no, not really . Just your app

**Post ID:** 595473

in your project,in the app folder you have the data folder which is empty so should I keep that or remove it

**Post ID:** 595475

and also will u be making any chnages in the repo

**Post ID:** 595477

File “/app/app.py”, line 35, in 
client = OpenAI(
^^^^^^^
File “/usr/local/lib/python3.12/site-packages/openai/_client.py”, line 110, in init
raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable                                                                              some pls help me fix this error!!

**Post ID:** 595493

Blunder in your main.py.
You are using API_KEY = os.getenv(“AI_PROXY_TOKEN”) but it should be AIPROXY_TOKEN.
Btw what you using for phase B?

**Post ID:** 595494

yes i will change that

**Post ID:** 595498

nothing i think, i’ll import those generic functions and use tool usage only probably if can’t crack dynamic code generation

**Post ID:** 595499

i don’t have that

```Image was here: None```
github.com


TDS-Project-1/tds-project-1/app at main · ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.

**Post ID:** 595500

What we expect in project.

server running inside docker container at 8000.
And all files will be accessed from data folder in root directory.

Apart from these two you can have anything extra.

**Post ID:** 595504

```Image was here: The image displays a command-line interface (CLI) session on a Windows PowerShell environment indicating activities related to Docker. The user executes the `docker login` command, successfully authenticating under the credentials for `pratik007`. Following this, the `docker build` command is run with the context set to `C:\Projects\tds_project_1`, initiating the build process using a `Dockerfile`. The output indicates an error, specifically an inability to load metadata for the `python:3.12-slim-bookworm` image from Docker Hub, with multiple error messages detailing a failure to resolve source metadata. The Dockerfile contents appear to include the line `FROM python:3.12-slim-bookworm`, suggesting that the attempt is to base a Docker image on this Python version while indicating a step for installing essential system dependencies. The error trace indicates a network issue while attempting to access the Docker image registry, specifically mentioning problems with a remote server (`docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com`). The console also references a "TPS proxy" connection failure, indicating potential issues with the host's network configuration or availability. Overall, this scenario revolves around troubleshooting```Screenshot 2025-02-15 2128261903×492 32.1 KB
how to fix this error ?

**Post ID:** 595505

What problem you facing with that dynamic code generation part?

**Post ID:** 595506

I have exhausted my api limit of $2. I need to test my project. Can you please provide some more credits? @Jivraj @carlton @s.anand

**Post ID:** 595509

no problem but im losing steam slowly, i need to buckle up and PUSH @Jivraj

**Post ID:** 595510

Subject: Request for Project Deadline Extension
Dear Sir,
This project is highly complex, and we need additional time to ensure its successful completion. We kindly request an extension of the deadline to allow for thorough testing and proper implementation. An extension would greatly help us deliver the best results.
Thank you for your understanding  @Jivraj @carlton @s.anand

**Post ID:** 595512

This might be problem with network settings(unstable internet, firewall, VPN interference)
try to debug it with help of chatgpt.
You can also use codespaces for trying another network.
Streamlining setup with GitHub Codespaces

**Post ID:** 595514

Push push @23f1002382

**Post ID:** 595517

@Jivraj is it fine if i have my AIPROXY_TOKEN in my code instead of getting it as environment variable?

**Post ID:** 595519

if you do that then during evaluation, it would use your credit limit. if it gets exhausted, you may face problems. @23f2003413

**Post ID:** 595521

```Image was here: The image depicts a directory structure from a software engineering project, likely managed within a code editor such as Visual Studio Code. The main project folder is labeled "TDS-Project-1," containing several subdirectories and files. Key components include a Python virtual environment directory named ".venv" and an "app" folder with its own cache directory "__pycache__." The "data" folder includes various Python files: "__init__.py," "funtions_tasks.py," "main.py," and a text file "task_to_embed.txt." Additionally, the structure shows a ".gitignore" file, a "Dockerfile," and two other Python scripts, "datagen.py" and "evaluate.py." Accompanying these files are two Markdown files, "README.md," which typically provides project documentation. The presence of the "__pycache__" folders suggests that the project uses Python packaging, and the "Dockerfile" indicates the intention to containerize the application. The consistent naming conventions and file structure imply a focus on modularity and organization within a Python-based development context.```image266×559 12.5 KB
this is what i am doing first using the podman given in the portal and then running the evaluate.py file

**Post ID:** 595522

ahhh okay, but i am getting an error while trying to fetch the token as an environment variable. any suggestions to fix this issue?

**Post ID:** 595523

you can use python-dotenv. check that out.

**Post ID:** 595526

tried that still not getting T_T anyways thanks mate!

**Post ID:** 595528

No don’t do that, just follow the procedure.
Two problems with keeping token in file.

It will become public after you push to github.
While running evaluation script after submission your token might run out of credits.

**Post ID:** 595531

ohh yes, didn’t think it through xD

**Post ID:** 595533

I am facing the same error. and I have checked for solutions and found none. Did you resolve it? If yes can you please guide me through it?

**Post ID:** 595536

{
“detail”: “Error code: 401 - {‘error’: {‘message’: ‘Your authentication token is not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}”
}          getting this error sir

**Post ID:** 595538

```Image was here: None```
github.com


TDS-Project-1/tds-project-1/app at main · ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.






i keep updating, check this

**Post ID:** 595543

Please extend deadline by 1 day. i just got discharged from hospital today, was suffering from liver problem since some days and got high heart beat due to a medicine unrelated to liver and made me got admitted@Jivraj

**Post ID:** 595545

11:59 + 5 hours atthe most, @s.anand ?

**Post ID:** 595686

11 posts were split to a new topic: Project 1 - Casual banter

**Post ID:** 595555

@Jivraj sir   @carlton    sir do have to add datagen in the docker container?
As when I’m running it locally, it gives 9/10, but when I pull it from Hub and run eval, it says:detail": “[Errno 2] No such file or directory: ‘/data/datagen.py’”

**Post ID:** 595558

```Image was here: The image displays a console output typically found in a development environment, possibly from a tool like Postman or a browser's developer console. It presents a structured JSON response indicating an error with an HTTP status code of 401. The JSON structure includes a "detail" key containing an error message that states: "Your authentication token is not from a valid issuer." Further breakdown of the error reveals keys such as 'error', which nests additional details: 'message', 'type' (labeled as 'invalid_request_error'), 'param' (set to None), and 'code' (indicating 'invalid_issuer'). This output suggests the context is related to API authentication issues within a web or server application, highlighting problems with token validation.```image706×193 6.15 KB
someone please help me fix this error

**Post ID:** 595569

@carlton can you pl merge this

github.com/sanand0/tools-in-data-science-public








Update evaluate.py with correct link of datagen.py for task `A1`


tds-2025-01 ← rohitxiitm:patch-1



          opened 10:56AM - 15 Feb 25 UTC



```Image was here: I'm unable to describe the content of this image.```
            rohitxiitm
          



+1
-1










ppl are facing issues in evaluate.py for task A2

**Post ID:** 595573

folks, need a confirmation. i don’t know but i heard it from someone or somewhere.
we cannot send json in response, if it is success ? need to send text
is that really the case ?

**Post ID:** 595577

@rohitgarg - thanks for this. Merged your PR pointing to the correct link for evaluate.py

**Post ID:** 595651

Sir from which session to which session is about tds project?

**Post ID:** 595657

week-5 session-1 & week-5 session-3

**Post ID:** 595664

Here is  a Bruno collection (open source alternate for postman) for API testing A1 to A6
bruno collection

**Post ID:** 595668

On my system evaulate.py is throwing an error on A2 trying to execute npx on format.md before the llm is even invoked. However running the command directly on the command line works.
evaluate.py:
 A2 failed: Command ‘[‘npx’, ‘prettier@3.4.2’, ‘–stdin-filepath’, ‘data/format.md’]’ returned non-zero exit status 2.
 A2 FAILED
bash:
npx prettier@3.4.2 --stdin-filepath data/format.md
bash works as expected. Can someone help?

**Post ID:** 595670

@carlton
Is there a maximum size limit for the Docker Image?
Thanking you

**Post ID:** 595677

@carlton @Jivraj
Hi ,
I am trying to build using both docker and podman but it failed on both. I have watched many videos trying to resolve this adn also chatgpt in order to resolve the issue but it seems to persist. I even uninstalled and reinstalled both podman and doceker multiple times but no help.
When i run command docker build -t ___________ .
the error that comes is :
Dockerfile:2
1 |     # Use a lightweight Python image
2 | >>> FROM python:3.12-slim
3 |
4 |     # Set the working directory in the container
ERROR: failed to solve: python:3.12-slim: failed to resolve source metadata for Docker Hub Container Image Library | App Containerization failed to copy: httpReadSeeker: failed open: failed to do request: Get “https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/6f/6f3c6367c5a38963f84310cbb24dfcfbddab1dad40cff18afb8fe89098891f08/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250215%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250215T192245Z&X-Amz-Expires=1200&X-Amz-SignedHeaders=host&X-Amz-Signature=ed37cf0c346e2ed440f29638ec43ce66640bdc7d285e7be7bf25c308c46fd6b1”: dialing docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443 container via direct connection because static system has no HTTPS proxy: connecting to docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443: dial tcp: lookup docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com: no such host
Even tried getting python:3.12-slim separatly and trying again but that also didn’t work.
I think there is some problem in getting python:3.12-slim as the build always stops at this.
on asking ChatGPT it shows that some DNS or network issue is there. I even tried all the remedy that was provided on creating custom network etc. but this was also of no use
Kindly help me finding solution to this and pls mention any other assistance I may require to get this running
Thank You.
Regards,
Aagman

**Post ID:** 595679

i am getting this error, I have tried many times but still the error persists:
“message”: “Bearer YOUR_AIPROXY_TOKEN is invalid: JWSInvalid: Invalid Compact JWS”

**Post ID:** 595680

someone please help!!!

**Post ID:** 595683

@carlton needed a confirmation on this task
A8 * `/data/credit-card.png` contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to `/data/credit-card.txt - in this task i assume prompt can ask for credit card number or other details like cvv and name.
My question is, whether my system should allow prompt that CVV or or such info ? or should give it ?

**Post ID:** 595690

Previously I asked for some more credits to test my project. I got an email stating I have been provided with a new token but I think I got that same token again, not a new one. I still cant send request to the AIPROXY. Please help.


Do I need to submit the docker image name with the tag or without the tag? I submitted it before without the tag. Now i see that I have tagged the image with as v1 but I cant submit the form due to pattern matching problems. Should i submit again after tagging it with :latest ?


@s.anand @carlton @Jivraj

**Post ID:** 595693

@Jivraj @carlton  sir in the phase B will the input and output path will be given ?

**Post ID:** 595695

@carlton @Jivraj @Saransh_Saini
When I run my docker image using
podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
Task A2 fails as the podman container is unable to find npx.
Running the same image using
docker run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
works fine and Task A2 passes. I can’t understand why this is happening.
I also ran the image in both docker and podman in interactive mode as show in the below snippet from terminal.
When run using docker, which node gives /usr/bin/node as output but when run using podman, nothing.
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo docker run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
/usr/bin/node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --user=root --rm -it docker.io/myusername/myreponame /bin/sh
# which node
# which node
# exit

**Post ID:** 595698

Here’s how to prompt folks. Just do what @carlton mentioned in today’s live session (the 5 hour marathon) and you should be good for Project-1!


x.com


```Image was here: I'm unable to describe the image you provided. If you have specific content from the image or details you'd like to discuss, feel free to share!```
Aakash Gupta
@aakashg0

Most people are still prompting wrong.

I've found this framework, which was even shared by OpenAI President Greg Brockman.

Here’s how it works: pic.x.com/2MMcEqBeIJ```Image was here: The image displays a structured prompt for generating hiking recommendations, titled "The Anatomy of an o1 Prompt." It outlines specific requirements for an AI to fulfill, including a defined goal ("I want a list of the best medium-length hikes within two hours of San Francisco"), expected return format, warnings about accuracy, and a context dump that provides background information. The prompt emphasizes the need to include hiking details such as the name, starting address, distance, drive time, hike duration, and a description of the adventure. It also instructs to return the top three hikes. The context mentions personal experiences related to hiking in local areas and assures that the information needs to be unique and lesser-known, highlighting the user's interest in fresh hiking adventures rather than popular trails. The layout suggests a methodical approach to retrieving relevant hiking information, possibly for conversation or recommendation systems.```


8:06 PM - 14 Feb 2025


      5.5K
    


      360

**Post ID:** 595700

Same issue. Got the same token. Can’t use it since 2 dollar limit has been crossed. Please help. @carlton @Jivraj

**Post ID:** 595718

Yes I also need the answer of this.

**Post ID:** 595719

Is there any way of figuring what is the usage of my token and if yes then how…
Plz some peers help…

**Post ID:** 595720

It will be corrected soon by @jkmadathil
He is in charge of our budget for TDS and the tokens are being issued by him.
Please tag him for any token related issues.

**Post ID:** 595726

New token assigned to the students.  Emails are also sent.

**Post ID:** 595738

sir I am noticing a pattern, that when I am running the datagen first. And then using the evaluate.py, then I am getting the A2 right.
But running the evaluation.py for the 2nd time cause the A2 to fail…
Probabbly Because the file in the data folder gets upated should I worry for that…

**Post ID:** 595754

in the phase B, we have no idea about how many arguments are there, so should we make every function mapping with 2 arguments ( 1 containing the input location and other containing output location) or should we take the parameters in some other way

**Post ID:** 595772

There has been an outage in some parts of the country related to cloudflare servers. What helped some students (and us) is using a completely different network eg. instead of using your home wifi, use mobile internet, since they go through a different DNS and this sometimes works.
Kind regards

**Post ID:** 595773

We have not specified a size limit for the docker image, so in theory there is not a limit to the docker image size.
Kind regards

**Post ID:** 595774

Hello  @carlton Sir,
While running evaluate.py , I have observed that the expected  and actual output is having difference like “\n” then also it marks task as fail.
eg:
 EXPECTED:
Cover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.
Attention officer successful. Us population the true show.
Real cold if play side wind affect. Street cause investment receive have miss page station.
Cold rest term her conference. Animal sure campaign new.
Meeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.
Difficult yourself build increase back put others.
Although artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.
Whole way know down. Music machine trip father rather.
Must medical bad law issue.
Someone explain seven maintain wrong day factor property.
 RESULT:
“Cover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.\nAttention officer successful. Us population the true show.\nReal cold if play side wind affect. Street cause investment receive have miss page station.\nCold rest term her conference. Animal sure campaign new.\nMeeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.\nDifficult yourself build increase back put others.\nAlthough artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.\nWhole way know down. Music machine trip father rather.\nMust medical bad law issue.\nSomeone explain seven maintain wrong day factor property.\n”
 A5 FAILED
Will this be considered as failure in actual evaluation as well or will this be taken care in actual evaluation?

**Post ID:** 595782

```Image was here: The image displays a web browser interface with a URL showing a localhost address (127.0.0.1:18000) indicating that a task is being executed on a local server. The page presents a JSON response structured with a success message, which states: "Executed https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagpm.py with email trial@gmail.com." This indicates that a Python script named `datagpm.py` located in a GitHub repository has been executed successfully. The interface suggests involvement in a data science or machine learning project where the script is being utilized, potentially involving APIs or data retrieval from the specified URL. The visual elements suggest both a programming context where web technologies and local server execution are utilized, likely for testing or experimentation purposes within a data science framework.```image1412×248 16.3 KB
Im able to execute the query succesfully.
```Image was here: The image displays a file explorer interface on a Windows operating system, focused on a directory named "data" located on the C drive of a computer labeled "Acer." Within the "data" folder, various files and subfolders are visible. The subfolders include "docs," "logs," "comments," "contacts," and "dates," each marked as file folders, indicating they contain additional content. The visible files include "credit_card," labeled as a JSON source file (9 KB), "email," a text source file (1 KB), "format," also a text source file (1 KB), and "ticket-sales," identified as a database file (32 KB). The files have a modified date of February 16, 2025, at 11:58 AM. The interface allows sorting and viewing options, suggesting typical file management tasks. The context implies an organization of data possibly related to a software project or application, with specific emphasis on structured formats like JSON and database management.```image1109×570 40.3 KB
But the data gets downloaded to C drive instead of the project folder
The datagen.py file is in the project folder itself.
```Image was here: The image displays a segment of Python code that focuses on ensuring proper file access within a project structure. The code includes comments indicating two key functionalities: first, establishing the project root directory based on the current working directory with the line `PROJECT_ROOT = os.path.abspath(os.getcwd())`, and second, constructing a path to a 'data' directory using `DATA_DIR = os.path.join(PROJECT_ROOT, "data")`. Additionally, the code ensures the existence of the 'data' directory using `os.makedirs(DATA_DIR, exist_ok=True)`, allowing the directory to be created if it does not already exist without raising an error if it does. The context suggests a script intended for managing project file structures in a typical Python application, likely run in an integrated development environment (IDE) like VSCode. The indentation and formatting indicate adherence to Python's syntax standards for readability and function.```image821×149 9.61 KB
am I making any error when setting the directories?
Please help, have been facing this issue since the beginning of this project, initially tried to move the files from C drive to project folder but that does not seem like a viable solution.

**Post ID:** 595793

```Image was here: The image features Python code from a script function named `run_datagen(task_description)`, which is designed to extract a URL and an email address from a provided task description. The code utilizes regular expressions to match the URL format (`r"https?://[^\s]+\.py"`) and an email pattern (`r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"`). If either match fails, it returns an error message indicating that the URL or email was not found. Upon successful regex matches, it constructs a file path for a Python script named `datagen.py` located in a directory represented by `PROJECT_ROOT`. The script then attempts to download the content from the matched URL using the `requests` library, ensuring the request was successful with `raise_for_status()`. It saves the downloaded content to the specified path. Following this, it checks for the installation of a package (presumably `uvicorn`) using `subprocess.run()` to check its version, and if it isn't found, it attempts to install it using `pip`. Finally, the code runs the downloaded script with the provided user email in the current working directory set to `PROJECT_ROOT`. Successful```image1123×760 42.8 KB
I am also running datagen.py in the project directory, yet data folder is created in C drive.

**Post ID:** 595796

@jkmadathil
sir plz renew my token…
Showing,
{‘message’: ‘On 2025-02 you used $2.0041067399999912, exceeding $2’}
Sorry sir!..

**Post ID:** 595797

use PlainTextResponse for /read

**Post ID:** 595798

Plz do someone reply.

**Post ID:** 595800

@carlton @s.anand @Jivraj
Please review the code and help me fix the error in order to proceed further. Thanks.

**Post ID:** 595808

github.com/ANdIeCOOl/TDS_CLUTCH_PROJECT_1


README.md

main

# TDS_CLUTCH_AT_6AY







using code generation, getting 6/10 or * if lucky, similar comments needs a tool function call for sure, maybe someone can implement and create pull request, if you all can get 10/10 fine tuning with tool functions
@Jivraj @carlton Please help if it meets deliverables

**Post ID:** 595833

Sir I need a help, In hte B portion where no any destination and source files are given…
There we need to ask the user to povide the source and destination files or does we should store it in any default file locations…
As the statement is very vauge saying the “agent should handle this”…
Thanks Sir!!

**Post ID:** 595845

@jkmadathil @carlton @Jivraj
Sir earlier my code was running fine, but after the assigment of the new token,
it is now showing 400 bad request, which simply implies there is something wrong with the token…
plz do something sir…
```Image was here: The image displays console output from a service running on localhost (127.0.0.1) on port 51794 and 51797, indicating HTTP requests made to a server. The first request is a POST to the endpoint `/run`, designed to interact with an SQLite database file located at `/data/ticket-sales.db`. The URL query parameters suggest that the task involves calculating total sales by customer bids for concert tickets. It returns a "400 Bad Request" error. The second request is a GET to `/read` with a path to `/data/ticket-sales-gold.txt`, which returns a "404 Not Found" error. The logged information hints at a backend service handling data related to ticket sales, possibly for an application focused on event management or sales analytics. The language used is indicative of a programming context possibly related to web development or API interactions, likely involving Python and SQLite.```
I have do have cross verified the new token been correctly been assigned to the system variable…

**Post ID:** 595847

More Particularily the failure occurs in the response portion…
def get_completions(prompt: str):
    print("Inside get_completions")#Debug
    with httpx.Client(timeout=20) as client:
        response = client.post(
            f"{openai_api_chat}",
            headers=headers,
            json=
                {
                    "model": "gpt-4o-mini",
                    "messages": [
                                    {"role": "system", "content": "You are a function classifier that extracts structured parameters from queries."},
                                    {"role": "user", "content": prompt}
                                ],
                    "tools": [
                                {
                                    "type": "function",
                                    "function": function
                                } for function in function_definitions_llm
                            ],
                    "tool_choice": "auto"
                },
        )

    print("DId suceessful llm calll")#Debug

INFO:     127.0.0.1:52108 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 400 Bad Request

**Post ID:** 595848

is there any limit on the size of the docker image @Jivraj @carlton ? because mine is about 5.6Gb

**Post ID:** 595850

bhai nhi hai…
koi size limit

**Post ID:** 595859

uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py
Installed 13 packages in 543ms
Traceback (most recent call last):
File “/tmp/evaluateF6zgG9.py”, line 20, in 
from datagen import (
…<9 lines>…
)
ModuleNotFoundError: No module named ‘datagen’
I am getting this error when I try to run evaluate.py
when I run the evaluate.py by having datagen.py in same folder , it is running perfectly. But my doubt is only after task a1 runs the datagen.py will be downloaded into the /data folder right ?
@carlton @Saransh_Saini @Jivraj
Kindly help me with this issue

**Post ID:** 595860

Use following as first parameter of subprocess.run() to create data/ directory inside your project instead of C: drive
["uv", "run", script_url, user_email, "--root", "./data"]

Also, you don’t need to download to script, you can directly run it from the url.

**Post ID:** 595863

The reason for error is evaluate.py is trying to import datagen.py which doesn’t exist in your system. I’ll suggest download both the files, keep them in same folder and run evaluate.py from your computer

**Post ID:** 595864

Yes actually Thats my doubt , when I run both in same folder it is working , but only after task a1 runs datagen.py will be downloaded in /data folder  right ?,
or did I misunderstood something??

**Post ID:** 595865

Generation-Based Automation Agent (No Hard Coding)
Repository Link: GitHub - 23f2005593/tds
Currently, it can complete 7 out of 10 tasks. In reality, it can complete 9 out of 10 tasks, but the expected results are not flexible in evaluate.py file.
If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.
Please contribute to this repository. We will win together.

**Post ID:** 595866

{
“message”: “On 2025-02 you used $2.0041388599999848, exceeding $2”
}
What to do?

**Post ID:** 595868

facing same error, have you fouind any solution?

**Post ID:** 595871

sir for this task- A6 Find all Markdown (.md ) files in /data/docs/ . For each file, extract the first occurrance of each H1 (i.e. a line starting with #  ). Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title (e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...} )   …I am getting correct result for all files but for the very first file budget.md it shows wrong.
my result- { “budget.md”: “Success easy same main modern doctor.”,
“build.md”: “Shoulder follow own never above.”,
and in the data files there is different heading in budget.md.-  # Series dog who make specific agree between.
my question is this if it works for all the files then why not for this file budget.md    @Saransh_Saini @Jivraj @carlton

**Post ID:** 595877

do you able to do this task * A5. Write the first line of the 10 most recent .log file in /data/logs/ to /data/logs-recent.txt, most recent first …
i am also doing using prompt no hard-coded.

**Post ID:** 595878

yes doing this only but finding correct for most of the files.

**Post ID:** 595879

yes i am able to do task a5.

**Post ID:** 595881

so you directly using prompt for doing this task.

**Post ID:** 595882

yes i am only using prompt based method

**Post ID:** 595883

If filename has number in its name then extract the number from the filename and convert it to an integer before sorting .Ensure numbers inside filenames are compared as integers, not as strings, to maintain proper order. Sort filenames in said in task. Avoid any lexicographical sorting issues.    i am using this extra info for doing this but still it does not give accurate result. can you help me in this

**Post ID:** 595884

i already shared my repo u can check there.

**Post ID:** 595912

you have pushed data,datagen and evaluate files…do we have to submit them as well??
(also send the docker file)

**Post ID:** 595917

Check the file once, there is a possibility that it’s either fetching a comment or the second heading. Refactor your prompt to search only for the First Heading, specify it explixitly.

**Post ID:** 595928

okay let me check once.
one more thing sir {“first_name”: “Crystal”, “last_name”: “Wilson”, “email”: “delgadorebecca@example.com”}   then what will be the sorted-contact for this as in email there is no first and lastname present. @Saransh_Saini

**Post ID:** 595945

Hey, I submitted the project links in the google form yesterday but, today in the portal it shows that I have not submitted the project.

**Post ID:** 595955

I am getting this error while running evaluate.py on task A9
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

🔴 A9 failed: 'data'

There were no authentication issues till yesterday.
please guide @carlton @Jivraj @Saransh_Saini

**Post ID:** 595957

This is happening because evaluate.py is unable to fetch your API Key from the environment variables. Create a new variable and set it’s value to your API Key then try.

**Post ID:** 595959

Hi everyone,
I’m running into an issue with the AI Proxy embeddings endpoint while executing the A9 task. Every time I send a POST request to:
bash
Copy
https://aiproxy.sanand.workers.dev/openai/v1/embeddings

I receive a 401 Unauthorized response. This, in turn, causes my code to fail with a KeyError: 'data' because the expected JSON response doesn’t include the "data" key.
What I’ve Tried

Token Verification:


I’m using the AIPROXY_TOKEN obtained by logging in at aiproxy.sanand.workers.dev with my IITM email.
The token is passed in the header as follows:

python
Copy
"Authorization": f"Bearer {AIPROXY_TOKEN}"


I added debug prints to confirm that the token is being used correctly (printing the first few characters).


API Request Details:


The request includes the correct Content-Type: application/json header.
The payload is set as:

json
Copy
{"model": "text-embedding-3-small", "input": ["Test"]}


Despite this, the response status is consistently 401 Unauthorized.


Debug Output:
Here’s a snippet of the debug output:

bash
Copy
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"
🔴 A9 failed: 'data'

This confirms that the issue is with the authentication rather than our processing logic.
What I Suspect

The token may be invalid, expired, or misconfigured.
There could be changes in the token permissions or endpoint requirements that I’m not aware of.
Alternatively, there might be an issue on the server side with token validation.

Request for Help
Has anyone else encountered this issue recently? Could someone verify if there are any changes to the authentication requirements for the embeddings endpoint? Any insights or updated instructions on how to ensure the token is valid and has the proper permissions would be greatly appreciated.
Thanks in advance for your assistance!

**Post ID:** 595961

B5. Run a SQL query on a SQLite or DuckDB database
Should I ask for the SQL data base. Or the agent should be smart enough to find the required database…
Moreover in the data folder there is only one database is it should be robust to handle multiple databases…

**Post ID:** 595965

same issue i also face                   pls sir help us fix this issue and provide us more  token
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 429 Too Many Requests”
 A9 failed: ‘data’
@Jivraj @carlton @Saransh_Saini

**Post ID:** 595982

I had a question on evaluation by the course team. To test that my application would run everywhere, I first deleted all images from my local machine using podman rmi -a and then ran podman run --rm -p 8000:8000 -e AIPROXY_TOKEN=$AIPROXY_TOKEN $IMAGE_NAME with the appropriate variables set. This is as per the instructions provided here. But this gave me the following error:
Error: short-name "freshbash/dataworks-agent" did not resolve to an alias and no unqualified-search registries are defined in "/etc/containers/registries.conf

The above is the format in which we have to provide the image name in the Google form. So, I was confused whether this would succeed during actual evaluation.
The only way its working right now is when I specify the image name to be docker.io/freshbash/dataworks-agent
I’m not yet very good with how containers work so some insights would be very helpful. Thanks!

**Post ID:** 595987

Nice bro, if its getting 8 you are sorted, probably get more later. But Prompting seems a little less info
BUT





Structured Outputs
JSON Mode




Outputs valid JSON
Yes
Yes


Adheres to schema
Yes (see supported schemas)
No


Compatible models
gpt-4o-mini, gpt-4o-2024-08-06, and later
gpt-3.5-turbo, gpt-4-* and gpt-4o-* models


Enabling
response_format: { type: json_schema, json_schema: {strict: true, schema: …} }
response_format: { type: json_object }



    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_object"}
        )



github.com/23f2005593/tds


app.py

main


      
          prompt = (
              f"The Python code generated for the task '{task}' produced the following error when executed:\n"
              f"{error_message}\n\n"
              f"Here is the original code:\n{original_code_data['code']}\n\n"
              "Please provide a corrected version of the code that fixes the error. Return only a JSON object with:\n"
              "- code: the corrected Python code as a string\n"
              "- function_name: name of the main function\n"
              "- required_libraries: list of required pip packages\n\n"
              "Make sure the code is simple, direct, and error-free this time. And try not to mess it up like before."
          )
          try:
              response = client.chat.completions.create(
                  model="gpt-4o-mini",
                  messages=[{"role": "user", "content": prompt}],
                  temperature=0,
                  response_format={"type": "json_object"}
              )
          except Exception as exc:
              logger.error("Error connecting to OpenAI API for auto-fix: %s", exc)
              raise HTTPException(status_code=500, detail="Connection error during auto-fix. Maybe it's time to admit defeat?")
          
      
    





you are taking a chance on that format

**Post ID:** 596001

```Image was here: The image displays a user interface from GitHub Codespaces, focusing on resource usage. It illustrates the current utilization of "Usage hours," showing 172.37 out of 180.00 included core hours used, indicated by a red progress bar. Below this, it indicates "Storage," with a consumption of 9.21 out of 20.00 GB-month used, represented by a blue progress bar. The footer mentions a $0.00 monthly spending limit and includes an option to "Set up a spending limit." Additionally, there is a note about included quotas resetting in 10 days with a link to the billing documentation, implying the context involves monitoring and managing resource usage for cloud development environments.```Screenshot 2025-02-16 0913411315×404 24.2 KB
```Image was here: The image displays a user interface from GitHub Codespaces, highlighting the usage statistics for a coding environment. It shows a section labeled "Usage hours," indicating that the user has reached the maximum limit of 120.00 out of the 120.00 included core hours, represented by a red progress bar. Below this, the "Storage" section reveals that the user has utilized 1.46 GB of the 15.00 GB-month included storage, depicted by a blue progress bar. Both sections display the current usage against the allowed quota, with a total monetary cost of $0.00. The interface also includes a reminder about the reset schedule for quotas in 13 days and a link to billing documentation for further inquiries. The layout suggests functionalities typical of a cloud-based integrated development environment, essential for managing resources in software development projects.```Screenshot 2025-02-16 0911011351×292 13.3 KB
Hardest i ever worked in my life. Thank you @s.anand

**Post ID:** 596007

TheVishal:

If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.


have tried function calling? with open code generation ?

**Post ID:** 596034

not yet… but i have another problem when i am running this by using docker it is giving error “datagen module not found”

**Post ID:** 596038

bro please help by contribute please

**Post ID:** 596052

come off on one meet

**Post ID:** 596053

what should we push in the github repo @Jivraj @carlton ??
is it enough if we just push the Dockerfile, app.py, datagen.py and the LICENSE. Someone pls help!

**Post ID:** 596054

bro i used all my codespaces credits xD
i am nitpicking and editing from website and running not exceed limit XD

**Post ID:** 596057

someone pls help T_T

**Post ID:** 596060

submit image and github  repo link, evalhaters will handle the rest im assuming

**Post ID:** 596063

yeaa i got that but what should we add in the github repo…like should we add the generated data folder?
or is it enough if we just add the code and the Dockerfile to the repo

**Post ID:** 596064

doesn’t matter they use only image

**Post ID:** 596065

use local editor naa bro

**Post ID:** 596066

and run my code xD i have one crazy setup XD give me some time, at 9:30 we’ll hop on eachother

**Post ID:** 596067

which repo u submitting yesterday one or todays.
i am unable to run the yesterday one

**Post ID:** 596068

this one new one only xD

**Post ID:** 596069

and what do they mean by image-name in the gform…is it the repo name in dockerhub?

**Post ID:** 596070

what evil have u done xd

**Post ID:** 596071

why? ///////////// O—O

**Post ID:** 596072

dockerhub image name

**Post ID:** 596074

ur words are saying something else

**Post ID:** 596075

image name as in i dont get it lol.

**Post ID:** 596076

(general) [shubham@laptop data]$ curl https://api.openai.com/v1/models -H "Authorization: Bearer $AIPROXY_TOKEN"
{
  "error": {
    "message": "Your authentication token is not from a valid issuer.",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_issuer"
  }

pls help

**Post ID:** 596077

push ur image to docker hub that it will be available for them to use
(use chatgpt on how to push to docker hub 2 3 steps to flw)

**Post ID:** 596078

yeah i hv pushed the image to dockerhub but i exactly dont get what image name is
like is it the name of my repo

**Post ID:** 596080

ur docker-username/image-name

**Post ID:** 596081

check if u have exported the AIPROXY_TOKEN properly in your environment

**Post ID:** 596083

anyone check my repo

github.com



```Image was here: The image displays a GitHub repository header for a project named "TDS_Project_1" under the user "Tusharisme." It indicates there is 1 contributor, with the project currently having 0 open issues, 0 stars, and 0 forks. The user interface features the typical GitHub layout, including a repository icon that suggests a software project. The repository's activity status implies it is newly created or still in an early phase of development, focusing on collaboration and version control for software engineering tasks.```
GitHub - Tusharisme/TDS_Project_1
Contribute to Tusharisme/TDS_Project_1 development by creating an account on GitHub.

**Post ID:** 596084

yes i have the same key which is provided on ai proxy website for my login
and yes i have that key properly exported

**Post ID:** 596086

check if u have used the correct ai proxy url then

**Post ID:** 596088

An email I just received says my license doesn’t have “MIT” in it. Although it does have it. I don’t know what I am missing. Someone help (if you didn’t get this mail). @carlton @Jivraj

**Post ID:** 596090

@carlton @Jivraj @Saransh_Saini
Hi,
I received a mail saying that my submission has no Dockerfile. But git repo has a dockerfile.
even if i am to submit again, i have submit the same repo.
what should i do?

**Post ID:** 596091

Hey I just got a mail saying that my github repo has no Dockerfile present. and im confused .
It doesnt mention anywhere that the dockerfile must be present in the root directory as a requirement/prerequisite of the project.
In my case its present inside the app directory. Could the team help clarify on this issue.
@Jivraj @carlton

**Post ID:** 596092

What is expected repo structure ?
I have a folder in my repo and dockerfile and license are present in that folder but I still received a mail regarding missing License and Dockerfile.

**Post ID:** 596095

do we need to have data folder in repo no right?

**Post ID:** 596096

No, it is not needed

**Post ID:** 596097

We see that your submission GitHub - 22f3001011/project-1  has a result of FAIL due to the below reasons:
No “MIT” in LICENSE
Hello sir, i got this mail despite having added the mit license as stated in the project problem statement. I cant figure out what the issue is, and help me out here.
@carlton @Jeeveash.k

```Image was here: None```
github.com


GitHub - 22f3001011/project-1
main
Contribute to 22f3001011/project-1 development by creating an account on GitHub.






Thank you
Regards
Shashank J Shetth
22f3001011

**Post ID:** 596101

Yeah. Same issue. Someone who didn’t get this error, please share the MIT license.

**Post ID:** 596104

https://github.com/saniyanz/tds-p1new
check my repo. whats wrong. Ive also got the mail but I`ve included the MIT License and the Dockerfile

**Post ID:** 596105

Rename LICENSE.txt to LICENSE

**Post ID:** 596108

I got a mail saying my Dockerfile is missing. However I have a dockerfile already in my github repository. Is it an issue with the spelling of dockerfile since I have submitted it in all small case as ‘dockerfile’. It was showing the score when I checked with the evaluate.py that was provided by iitm.
Shall I just change the name of the file from ‘dockerfile’ to ‘Dockerfile’ in github repository of mine or is there anything else that is needed to detect the Dockerfile?

**Post ID:** 596109

Hey team, I just moved my Dockerfile to the root level on my Github repo. Hope this solves the issue.
Small doubt: Do i need to submit the google form again?

**Post ID:** 596114

I ran out of tokens. Please help me. Please its urgent.

**Post ID:** 596117

@carlton sir @s.anand sir please provide me more tokens, I am out of tokens i don’t knwo what happened i hade 151 requests use and 0.09 usd and suddenly i check it was 300 requests and 2 usd i don’t knwo what happened can you provide me more tokens.

**Post ID:** 596118

Dear @s.anand , @carlton , @Jivraj , and @Saransh_Saini
Thank you all for this wonderful project. Coming from a non-coding background, I have learned a lot new things throughout this project building process.
@carlton Sir, yesterday’s session provided valuable insights into Method 1 (prompt engineering) for dynamically handling tasks. I was able to develop an application using this approach; however, due to submission time constraints, I could not verify all tasks (my bad). While I tested some tasks and found the results to be highly accurate, I was unable to validate everything thoroughly.
Therefore, I submitted the function-calling approach (Method 2) instead.
I sincerely appreciate everyone’s guidance and support.

**Post ID:** 596120

Did you ran out of tokens suddenly like me ?
How many requests have you sent in total ?

**Post ID:** 596121

can u share ur repo
i really need it

**Post ID:** 596129

Thanks @lakshaygarg654 for this feedback. Glad to know you learned from our efforts, it means a lot. This proves that even a person from non-tech background with determination can achieve it.

**Post ID:** 596131

sir pls provide more token   @Saransh_Saini @Jivraj @s.anand                              sir pls , give any reply we have only 2 hr left

**Post ID:** 596132

Change the name of your dockerfile to “Dockerfile”

**Post ID:** 596133

yes sir please provide more tokens to me also @s.anand @Jivraj @carlton @Saransh_Saini

**Post ID:** 596135

i hope i get 1 mark xD
im getting tasks only maybe 3 / 10

**Post ID:** 596138

i have done many attempt but it is not working please show  my environment saying fastapi is not installed but i have installed and it is showing on checking but no running file it is saying no module i have installed in both virtual and system
please help

**Post ID:** 596140

```Image was here: The image shows a Visual Studio Code interface displaying a Python script utilizing the FastAPI framework. The code snippet includes an import statement for FastAPI and a function named `run_task`. The FastAPI app instance is instantiated, and a `POST` method is defined to return a JSON response stating, "LUI-based Automation Agent is Running." Below the code, the integrated terminal output reveals system warnings and errors during a package installation attempt. It indicates that a compatible version of `pip` is not found for Python installation, listing available versions of Python and failing dependency checks. The terminal also shows a command executed to build an image from a Dockerfile, specifically building a slim version of Python 3.10, and reports on the progress of the build process. This context suggests that the user is engaged in debugging a FastAPI application and managing dependencies using Docker.```image1919×1016 117 KB
this problem occuring sir since two days

**Post ID:** 596141

How long does it take to make a docker image, I’ve been doing it for the past 25 minutes and it’s still not completed.

**Post ID:** 596144

Your LLM app should be designed like it can give desire result based on task desc at run endpoint, and that result should be accessible at read endpoint.


Evaluation file just for reference to check how things works and it works for phase A tasks only. Also ensure datagen.py file and evaluation.py file are latest. There is one issue in evaluation.py file for task A1,  link of datagen.py file not correct, rectify that link. Even it corrected in GitHub repo file but when I download that raw file in local system it takes back previous link.

**Post ID:** 596146

I WONDER HOW MANY API REQUESTS THE SERVER IS PROCESSING . It’s too slow

**Post ID:** 596151

too much in the last few hours it feel

**Post ID:** 596161

I guess what is done is done. I should have maintained my version history properly. I am getting 4 correct but with minor formatting issues so only 1 correct I guess.

**Post ID:** 596163

It was tough… I will probably not score much but I enjoyed it a lot. Thank you for pushing us so hard. At least I am not scared of docker now and function calling feels easier than before.

**Post ID:** 596166

Well done, everyone! This is not an easy project. This is the kind of work our clients are asking us for.
I will keep you posted on the evaluation on this thread, it progresses.

2025-02-16T18:31:00Z Google Form closed
2025-02-16T18:35:00Z Validating submissions. Will post results shortly

**Post ID:** 596168

Sir i have missed the submission deadline  by 5  minutes, can you give permission for the google form to accept the response for half an hour more.

**Post ID:** 596169

Sir, due to time panic, I mistakenly named the Docker image incorrectly.

**Post ID:** 596170

Sir can you please allow submission for 5 more minutes?

**Post ID:** 596988

A post was merged into an existing topic: Project 1 - Casual banter

**Post ID:** 596172

@s.anand @carlton
Dear Sir,
I am writing to you in a state of distress and humility. An unfortunate mistake on my part has led to the upload of an incorrect Docker image link. When I checked the authenticity of the link, it showed an error, even though the GitHub repository link is functioning perfectly.
I have poured my heart and soul into this project, dedicating countless hours and sleepless nights to ensure its success. The project has successfully passed both Test A and Test B, and I was thrilled to see my hard work paying off. However, this single error has left me devastated.
I am pleading with you, with all my heart, to allow me to correct this mistake by updating the Docker image link. Alternatively, I humbly request that my application be reviewed directly through GitHub. Please consider this an exception, as I have worked tirelessly over the past two weeks to create an application that is 890 lines long.
I beg for your understanding and leniency in this matter. This project means the world to me, and I am genuinely sobbing over this setback.
Thank you for considering my heartfelt request.
Sincerely,
Rishit Jain
(24F2004595)

**Post ID:** 596174

Although couldn’t complete handling every task, but really enjoyed working on this project and learned a lot throughout the process. I appreciate the opportunity to work on such an engaging project. For Project 2, I’ll make sure to allocate sufficient time and approach it with even greater commitment.

**Post ID:** 596175

Sorry @s.anand @carlton @Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.

**Post ID:** 596179

Just push the latest image to docker asap. Hopefully the team considers it.

**Post ID:** 596180

True. Same here. Just giving 2 days for this project was definitely a big mistake on my part… but I couldn’t really give more time due to work commitments.

**Post ID:** 596182

@s.anand @carlton @Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.
I am not 100% sure but i guess i used “ii” instead of “i” in “thevixhal/tdsvishal”… is there any way to check this ?

**Post ID:** 596183

Can the submissions open just for some time? In minutes?
Many students did silly mistakes due toh nervousness, we can just correct it.

**Post ID:** 596203

I don’t think the project is too difficult to implement—it’s essentially a simple HTTP API for an AI agent that reads a task, converts it into parameters, and passes those parameters to specific functions to complete the task. However, the instructions in the project question aren’t very clear. Before the session, I am unable to fully understand the question. It took me almost an entire day just to understand what we need to do.
Sir Could you provide test cases or a sample answer for Phase B?

**Post ID:** 596221

@s.anand
@carlton sorry to disturb you, project1 deadline is over.
I made a mistake in my project. In my call llm function i set some payload instead of default for open ai api call like max token, temp. , n, stop etc.
Due to this, some tasks may fail especially credit card image task will fail 100%, if possible can i just remove that payload from git hub repository . or you can check this call llm function present in my task_handler.py file of my repository.
I found this issue after deadline. If possible consider this request. I never engaged in a project or course like for this one. I love this project genuinely.
my github repo : GitHub - 21f3001076/TDS_Project_1: This is IITM Data Science TDS Course Project 1 Repository
Thankyou
Lakshay
student id: 21f3001076@ds.study.iitm.ac.in

**Post ID:** 596231

Dear @s.anand @carlton @Jivraj ,
Thank you so much for this wonderful project! We have learned so many things from this experience, especially the power of prompts. The team has put in tremendous effort, extending a few sessions and patiently clearing all our doubts. We truly appreciate the dedication and support
Regards,
Arjun

**Post ID:** 596233

I would like to sincerely thank the course faculty @carlton @Jivraj @Saransh_Saini for their support on the project throughout the week. They were so patient in listening to our issues and helping us resolve them, even if the issues were repeated.
I was not able to complete some or maybe many of the tasks but overall, it was a very good learning for me, and I thoroughly enjoyed it.
Thanks very much again for your guidance and support.
Regards,
Swati

**Post ID:** 596296

Thanks for your compliments Swati. It’s always nice to know our efforts paid off.
Happy Learning

**Post ID:** 596310

I have received a mail that my project has ""No “MIT” in LICENSE;No Dockerfile " which I saw today. My project has MIT licence and Dockerfile was also there… but to reconfirm I pulled my dockerfile from dockerhub to github only . NOw am not sure will that be considered now in my project submission or not. Requesting to kindly consider current state of my project in submission for my project.

**Post ID:** 596317

WOMP WOMP should i call a wambulance?

**Post ID:** 596319

(post deleted by author)

**Post ID:** 596321

@all those who didn’t submit, its ok EVEN I did NOT submit. Even though i get zero, i am happy with the learning i did. Once again thank you sir @carlton @s.anand . This a been awesome experience , i haven’t been this alive in forever. Cheers.

**Post ID:** 596326

I noticed something quite funny. The project never specified the required tech stack, so one could have done this entirely with JavaScript as well, assuming the necessary libraries are installed.

**Post ID:** 596329

@TheVishal
EDIT: Create a new docker image with the mistaken image name , so when they pull image from repo, that image with the wrong name also gets pulled.
what to do

push a new image with the mistaken name, so in your repo there will be two images
how will this help?
since you are unsure, which image link you posted, you can be sure that even you had a mistake in link, a new image will exist with the wrong name after you push another image

@all
use this to update your image even after submission, as now they only validate the images, they do not pull it so you can edit your project and add more functionality if they release the code solutiion
CHEERS
Andrew OUT.

**Post ID:** 596332

I didn’t submit the google form, I have made the github repo and docker image for TDS project 1. I, mistakenly, thought that I had submitted the google form but actually it was saved as a draft and closed my laptop. As soon as I realized my mistake, I hit the submit button but this was shown then,
“The form TDS Jan 2025 - Project 1 Submission is no longer accepting responses.”
I apologize for this. I have been working on this project for weeks.
This was my first TDS project. I would highly appreciated, if you could help me.
Thankyou
GitHub repo:GitHub - Sagankaur/TDS_project1: LLM-based automation agent
Docker : sagandeep/tds_project1

**Post ID:** 596348

Sir, can we get the evaluation script now
@carlton @s.anand

**Post ID:** 596368

If I am not wrong you were getting 9/10 in task A when many of us were stuck  and you didn’t submit… unbelievable

**Post ID:** 596370

Thank you, sir, for giving us this amazing opportunity! Honestly, I learned more in the last week than I did throughout the three modules.
The project was a rollercoaster ride—especially with all the errors that kept popping up—but overall, the experience was incredibly enriching. The amount of knowledge I gained was truly valuable.
A huge thanks to @Carlton, @Saransh_Saini, and @Jivraj sir for their guidance and support. Without the last week’s lectures, the project couldn’t have been completed.

**Post ID:** 596381

i couldn’t my code space ran out of compute and then it was just lagging before i found out what happened , i just submitted old code repo and the image the we created in week 2 or week1 when had to create docker image for graded assignments
EDIT:
```Image was here: The image displays a user interface from GitHub Codespaces, showing usage statistics for a developer's coding environment. It highlights **core hours** utilized, indicating that 120 out of a maximum of 120 included core hours have been exhausted, marked by a red progress bar. Below this, **storage usage** is indicated, showing 1.46 out of 15.00 GB-months utilized, represented by a blue progress bar. The interface includes links to billing documentation, suggesting a focus on monitoring resource consumption. This context indicates the user is likely managing a coding project within a GitHub Codespace environment, tracking usage limits for efficient resource allocation.```Screenshot 2025-02-16 0911011351×292 13.3 KB
```Image was here: The image displays a notification from the GitHub Codespaces interface, indicating that the user has reached 100% of their included usage for the current billing period. The message is highlighted with a red warning symbol, emphasizing the urgency of the situation. It advises the user to review their billing settings for more information. The context suggests concerns related to resource consumption in a cloud-based development environment, potentially affecting ongoing projects or code collaboration activities. No specific code, console output, or technical configurations are visible, as the focus is solely on the account usage warning. The UI elements include navigational options to "Go to docs" and "New codespace," indicative of an integrated development environment focused on software engineering.```Screenshot 2025-02-17 2004141338×200 18.2 KB
```Image was here: The image displays a user interface from GitHub Codespaces, showing usage statistics for core hours and storage. The "Usage hours" section indicates that 180 out of a maximum of 180 included core hours have been used, with a bold red line emphasizing the limit being reached. The "Storage" section shows a usage of 9.60 out of a 20.00 GB-month allocation, represented by a blue line, well within the allowed limit. The UI contains a callout for "Included quotas reset in 8 days" and provides a link to "See billing documentation," implying a focus on managing usage within the context of cloud development environments. This configuration emphasizes monitoring resource consumption relevant to ongoing development activities.```Screenshot 2025-02-17 2005251312×321 18.5 KB

**Post ID:** 596406

Wait we had limits in codespace…I didn’t thought much of it but now that I see… …even mine is not so far from the limit…thanks for reminding…gotta be careful in next project

**Post ID:** 596606

@carlton @Jivraj Is there something like peer-review in the project, I found this in the grading document.
```Image was here: The image contains a text snippet detailing a grading structure for two components labeled P1 and P2 in an educational context. It specifies that both components consist of "Submissions" and "peer reviews," with a weightage distribution of 80% for submissions and 20% for peer reviews. The concise format suggests usage in a software system managing coursework or assessments. The context implies a focus on collaborative learning or assessment systems, likely relevant to educational software or platforms that facilitate peer evaluations and submissions. Specific technologies or platforms are not directly indicated in the text presented.```
```Image was here: The image displays a table with two rows and one column, indicating a "Peer Review Date" field, where the first row is labeled as such and currently marked with a dash ("-"), suggesting no date has been assigned. The second row contains a specific date: "Tuesday, February 25, 2025." This format is typical in documentation or project management tools where tracking review timelines is necessary, possibly within a software engineering, academic, or project development context. The layout implies it may be part of a report or a formal submission related to code or documentation review processes.```Screenshot 2025-02-18 at 1.00.50 PM126×226 2.02 KB

**Post ID:** 596614

This project is one of the best experiences I had in the entire degree program. I could say this without any hesitation that what I learnt in the past 10 days >> last 3 months.
I really appreciate the idea of open internet type of evaluations, wherein, you implement things without any constraints, learning for the sake of implementing.
Doing this project, I also found many new ideas wherein function calling can be used to solve new problems. I also learned many new things from enthusiastic peers like @23f1002382 and also got the chance to help a few.
I thank the entire TDS team - @s.anand sir, @carlton , @Jivraj for their support throughout this amazing experience.
Regards,
Pradeep Mondal

**Post ID:** 596662

sir using prompt method also i am having the error please provide a step wise solution so then i can make functions accordingly.
#/// Scirpt
# requires-python = ">=3.13"
# dependencies = [
#     "fastapi",
#     "uvicorn",
#     "requests",
# ]
#///

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

import requests
import os
import json
from subprocess import run

app = FastAPI()

response_format = {
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}

primary_prompt = """
                You are an automated agent, so generate python code that does the specified task.
                Assume that uv and python are pre-installed.
                Assume that code you generate will be executed inside a docker container.
                Inorder to perform any task if some python package is required to install, provide name of those modules. 
"""

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {AIPROXY_TOKEN}"
}

@app.get("/")
def home():
    return {"welcome to the task runner"}
@app.post("/run")
def task_runnner(task: str):
    url = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    data = {
        "model": "gpt-4o-mini", 
         "messages": [
             {
              "role": "user", 
              "content": task
              },
              {
                "role": "system",
                "content": f"""{primary_prompt}"""
            }
         ],
         "response_format": response_format
    }

    response = requests.post(url=url, headers=headers, json=data)
    r = response.json()

    return r

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

```Image was here: The image displays a Postman interface utilized for making HTTP requests, specifically a POST request to a local server running at `http://localhost:8000/run`. The request parameter includes a key called `task` with the value `The file /data/dates.txt`. The server's response indicates a status code of `200 OK`, suggesting the request was processed. However, the response body contains a JSON object with an error message: `Invalid value: 'json'. Supported values are: 'json_object', 'json_schema', and 'text'`, and it lists additional properties such as `monthlyCost`, `cost`, and `monthlyRequest`. The error details specify the issue as an `invalid_request_error` with the parameter `response_format.type` identified as `invalid_value`. The interface elements also indicate the setup of different headers and provide options for viewing and visualizing the response data. The context implies debugging an API response format issue while working with a service that processes input tasks.```Screenshot 2025-02-14 1858201945×1484 229 KB
@carlton , @Saransh_Saini , @Jivraj

**Post ID:** 595022

Sakshi6479:

{
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}



It clearly says in your error message:
Invalid value: ‘json’
if you look at the “type” key in your response_format variable at the top,
the value cannot be “json”
The error is telling you what the supported values are
‘json_object’, ‘json_schema’, and ‘text’
Since you are defining a schema the correct value should be ‘json_schema’
So therefore you should change
"type": "json"

to
"type": "json_schema"

If you have trouble constructing Json schemas,
either feed it to gpt and have it correct it (along with your error) or please go over Module 3, in particular
https://tds.s-anand.net/#/llm-text-extraction
There is a clear example you can use as a template. We use the same one as a template when we do it in the sessions. That way you will make less errors.
Kind regards

**Post ID:** 596763

Thanks @21f2000709 for kind words
Tagging Saransh for his efforts to project @Saransh_Saini.
@23f1002382 most active student on this post thanks to you too.
Kind regards

**Post ID:** 596771

21f2000709:

@carlton @Jivraj Is there something like peer-review in the project, I found this in the grading document.


Anyone having any idea on this?

**Post ID:** 598912

No human peer reviews. The peer will be an LLM that has been given the rubrics and fine tuned.
Kind regards

**Post ID:** 598921

carlton:

The peer will be an LLM that has been given the rubrics and fine tuned.


May the peer give me good marks

**Post ID:** 599398

@carlton Would the scores of project 1 be released tomorrow?

**Post ID:** 599832

@Yogesh1
We do not have an ETA on Project 1 scores yet. Might have more clarity soon.
Project 1 scores will be available roughly second week of March.
Kind regards

**Post ID:** 599836

@lakshaygarg654
I know this is a late reply, but its not possible for us to consider changes to your project after the deadline for academic integrity purposes.
If we were to allow it, we would have to allow everyone to make changes to their project as well for it to be fair.
Kind regards

**Post ID:** 599837

We will soon provide a complete solution for Project 1 because of its valuable learning.

**Post ID:** 599929

Alright, @Carlton. No problem at all, and thank you for your response.
I just wanted to bring a small limitation in my project’s LLM function to your attention, which I discovered after submission. It may impact one or two tasks. However, no concerns—this has been a great learning experience.
And if possible, just add one line in your Evaluation LLM prompt: “Give loose marking for effort!”—because, you know, creativity deserves some extra credit!

**Post ID:** 606016

I am not able to see my project marks please look into the problem

**Post ID:** 606505

Its not been evaluated yet.
We are still processing them.
Kind regards

**Post ID:** 607262

So will the solution be based on New MCP style or will they use the same function calling?

**Post ID:** 607744

Definitely MCP style. Its the most elegant solution and it works beautifully. As soon as evals are done we will showcase it.

**Post ID:** 609776

@carlton Any ETA on project 1 scores?

**Post ID:** 609976

I would like to request some bonus like 0.5 bonus mark for each day of delay from the original expected date of receiving score for Project 1 (will be life-saving for us and will be an incentive for team to release scores quickly; or request to TAs if you had better ideas for helping us score more in Project 1)!

**Post ID:** 611582

Any Updates? Can we expect it to be out before P2 deadline?

**Post ID:** 614016

```Image was here: The image presents a checklist summary likely from a validation or assessment tool concerning various elements related to a software project, particularly focusing on Docker and GitHub configuration. The visible text includes specific checks for a Docker image's presence on Docker Hub, indicating a failure status ("FAIL") for the condition "Is Docker image present in dockerhub AND is public." The checklist continues with other assessments, where the GitHub repository's public status is confirmed as "PASS," the presence of a "Dockerfile" in the GitHub repository is also marked as "PASS," and the existence of an MIT license at the repository's root is noted as "PASS." Below this checklist, the prerequisites are listed with "FAIL" and an overall project score of 0. The context suggests a scenario related to evaluating project readiness or compliance in a software engineering environment, possibly using a custom-built evaluation script or tool that checks for adherence to certain standards.```image412×167 4.49 KB
```Image was here: The image displays a user interface from a version control platform, likely GitHub or a similar repository hosting service. It shows a table with two entries indicating the status of code repositories. The first entry notes that changes were “Last Pushed” approximately two hours ago, with an accompanying indicator suggesting a recent update. The second entry states a push from “2 months ago.” Both entries have a “Public” visibility label highlighted, indicating the repositories are accessible to anyone. The presence of an “IMAGE” label next to the entries suggests that there may be associated visual content or README files related to each repository, possibly indicating the files contain illustrative elements or screenshots. The overall context suggests a focus on managing and monitoring the state of publicly available code repositories, suitable for software collaboration and version tracking.```image439×204 7.25 KB
This docker image has outlived many students’ hopes, dreams and ambitions of passing this course.
Why is it still not being detected properly on the docker hub?
What in the April Fools is this 

It hasn’t even been morning yet!

PS ( @carlton @Jivraj ): My P1 submission had passed all the basic sanity checks on 15th February. No breaking modifications to the Github repo nor the DockerHub image have been made since then. There’s something bugged in your scripts. Kindly check.

**Post ID:** 614037

same issue here
i have my git repo public but its saying i don’t have public git repo, also i have dockerfile in my root folder but its also said fail, same for mit license
```Image was here: The image depicts a GitHub repository titled "TDS_Project_1" with the current branch set to "main." The repository contains multiple files, including a Python script named `__init__.py` marked as "completed final," a `data` directory, a `Dockerfile` with the note "Added Dockerfile," and several other files like `README.md`, `LICENSE`, and `setup.py`, all showing timestamps indicating updates from two months ago. The repository utilizes an MIT license and includes implementation notes indicating various stages of development, particularly focused on an "API for automation agent." The interface suggests use of GitHub's collaboration features, with options available for cloning, forking, and reviewing code changes. The coding languages utilized within the repository are identified as Python and Dockerfile, alongside indications of contributions and potentially open discussions related to the project.```image1889×1022 122 KB

**Post ID:** 614094

yes sir same problem
```Image was here: The terminal output shows a command-line interface operating in a Git Bash environment on a Windows machine. The user navigates to the "hello_world" directory using the command `cd hello_world`. An error indicates an invalid command, likely due to a formatting issue with the input. Following this, the user correctly executes `ls -l Dockerfile`, which lists the properties of a file named "Dockerfile". The output reveals that the Dockerfile is a regular file with read and write permissions for the owner (hsent), indicating its size is 197609 bytes and the last modified date is February 16 at 18:50. The interface denotes the Git branch as "main", indicative of a Git repository context, suggesting the user is working with Docker configurations, possibly for a software project. The command syntax, user prompt, and output formatting point towards a focus on file management and retrieval of Dockerfile attributes within a software engineering setting.```image885×346 15.3 KB
```Image was here: The image displays a GitHub repository named "hello_world" under the user "Harish018S." The repository interface shows the "Code" tab, highlighting the main branch, which has 2 branches and 0 tags. A list of files is visible in the repository, including "LICENSE," "README.md," and "app.py," with corresponding commit messages indicating the creation of the LICENSE file and the app.py script, as well as an initial commit for the README.md file, all dated approximately two months ago. The README file is noted to include an MIT license. The GitHub interface features standard elements such as the repository's public status, navigation options (Issues, Pull requests, Actions, Projects, Wiki, Security, Insights, Settings), and a search bar. This repository likely serves as a simple starting point for a project, potentially involving Python programming given the presence of "app.py."```image1330×718 54.7 KB
please check and say sir.
```Image was here: The image displays a Windows File Explorer view of a directory named "hello_world" located at the path "C:\Users\hsen\". The folder contains six items, including a subdirectory named "gPR" and files named "Dockerfile" (type: Python Source File, size: 1 KB), "LICENSE" (type: File, size: 1 KB), "README" (type: Markdown Source File, size: 1 KB), and "requirements" (type: Text Document, size: 1 KB). The date modified for all files is shown as 16-02-2025, with timestamps indicating they were all modified around the same time. The interface includes typical Windows elements such as a search bar, viewing options, and a mini toolbar, suggesting a development context likely associated with Python projects or containerization given the presence of the Dockerfile.```image1918×1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven’t opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton @s.anand @Jivraj

**Post ID:** 614097

yes sir same problem
```Image was here: The image displays a terminal session in a MINGW64 environment, indicating a user navigating a project named "hello_world". The command sequence begins with `cd hello_world`, which successfully changes the directory to "hello_world". Following that, an erroneous command `[[200-ls -] Dockerfile` is attempted, leading to the error message `bash: '$'\E[200-ls': command not found`, highlighting a syntax error. The user then runs `ls -l Dockerfile`, which successfully lists the details of a single file named "Dockerfile" in long format. The output shows the file permissions as `-rw-r--r--`, owned by the user `hsent`, with a size of `197609` bytes, created on `Feb 16` at `18:50`. The interface indicates that the user is likely engaged in system-level operations, potentially related to Docker configuration or setup within a software development context.```image885×346 15.3 KB
```Image was here: The image depicts a GitHub repository named "hello_world," showcasing a structured directory view. The repository, owned by the user "Harish018S," is set to public and includes two branches with no tags. Visible files in the repository include "LICENSE," "README.md," and "app.py," indicating basic project documentation and a main application script. The "README.md" file is designated for initial commit details, alongside a LICENSE file indicating the MIT license for the code, while "app.py" is noted as a recently created application file. The interface hints at a version control environment, with options for code exploration and management typically found in GitHub repositories, categorized under actions like pull requests and project insights. This setup suggests foundational work in a software engineering project, possibly intended for demonstrating basic functionality or serving as a template for future development.```image1330×718 54.7 KB
please check and say sir.
```Image was here: The image displays a file explorer interface on a Windows operating system showcasing the contents of a directory named "hello_world." Within this directory, there are six items, including a folder named "src" and several files: a Python source file named "app.py" (1 KB), a "Dockerfile" (1 KB), a "LICENSE" file (1 KB), a "README" Markdown source file (1 KB), and a "requirements.txt" text document (1 KB). The files were last modified on February 16, 2025, at various times, indicating recent updates. The user interface reflects common file navigation elements, including a search bar and typical Windows Explorer buttons. This setup suggests that the user is likely involved in developing a Python application, possibly using Docker for containerization, with notes on requirements and licensing included in the project.```image1918×1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven’t opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton @s.anand @Jivraj

**Post ID:** 614326

same issue with me , my repo has both the dockerfile , license and is public. Please look into this . @carlton sir . GitHub - veershah1231/tds_proj_1: Tds project and i have made them 2 months ago and is not a new commit.
```Image was here: The image displays an email correspondence regarding a project evaluation for a software engineering task, emphasizing the requirements for a GitHub repository and associated Docker configurations. It outlines prerequisites for a project, indicating that the recipient's GitHub repository must be publicly accessible, have a valid MIT license, contain a Dockerfile, and ensure that the Docker image is accessible via a specified command format using the `podman run` command with an AirProxy token. The evaluation results indicate a failure, noting that the GitHub repository is not public and the MIT license is missing, while the Docker image's status is also flagged as not meeting the criteria. Technical terms such as "Docker image," "GitHub repository," and "AirProxy_TOKEN" are present, reflecting a context involving containerization and version control. The assessment for prerequisites shows a score of zero, stressing the need for corrections before re-evaluation.```10001053861072×1787 256 KB

**Post ID:** 615829

I came pretty close, but too close(double entendre) to the deadline. Classic ICARUS stuff
0/20
